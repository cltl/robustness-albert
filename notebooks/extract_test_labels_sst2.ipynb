{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "actual-heather",
   "metadata": {},
   "source": [
    "# Retrieve SST-2 Test Set Labels\n",
    "Since the SST-2 dataset from HuggingFace does not include the labels for the test set, we manually extract them from the original SST-2 data (https://gluebenchmark.com/tasks). \n",
    "\n",
    "We match the phrases of the test set in HuggingFace with the phrases in the SST-2 dataset from the *dictionary.txt* file to get their phrase IDs. Then we use those IDs to extract the labels from *sentiment\\_labels.txt*. Every label above $0.6$ is mapped to *positive* and equal to or lower than $0.4$ is mapped to *negative*, as mentioned in the instructions of the *README.md* file. Some sentences are matched manually as they differ only in British vs. American English spelling.\n",
    "\n",
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "intended-trauma",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "offshore-tomato",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/Users/urjakhurana/.cache/huggingface/datasets/glue/sst2/1.0.0/7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n"
     ]
    }
   ],
   "source": [
    "from generalize_checklist.utils import get_dataset\n",
    "            \n",
    "dataset = get_dataset(\"glue\", \"albert-large-v2\", \"sst2\", split=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "specified-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match phrases to their IDs.\n",
    "labels = np.array([d[\"labels\"] for d in dataset]).astype(int)\n",
    "\n",
    "dictionary_path = \"Downloads/SST-2/original/dictionary.txt\"\n",
    "all_sentences = [d[\"sentence\"] for d in dataset]\n",
    "\n",
    "with open(dictionary_path, \"r\") as f: \n",
    "    original_sentences = f.read().splitlines()\n",
    "    \n",
    "sentences = [h.split(\"|\")[0] for h in original_sentences]\n",
    "original_ids = [h.split(\"|\")[1] for h in original_sentences]\n",
    "lower_originals = [s.lower() for s in sentences]\n",
    "\n",
    "phrase_to_id_og = dict(zip(lower_originals, original_ids))\n",
    "phrase_to_id = {k: v for k, v in phrase_to_id_og.items() if k.strip() in all_sentences}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "laden-organ",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Match IDs with the labels. \n",
    "labels_path = \"Downloads/SST-2/original/sentiment_labels.txt\"\n",
    "\n",
    "with open(labels_path, \"r\") as f: \n",
    "    ids_labels = f.read().splitlines()\n",
    "    \n",
    "ids = [h.split(\"|\")[0] for h in ids_labels]\n",
    "og_labels = [h.split(\"|\")[1] for h in ids_labels]\n",
    "\n",
    "labels = []\n",
    "for label in og_labels[1:]:\n",
    "    if float(label) <= 0.4: \n",
    "        label = 0.0 \n",
    "    elif float(label) > 0.6: \n",
    "        label = 1.0\n",
    "    labels.append(label)\n",
    "\n",
    "id_to_label = dict(zip(ids[1:], labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "sunset-jefferson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map phrases to the labels. \n",
    "phrase_to_label = {}\n",
    "for phrase in phrase_to_id.keys(): \n",
    "    phrase_id = phrase_to_id[phrase]\n",
    "    label = id_to_label[phrase_id]\n",
    "    # Get rid of neutral sentences\n",
    "    if label == 0.0 or label == 1.0:\n",
    "        phrase_to_label[phrase] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "married-extent",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1795, {0.0, 1.0})"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(phrase_to_label), set(phrase_to_label.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "centered-aspect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['with spy kids 2 : the island of lost dreams writer/director/producer robert rodriguez has cobbled together a film that feels like a sugar high gone awry .',\n",
       " 'a very witty take on change , risk and romance , and the film uses humor to make its points about acceptance and growth .',\n",
       " 'once again , director jackson strikes a rewarding balance between emotion on the human scale and action/effects on the spectacular scale .',\n",
       " 'he has not learned that storytelling is what the movies are about .',\n",
       " \"a recent favorite at sundance , this white-trash satire will inspire the affection of even those unlucky people who never owned a cassette of def leppard 's pyromania .\",\n",
       " \"one minute , you think you 're watching a serious actioner ; the next , it 's as though clips from the pink panther strikes again and/or sailor moon have been spliced in .\",\n",
       " 'a teasing drama whose relentless good-deed/bad-deed reversals are just interesting enough to make a sinner like me pray for an even more interesting , less symmetrical , less obviously cross-shaped creation .',\n",
       " \"opens as promising as any war/adventure film you 'll ever see and dissolves into a routine courtroom drama , better suited for a movie titled `` glory : a soldier 's story . ''\",\n",
       " \"a frantic search for laughs , with a hit-to-miss ratio that does n't exactly favor the audience .\",\n",
       " 'collateral damage is , despite its alleged provocation post-9 / 11 , an antique , in the end .',\n",
       " 'the picture , scored by a perversely cheerful marcus miller accordion/harmonica/banjo abomination , is a monument to bad in all its florid variety .',\n",
       " \"a moody horror/thriller elevated by deft staging and the director 's well-known narrative gamesmanship .\",\n",
       " 'an eccentric little comic/thriller deeply in love with its own quirky personality .',\n",
       " 'maguire is a surprisingly effective peter/spider-man .',\n",
       " 'no . .',\n",
       " \"acting , particularly by tambor , almost makes `` never again '' worthwhile , but ( writer/director ) schaeffer should follow his titular advice\",\n",
       " 'earnest but earthbound ... a slow , soggy , soporific , visually dank crime melodrama/character study that would be more at home on the small screen but for its stellar cast .',\n",
       " 'so young , so smart , such talent , such a wise *** .',\n",
       " 'this bold and lyrical first feature from raja amari expands the pat notion that middle-aged women just wan na have fun into a rousing treatise of sensual empowerment .',\n",
       " \"writer/director john mckay ignites some charming chemistry between kate and jed but , when he veers into sodden melodrama , punctuated by violins , it 's disastrous and kate 's jealous female friends become downright despicable .\",\n",
       " 'an imaginative comedy/thriller .']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "missed_sents = [sent for sent in all_sentences if sent not in phrase_to_id.keys()]\n",
    "missed_sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "focused-nickel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are not matched due to british vs american english and some issues with slashes (\\/).\n",
    "missed_ids = [\"150999\", \"18604\", \"26285\", \"223622\", \"24438\", \"225308\", \"24492\", \"225334\", \"143102\", \"222979\", \"149724\", \"24391\", \"143730\", \"26026\", None, \"222185\", \"145027\", \"225842\", \"19357\", \"151070\", \"13851\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cheap-speech",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent, sent_id in zip(missed_sents, missed_ids): \n",
    "    if sent_id:\n",
    "        label = id_to_label[sent_id]\n",
    "        if label == 0.0 or label == 1.0: \n",
    "            phrase_to_label[sent] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "close-shopper",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1815"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(phrase_to_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "random-kidney",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sst2_test_labels.json\", \"w\") as f: \n",
    "    json.dump(phrase_to_label, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
