{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "direct-prototype",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import spacy\n",
    "import wandb\n",
    "import numpy as np\n",
    "processor = spacy.load('en_core_web_sm')\n",
    "\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import json\n",
    "from checklist.test_suite import TestSuite\n",
    "\n",
    "\n",
    "class BatchedInference:\n",
    "    def __init__(self, model, tokenizer, checkpoint_path=None, device=\"cpu\"): \n",
    "        self.model = model\n",
    "        if checkpoint_path: \n",
    "            self.load_model_from_checkpoint(checkpoint_path, device=device)\n",
    "        self.model = self.model.eval()\n",
    "        self.tokenizer = tokenizer\n",
    "        self.softmax = torch.nn.Softmax(dim=-1)\n",
    "        self.device = device\n",
    "        \n",
    "    def __call__(self, batch):\n",
    "        with torch.no_grad():\n",
    "            tokenized_input = self.tokenizer(batch, padding=True)\n",
    "            input_ids = torch.tensor(tokenized_input[\"input_ids\"]).to(self.device)\n",
    "            attention_mask = torch.tensor(tokenized_input[\"attention_mask\"]).to(self.device)\n",
    "            output = self.model(input_ids, attention_mask=attention_mask)\n",
    "            prediction = output.logits.argmax(dim=-1).cpu()\n",
    "            confidence = self.softmax(output.logits).cpu()\n",
    "        return prediction, confidence\n",
    "    \n",
    "    def load_model_from_checkpoint(self, checkpoint_path, device=\"cpu\"): \n",
    "        checkpoint = torch.load(checkpoint_path, map_location=torch.device(device))\n",
    "        model_state_dict = {k.replace(\"module.\", \"\"): v for (k, v) in checkpoint[\"model\"].items()}\n",
    "        self.model.load_state_dict(model_state_dict, strict=False)\n",
    "        self.model.to(device)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_model_name(cls, model_name, checkpoint_path=None, device=\"cpu\"): \n",
    "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "        return cls(model=model, tokenizer=tokenizer, checkpoint_path=checkpoint_path, device=device)\n",
    "    \n",
    "    \n",
    "def save_test_results(config, test_suite): \n",
    "    tests_information = {}\n",
    "    for test in test_suite.tests: \n",
    "        tests_information[test] = {}\n",
    "        samples = test_suite.tests[test].data\n",
    "        predictions = [pred.tolist() for pred in test_suite.tests[test].results[\"preds\"]]\n",
    "        confidences = [conf.tolist() for conf in test_suite.tests[test].results[\"confs\"]]\n",
    "        expect_results = [expect_result.tolist() for expect_result in test_suite.tests[test].results[\"expect_results\"]]\n",
    "        stats = test_suite.tests[test].get_stats()\n",
    "        failures = [test_suite.tests[test].data[idx] for idx in test_suite.tests[test].fail_idxs()]\n",
    "        passed = test_suite.tests[test].results[\"passed\"].tolist()\n",
    "\n",
    "        tests_information[test][\"samples\"] = samples\n",
    "        tests_information[test][\"predictions\"] = predictions\n",
    "        tests_information[test][\"confidences\"] = confidences\n",
    "        tests_information[test][\"expect_results\"] = expect_results\n",
    "        tests_information[test][\"stats\"] = stats\n",
    "        tests_information[test][\"failures\"] = failures\n",
    "        tests_information[test][\"passed\"] = passed\n",
    "\n",
    "        wandb.log({\"test\": test, \"samples\": samples, \"predictions\": predictions, \"confidences\": confidences, \"expect_results\": expect_results, \"stats\": stats, \"failures\": failures, \"passed\": passed})\n",
    "\n",
    "    with open(results_path, \"w\") as f: \n",
    "        json.dump(tests_information, f)\n",
    "\n",
    "    wandb.save(config[\"results_path\"], base_path=\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "automotive-prevention",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_suite_path = \"testset_19_07_21.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-senate",
   "metadata": {},
   "source": [
    "#### Random Seed 0 - Vanilla "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "alert-international",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"albert-large-v2\"\n",
    "checkpoint_path = \"model-outputs/final-models/rs0-shuffle-train/albert-large-v2_6.pt\"\n",
    "pipeline = BatchedInference.from_model_name(\n",
    "    model_name, checkpoint_path=checkpoint_path, device=\"cuda\"\n",
    ")\n",
    "\n",
    "def pred_and_conf(data, batch_size=32):\n",
    "    data = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    for data in data: \n",
    "        preds, confs = pipeline(data)\n",
    "        preds = preds.numpy().tolist()\n",
    "        confs = confs.numpy()\n",
    "        predictions.append(preds)\n",
    "        confidences.append(confs)\n",
    "    predictions = np.hstack(predictions)\n",
    "    confidences = np.vstack(confidences)\n",
    "    return predictions, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "fatty-pursuit",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:39vl6slk) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 9324<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 4.74MB of 4.74MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_103335-39vl6slk/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_103335-39vl6slk/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>test</td><td>used to, but now</td></tr><tr><td>_runtime</td><td>90</td></tr><tr><td>_timestamp</td><td>1626950109</td></tr><tr><td>_step</td><td>17</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_step</td><td>▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">rs0_shuffle_train_6_testset_19_07_21</strong>: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/39vl6slk\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/39vl6slk</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:39vl6slk). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: wandb version 0.11.0 is available!  To upgrade, please run:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.22<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">rs0_shuffle_train_6_testset_19_07_21</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ukh/checklist_evaluation\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/906jycek\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/906jycek</a><br/>\n",
       "                Run data is saved locally in <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_103751-906jycek</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Movie sentiments\n",
      "Predicting 58 examples\n",
      "Running Single positive words\n",
      "Predicting 22 examples\n",
      "Running Single negative words\n",
      "Predicting 14 examples\n",
      "Running Sentiment-laden words in context\n",
      "Predicting 1350 examples\n",
      "Running add positive phrases\n",
      "Predicting 5500 examples\n",
      "Running add negative phrases\n",
      "Predicting 5000 examples\n",
      "Running Simple negations: negative\n",
      "Predicting 1350 examples\n",
      "Running Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Predicting 500 examples\n",
      "Running Movie genre specific sentiments\n",
      "Predicting 736 examples\n",
      "Running Change names\n",
      "Predicting 1617 examples\n",
      "Running Polarizing Negative Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Polarizing Positive Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Negative Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Positive Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Change Movie Industries\n",
      "Predicting 252 examples\n",
      "Running Movie Industries specific sentiments\n",
      "Predicting 1200 examples\n",
      "Running change neutral words with BERT\n",
      "Predicting 3846 examples\n",
      "Running used to, but now\n",
      "Predicting 2152 examples\n"
     ]
    }
   ],
   "source": [
    "results_path = \"results/checklist/rs0_shuffle_train_6_testset_19_07_21.json\"\n",
    "config = {\n",
    "    \"project_name\": \"checklist_evaluation\", \n",
    "    \"run_name\": \"rs0_shuffle_train_6_testset_19_07_21\",\n",
    "    \"model\": \"albert-large-v2\", \n",
    "    \"checkpoint\": checkpoint_path, \n",
    "    \"test_suite\": test_suite_path,\n",
    "    \"results_path\": results_path\n",
    "}\n",
    "wandb.init(config=config, project=config[\"project_name\"], name=config[\"run_name\"])\n",
    "\n",
    "test_suite = TestSuite.from_file(test_suite_path)\n",
    "test_suite.run(pred_and_conf, overwrite=True, seed=0)\n",
    "save_test_results(config, test_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "comic-syracuse",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary\n",
      "\n",
      "Single positive words\n",
      "Test cases:      22\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Single negative words\n",
      "Test cases:      14\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Sentiment-laden words in context\n",
      "Test cases:      1350\n",
      "Fails (rate):    12 (0.9%)\n",
      "\n",
      "Example fails:\n",
      "0.5 I abhorred this actor.\n",
      "----\n",
      "0.5 We abhorred that actor.\n",
      "----\n",
      "0.8 I abhorred that director.\n",
      "----\n",
      "\n",
      "\n",
      "add positive phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    3 (0.6%)\n",
      "\n",
      "Example fails:\n",
      "0.4 The lack of pace kills it , although , in a movie about cancer , this might be apt .\n",
      "0.1 The lack of pace kills it , although , in a movie about cancer , this might be apt. I would watch this again.\n",
      "\n",
      "----\n",
      "0.1 The central story lacks punch .\n",
      "0.0 The central story lacks punch. I would watch this again.\n",
      "\n",
      "----\n",
      "0.9 A very stylish but ultimately extremely silly tale ... a slick piece of nonsense but nothing more .\n",
      "0.1 A very stylish but ultimately extremely silly tale ... a slick piece of nonsense but nothing more. It is good.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "add negative phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    20 (4.0%)\n",
      "\n",
      "Example fails:\n",
      "0.9 Hands down the year 's most thought-provoking film .\n",
      "1.0 Hands down the year 's most thought-provoking film. I abhor it.\n",
      "\n",
      "----\n",
      "0.9 A very stylish but ultimately extremely silly tale ... a slick piece of nonsense but nothing more .\n",
      "1.0 A very stylish but ultimately extremely silly tale ... a slick piece of nonsense but nothing more. I hate it.\n",
      "1.0 A very stylish but ultimately extremely silly tale ... a slick piece of nonsense but nothing more. I despise it.\n",
      "\n",
      "----\n",
      "0.0 Warmed-over Tarantino by way of wannabe Elmore Leonard .\n",
      "0.1 Warmed-over Tarantino by way of wannabe Elmore Leonard. I dread it.\n",
      "0.1 Warmed-over Tarantino by way of wannabe Elmore Leonard. I abhor it.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "change neutral words with BERT\n",
      "Test cases:      500\n",
      "Fails (rate):    47 (9.4%)\n",
      "\n",
      "Example fails:\n",
      "0.2 The Transporter is as lively and as fun as it is unapologetically dumb\n",
      "0.6 Life Transporter is as lively and as fun as it is unapologetically dumb\n",
      "\n",
      "----\n",
      "0.4 Like a south-of-the-border Melrose Place .\n",
      "1.0 Like that south-of-the-border Melrose Place .\n",
      "1.0 Like your south-of-the-border Melrose Place .\n",
      "\n",
      "----\n",
      "1.0 Not so much funny as aggressively sitcom-cute , it 's full of throwaway one-liners , not-quite jokes , and a determined TV amiability that Allen personifies .\n",
      "0.0 Not so much funny as aggressively sitcom-cute , it 's full of throwaway one-liners , not-quite jokes , and un determined TV amiability that Allen personifies .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NER\n",
      "\n",
      "Change names\n",
      "Test cases:      147\n",
      "Fails (rate):    11 (7.5%)\n",
      "\n",
      "Example fails:\n",
      "0.4 Imagine if you will a Tony Hawk skating video interspliced with footage from Behind Enemy Lines and set to Jersey shore techno .\n",
      "0.6 Imagine if you will a Christopher Ross skating video interspliced with footage from Behind Enemy Lines and set to Jersey shore techno .\n",
      "\n",
      "----\n",
      "0.2 And in truth , cruel as it may sound , he makes Arnold Schwarzenegger look like Spencer Tracy .\n",
      "0.8 And in truth , cruel as it may sound , he makes Arnold Schwarzenegger look like Joshua Nelson .\n",
      "0.8 And in truth , cruel as it may sound , he makes Arnold Schwarzenegger look like Christopher Ross .\n",
      "\n",
      "----\n",
      "0.8 I would have preferred a transfer down the hall to Mr. Holland 's class for the music , or to Robin Williams 's lecture so I could listen to a teacher with humor , passion , and verve .\n",
      "0.1 I would have preferred a transfer down the hall to Mr. Holland 's class for the music , or to Melissa Reyes lecture so I could listen to a teacher with humor , passion , and verve .\n",
      "0.1 I would have preferred a transfer down the hall to Mr. Holland 's class for the music , or to Jennifer Cruz lecture so I could listen to a teacher with humor , passion , and verve .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    17 (10.8%)\n",
      "\n",
      "Example fails:\n",
      "0.1 Elling , portrayed with quiet fastidiousness by Per Christian Ellefsen , is a truly singular character , one whose frailties are only slightly magnified versions of the ones that vex nearly everyone .\n",
      "0.5 Elling , portrayed with quiet fastidiousness by Per Crispin Glover , is a truly singular character , one whose frailties are only slightly magnified versions of the ones that vex nearly everyone .\n",
      "\n",
      "----\n",
      "0.4 Who knows what exactly Godard is on about in this film , but his words and images do n't have to add up to mesmerize you .\n",
      "1.0 Who knows what exactly Yvan Attal is on about in this film , but his words and images do n't have to add up to mesmerize you .\n",
      "1.0 Who knows what exactly Michel Gondry is on about in this film , but his words and images do n't have to add up to mesmerize you .\n",
      "\n",
      "----\n",
      "0.4 A sensual performance from Abbass buoys the flimsy story , but her inner journey is largely unexplored and we 're left wondering about this exotic-looking woman whose emotional depths are only hinted at .\n",
      "0.6 A sensual performance from Carol Kane buoys the flimsy story , but her inner journey is largely unexplored and we 're left wondering about this exotic-looking woman whose emotional depths are only hinted at .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    19 (15.4%)\n",
      "\n",
      "Example fails:\n",
      "1.0 Flat , but with a revelatory performance by Michelle Williams .\n",
      "0.1 Flat , but with a revelatory performance by Birot .\n",
      "\n",
      "----\n",
      "0.9 To imagine the life of Harry Potter as a martial arts adventure told by a lobotomized Woody Allen is to have some idea of the fate that lies in store for moviegoers lured to the mediocrity that is Kung Pow : Enter the Fist .\n",
      "0.3 To imagine the life of Harry Potter as a martial arts adventure told by a lobotomized Birot is to have some idea of the fate that lies in store for moviegoers lured to the mediocrity that is Kung Pow : Enter the Fist .\n",
      "\n",
      "----\n",
      "0.5 The only thing in Pauline and Paulette that you have n't seen before is a scene featuring a football field-sized Oriental rug crafted out of millions of vibrant flowers .\n",
      "0.9 The only thing in Smokey Robinson and Paulette that you have n't seen before is a scene featuring a football field-sized Oriental rug crafted out of millions of vibrant flowers .\n",
      "0.9 The only thing in Gosling and Paulette that you have n't seen before is a scene featuring a football field-sized Oriental rug crafted out of millions of vibrant flowers .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    22 (17.9%)\n",
      "\n",
      "Example fails:\n",
      "1.0 Flat , but with a revelatory performance by Michelle Williams .\n",
      "0.1 Flat , but with a revelatory performance by Britney .\n",
      "\n",
      "----\n",
      "0.3 I kept wishing I was watching a documentary about the wartime Navajos and what they accomplished instead of all this specious Hollywood hoo-ha .\n",
      "0.9 I kept wishing I was watching a documentary about the wartime Crispin Glover and what they accomplished instead of all this specious Hollywood hoo-ha .\n",
      "0.7 I kept wishing I was watching a documentary about the wartime Yvan Attal and what they accomplished instead of all this specious Hollywood hoo-ha .\n",
      "\n",
      "----\n",
      "0.0 Oedekerk wrote Patch Adams , for which he should not be forgiven .\n",
      "0.9 Oedekerk wrote Crispin Glover , for which he should not be forgiven .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    11 (7.0%)\n",
      "\n",
      "Example fails:\n",
      "0.8 Whether seen on a 10-inch television screen or at your local multiplex , the edge-of-your-seat , educational antics of Steve Irwin are priceless entertainment .\n",
      "0.4 Whether seen on a 10-inch television screen or at your local multiplex , the edge-of-your-seat , educational antics of Phillip Noyce are priceless entertainment .\n",
      "0.4 Whether seen on a 10-inch television screen or at your local multiplex , the edge-of-your-seat , educational antics of Ellen Pompeo are priceless entertainment .\n",
      "\n",
      "----\n",
      "0.4 A sensual performance from Abbass buoys the flimsy story , but her inner journey is largely unexplored and we 're left wondering about this exotic-looking woman whose emotional depths are only hinted at .\n",
      "0.8 A sensual performance from Gosling buoys the flimsy story , but her inner journey is largely unexplored and we 're left wondering about this exotic-looking woman whose emotional depths are only hinted at .\n",
      "0.7 A sensual performance from Smokey Robinson buoys the flimsy story , but her inner journey is largely unexplored and we 're left wondering about this exotic-looking woman whose emotional depths are only hinted at .\n",
      "\n",
      "----\n",
      "0.7 What you would end up with if you took Orwell , Bradbury , Kafka , George Lucas and the Wachowski Brothers and threw them into a blender .\n",
      "0.4 What you would end up with if you took Orwell , Bradbury , Kafka , Eric and the Wachowski Brothers and threw them into a blender .\n",
      "0.4 What you would end up with if you took Orwell , Bradbury , Kafka , Yong Kang and the Wachowski Brothers and threw them into a blender .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Change Movie Industries\n",
      "Test cases:      18\n",
      "Fails (rate):    3 (16.7%)\n",
      "\n",
      "Example fails:\n",
      "0.2 Home Alone goes Hollywood , a funny premise until the kids start pulling off stunts not even Steven Spielberg would know how to do .\n",
      "0.7 Home Alone goes Aussiewood , a funny premise until the kids start pulling off stunts not even Steven Spielberg would know how to do .\n",
      "0.6 Home Alone goes Taiwood , a funny premise until the kids start pulling off stunts not even Steven Spielberg would know how to do .\n",
      "\n",
      "----\n",
      "0.3 I kept wishing I was watching a documentary about the wartime Navajos and what they accomplished instead of all this specious Hollywood hoo-ha .\n",
      "1.0 I kept wishing I was watching a documentary about the wartime Navajos and what they accomplished instead of all this specious Taiwood hoo-ha .\n",
      "0.9 I kept wishing I was watching a documentary about the wartime Navajos and what they accomplished instead of all this specious Cantonwood hoo-ha .\n",
      "\n",
      "----\n",
      "0.2 Even when foreign directors ... borrow stuff from Hollywood , they invariably shake up the formula and make it more interesting .\n",
      "0.8 Even when foreign directors ... borrow stuff from Tollywood , they invariably shake up the formula and make it more interesting .\n",
      "0.7 Even when foreign directors ... borrow stuff from Aussiewood , they invariably shake up the formula and make it more interesting .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Temporal\n",
      "\n",
      "used to, but now\n",
      "Test cases:      2152\n",
      "Fails (rate):    507 (23.6%)\n",
      "\n",
      "Example fails:\n",
      "0.6 I dislike this movie,  I used to enjoy it.\n",
      "----\n",
      "0.9 In the past I would welcome this movie, although now I despise it.\n",
      "----\n",
      "0.8 I abhor this movie, but in the past I would enjoy it.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Negation\n",
      "\n",
      "Simple negations: negative\n",
      "Test cases:      1350\n",
      "Fails (rate):    240 (17.8%)\n",
      "\n",
      "Example fails:\n",
      "1.0 I would never say I like the show.\n",
      "----\n",
      "1.0 I would never say I love the show.\n",
      "----\n",
      "1.0 I would never say I recommend the movie.\n",
      "----\n",
      "\n",
      "\n",
      "Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Test cases:      500\n",
      "Fails (rate):    459 (91.8%)\n",
      "\n",
      "Example fails:\n",
      "1.0 I don't think, given that we watched a lot, that the director was beautiful.\n",
      "----\n",
      "1.0 I can't say, given all that I've seen over the years, that I welcome that scene.\n",
      "----\n",
      "1.0 I wouldn't say, given all that I've seen over the years, that we welcome this scene.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sentiment\n",
      "\n",
      "Movie genre specific sentiments\n",
      "Test cases:      736\n",
      "Fails (rate):    39 (5.3%)\n",
      "\n",
      "Example fails:\n",
      "0.9 This comedy movie was serious, not rib-tickling\n",
      "----\n",
      "0.7 This drama movie was funny rather than serious\n",
      "----\n",
      "0.9 The drama movie was funny rather than moving\n",
      "----\n",
      "\n",
      "\n",
      "Movie Industries specific sentiments\n",
      "Test cases:      1200\n",
      "Fails (rate):    2 (0.2%)\n",
      "\n",
      "Example fails:\n",
      "0.9 This Aussiewood movie is horrifying\n",
      "----\n",
      "0.6 The Aussiewood movie is horrifying\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Synonym/Antonym\n",
      "\n",
      "Movie sentiments\n",
      "Test cases:      58\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_suite.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "instructional-retailer",
   "metadata": {},
   "source": [
    "#### Random Seed 0 - SWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "graphic-profession",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"albert-large-v2\"\n",
    "checkpoint_path = \"model-outputs/final-models/rs0-swa-linear-60-start2-drop-shuffle/albert-large-v2_7.pt\"\n",
    "pipeline = BatchedInference.from_model_name(\n",
    "    model_name, checkpoint_path=checkpoint_path, device=\"cuda\"\n",
    ")\n",
    "\n",
    "def pred_and_conf(data, batch_size=32):\n",
    "    data = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    for data in data: \n",
    "        preds, confs = pipeline(data)\n",
    "        preds = preds.numpy().tolist()\n",
    "        confs = confs.numpy()\n",
    "        predictions.append(preds)\n",
    "        confidences.append(confs)\n",
    "    predictions = np.hstack(predictions)\n",
    "    confidences = np.vstack(confidences)\n",
    "    return predictions, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "dying-battlefield",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:906jycek) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 9511<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 4.80MB of 4.80MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_103751-906jycek/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_103751-906jycek/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>test</td><td>used to, but now</td></tr><tr><td>_runtime</td><td>90</td></tr><tr><td>_timestamp</td><td>1626950367</td></tr><tr><td>_step</td><td>17</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_step</td><td>▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">rs0_shuffle_train_6_testset_19_07_21</strong>: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/906jycek\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/906jycek</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:906jycek). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: wandb version 0.11.0 is available!  To upgrade, please run:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.22<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">rs0-swa-linear-60-start2-drop-shuffle_7_testset_19_07_21</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ukh/checklist_evaluation\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/dxy5q3z0\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/dxy5q3z0</a><br/>\n",
       "                Run data is saved locally in <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_104102-dxy5q3z0</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Movie sentiments\n",
      "Predicting 58 examples\n",
      "Running Single positive words\n",
      "Predicting 22 examples\n",
      "Running Single negative words\n",
      "Predicting 14 examples\n",
      "Running Sentiment-laden words in context\n",
      "Predicting 1350 examples\n",
      "Running add positive phrases\n",
      "Predicting 5500 examples\n",
      "Running add negative phrases\n",
      "Predicting 5000 examples\n",
      "Running Simple negations: negative\n",
      "Predicting 1350 examples\n",
      "Running Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Predicting 500 examples\n",
      "Running Movie genre specific sentiments\n",
      "Predicting 736 examples\n",
      "Running Change names\n",
      "Predicting 1617 examples\n",
      "Running Polarizing Negative Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Polarizing Positive Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Negative Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Positive Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Change Movie Industries\n",
      "Predicting 252 examples\n",
      "Running Movie Industries specific sentiments\n",
      "Predicting 1200 examples\n",
      "Running change neutral words with BERT\n",
      "Predicting 3846 examples\n",
      "Running used to, but now\n",
      "Predicting 2152 examples\n"
     ]
    }
   ],
   "source": [
    "results_path = \"results/checklist/rs0-swa-linear-60-start2-drop-shuffle_7_testset_19_07_21.json\"\n",
    "config = {\n",
    "    \"project_name\": \"checklist_evaluation\", \n",
    "    \"run_name\": \"rs0-swa-linear-60-start2-drop-shuffle_7_testset_19_07_21\",\n",
    "    \"model\": \"albert-large-v2\", \n",
    "    \"checkpoint\": checkpoint_path, \n",
    "    \"test_suite\": test_suite_path,\n",
    "    \"results_path\": results_path\n",
    "}\n",
    "wandb.init(config=config, project=config[\"project_name\"], name=config[\"run_name\"])\n",
    "\n",
    "test_suite = TestSuite.from_file(test_suite_path)\n",
    "test_suite.run(pred_and_conf, overwrite=True, seed=0)\n",
    "save_test_results(config, test_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "informational-quebec",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary\n",
      "\n",
      "Single positive words\n",
      "Test cases:      22\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Single negative words\n",
      "Test cases:      14\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Sentiment-laden words in context\n",
      "Test cases:      1350\n",
      "Fails (rate):    3 (0.2%)\n",
      "\n",
      "Example fails:\n",
      "0.6 We abhor the show.\n",
      "----\n",
      "0.6 I abhor the show.\n",
      "----\n",
      "0.6 I abhor this director.\n",
      "----\n",
      "\n",
      "\n",
      "add positive phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    4 (0.8%)\n",
      "\n",
      "Example fails:\n",
      "0.8 A very stylish but ultimately extremely silly tale ... a slick piece of nonsense but nothing more .\n",
      "0.7 A very stylish but ultimately extremely silly tale ... a slick piece of nonsense but nothing more. I value it.\n",
      "\n",
      "----\n",
      "0.8 We need ( Moore 's ) noisy , cocky energy , his passion and class consciousness ; we need his shticks , we need his stones .\n",
      "0.7 We need ( Moore 's ) noisy , cocky energy , his passion and class consciousness ; we need his shticks , we need his stones. I would watch this again.\n",
      "\n",
      "----\n",
      "0.5 So routine , familiar and predictable , it raises the possibility that it wrote itself as a newly automated Final Draft computer program .\n",
      "0.4 So routine , familiar and predictable , it raises the possibility that it wrote itself as a newly automated Final Draft computer program. I would watch this again.\n",
      "0.4 So routine , familiar and predictable , it raises the possibility that it wrote itself as a newly automated Final Draft computer program. I recommend it.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "add negative phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    75 (15.0%)\n",
      "\n",
      "Example fails:\n",
      "0.9 Sits uneasily as a horror picture ... but finds surprising depth in its look at the binds of a small family .\n",
      "0.9 Sits uneasily as a horror picture ... but finds surprising depth in its look at the binds of a small family. I abhor it.\n",
      "\n",
      "----\n",
      "0.1 There 's no denying the elaborateness of the artist 's conceptions , nor his ability to depict them with outrageous elan , but really the whole series is so much pretentious nonsense , lavishly praised by those who equate obscurity with profundity .\n",
      "0.3 There 's no denying the elaborateness of the artist 's conceptions , nor his ability to depict them with outrageous elan , but really the whole series is so much pretentious nonsense , lavishly praised by those who equate obscurity with profundity. Never watching this again.\n",
      "\n",
      "----\n",
      "0.2 There 's more scatological action in 8 Crazy Nights than a proctologist is apt to encounter in an entire career .\n",
      "0.4 There 's more scatological action in 8 Crazy Nights than a proctologist is apt to encounter in an entire career. I abhor it.\n",
      "0.3 There 's more scatological action in 8 Crazy Nights than a proctologist is apt to encounter in an entire career. Never watching this again.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "change neutral words with BERT\n",
      "Test cases:      500\n",
      "Fails (rate):    33 (6.6%)\n",
      "\n",
      "Example fails:\n",
      "0.4 As Tweedy talks about canning his stockbroker and repairing his pool , you yearn for a few airborne TV sets or nude groupies on the nod to liven things up .\n",
      "0.5 As Tweedy talks about canning his stockbroker and repairing his pool , critics yearn for a few airborne TV sets or nude groupies on the nod to liven things up .\n",
      "\n",
      "----\n",
      "0.4 We miss the quirky amazement that used to come along for an integral part of the ride .\n",
      "0.6 We miss that quirky amazement that used to come along for an integral part of that ride .\n",
      "0.5 We miss the quirky amazement who used to come along for an integral part of the ride .\n",
      "\n",
      "----\n",
      "0.8 Absorbing and disturbing -- perhaps more disturbing than originally intended -- but a little clarity would have gone a long way .\n",
      "0.1 Absorbing was disturbing -- perhaps more disturbing than originally intended -- but a little clarity would have gone a long way .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NER\n",
      "\n",
      "Change names\n",
      "Test cases:      147\n",
      "Fails (rate):    8 (5.4%)\n",
      "\n",
      "Example fails:\n",
      "0.6 Never quite transcends jokester status ... and the punchline does n't live up to Barry 's dead-eyed , perfectly chilled delivery .\n",
      "0.4 Never quite transcends jokester status ... and the punchline does n't live up to Aiden 's dead-eyed , perfectly chilled delivery .\n",
      "0.4 Never quite transcends jokester status ... and the punchline does n't live up to Austin 's dead-eyed , perfectly chilled delivery .\n",
      "\n",
      "----\n",
      "0.7 Whether seen on a 10-inch television screen or at your local multiplex , the edge-of-your-seat , educational antics of Steve Irwin are priceless entertainment .\n",
      "0.5 Whether seen on a 10-inch television screen or at your local multiplex , the edge-of-your-seat , educational antics of David Taylor are priceless entertainment .\n",
      "0.5 Whether seen on a 10-inch television screen or at your local multiplex , the edge-of-your-seat , educational antics of Matthew Ross are priceless entertainment .\n",
      "\n",
      "----\n",
      "0.9 Not so much funny as aggressively sitcom-cute , it 's full of throwaway one-liners , not-quite jokes , and a determined TV amiability that Allen personifies .\n",
      "0.1 Not so much funny as aggressively sitcom-cute , it 's full of throwaway one-liners , not-quite jokes , and a determined TV amiability that Luke personifies .\n",
      "0.1 Not so much funny as aggressively sitcom-cute , it 's full of throwaway one-liners , not-quite jokes , and a determined TV amiability that Luke personifies .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    6 (3.8%)\n",
      "\n",
      "Example fails:\n",
      "0.4 Roman Coppola may never become the filmmaker his Dad was , but heck -- few filmmakers will .\n",
      "0.6 Yvan Attal may never become the filmmaker his Dad was , but heck -- few filmmakers will .\n",
      "0.5 Mat Hoffman may never become the filmmaker his Dad was , but heck -- few filmmakers will .\n",
      "\n",
      "----\n",
      "0.7 Whether seen on a 10-inch television screen or at your local multiplex , the edge-of-your-seat , educational antics of Steve Irwin are priceless entertainment .\n",
      "0.2 Whether seen on a 10-inch television screen or at your local multiplex , the edge-of-your-seat , educational antics of Jelinek are priceless entertainment .\n",
      "0.3 Whether seen on a 10-inch television screen or at your local multiplex , the edge-of-your-seat , educational antics of Britney are priceless entertainment .\n",
      "\n",
      "----\n",
      "0.6 It is so refreshing to see Robin Williams turn 180 degrees from the string of insultingly innocuous and sappy fiascoes he 's been making for the last several years .\n",
      "0.3 It is so refreshing to see Jelinek turn 180 degrees from the string of insultingly innocuous and sappy fiascoes he 's been making for the last several years .\n",
      "0.3 It is so refreshing to see Britney turn 180 degrees from the string of insultingly innocuous and sappy fiascoes he 's been making for the last several years .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    17 (13.8%)\n",
      "\n",
      "Example fails:\n",
      "0.3 Jolie 's performance vanishes somewhere between her hair and her lips .\n",
      "0.8 Merchant Ivory 's performance vanishes somewhere between her hair and her lips .\n",
      "0.7 Walt Becker 's performance vanishes somewhere between her hair and her lips .\n",
      "\n",
      "----\n",
      "0.4 And in truth , cruel as it may sound , he makes Arnold Schwarzenegger look like Spencer Tracy .\n",
      "0.8 And in truth , cruel as it may sound , he makes Arnold Schwarzenegger look like Eric .\n",
      "0.7 And in truth , cruel as it may sound , he makes Arnold Schwarzenegger look like Hélène Angel .\n",
      "\n",
      "----\n",
      "0.3 Adam Sandler is to Gary Cooper what a gnat is to a racehorse .\n",
      "0.7 Adam Sandler is to Hélène Angel what a gnat is to a racehorse .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    15 (12.2%)\n",
      "\n",
      "Example fails:\n",
      "0.0 Never mind whether you buy the stuff about Barris being a CIA hit man .\n",
      "0.8 Never mind whether you buy the stuff about Einstein being a CIA hit man .\n",
      "\n",
      "----\n",
      "0.3 Adam Sandler is to Gary Cooper what a gnat is to a racehorse .\n",
      "0.7 Adam Sandler is to Seagal what a gnat is to a racehorse .\n",
      "0.5 Michel Gondry is to Gary Cooper what a gnat is to a racehorse .\n",
      "\n",
      "----\n",
      "0.7 Ethan Hawke has always fancied himself the bastard child of the Beatnik generation and it 's all over his Chelsea Walls .\n",
      "0.1 Paul Pender has always fancied himself the bastard child of the Beatnik generation and it 's all over his Chelsea Walls .\n",
      "0.1 Yvan Attal has always fancied himself the bastard child of the Beatnik generation and it 's all over his Chelsea Walls .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    6 (3.8%)\n",
      "\n",
      "Example fails:\n",
      "0.4 Roman Coppola may never become the filmmaker his Dad was , but heck -- few filmmakers will .\n",
      "0.5 Carl Franklin may never become the filmmaker his Dad was , but heck -- few filmmakers will .\n",
      "\n",
      "----\n",
      "0.6 It is so refreshing to see Robin Williams turn 180 degrees from the string of insultingly innocuous and sappy fiascoes he 's been making for the last several years .\n",
      "0.3 It is so refreshing to see Gosling turn 180 degrees from the string of insultingly innocuous and sappy fiascoes he 's been making for the last several years .\n",
      "0.4 It is so refreshing to see Birot turn 180 degrees from the string of insultingly innocuous and sappy fiascoes he 's been making for the last several years .\n",
      "\n",
      "----\n",
      "0.7 Whether seen on a 10-inch television screen or at your local multiplex , the edge-of-your-seat , educational antics of Steve Irwin are priceless entertainment .\n",
      "0.2 Whether seen on a 10-inch television screen or at your local multiplex , the edge-of-your-seat , educational antics of Ellen Pompeo are priceless entertainment .\n",
      "0.3 Whether seen on a 10-inch television screen or at your local multiplex , the edge-of-your-seat , educational antics of Birot are priceless entertainment .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Change Movie Industries\n",
      "Test cases:      18\n",
      "Fails (rate):    1 (5.6%)\n",
      "\n",
      "Example fails:\n",
      "0.6 Home Alone goes Hollywood , a funny premise until the kids start pulling off stunts not even Steven Spielberg would know how to do .\n",
      "0.1 Home Alone goes Ghollywood , a funny premise until the kids start pulling off stunts not even Steven Spielberg would know how to do .\n",
      "0.1 Home Alone goes Nollywood , a funny premise until the kids start pulling off stunts not even Steven Spielberg would know how to do .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Temporal\n",
      "\n",
      "used to, but now\n",
      "Test cases:      2152\n",
      "Fails (rate):    432 (20.1%)\n",
      "\n",
      "Example fails:\n",
      "0.5 I used to love this movie, even though now I regret it.\n",
      "----\n",
      "0.8 I abhor this movie, even though in the past I would love it.\n",
      "----\n",
      "0.4 I used to dread this movie, even though now I recommend it.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Negation\n",
      "\n",
      "Simple negations: negative\n",
      "Test cases:      1350\n",
      "Fails (rate):    150 (11.1%)\n",
      "\n",
      "Example fails:\n",
      "0.8 I would never say I like that movie.\n",
      "----\n",
      "0.9 I can't say I appreciate this director.\n",
      "----\n",
      "1.0 I can't say I love the scene.\n",
      "----\n",
      "\n",
      "\n",
      "Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Test cases:      500\n",
      "Fails (rate):    469 (93.8%)\n",
      "\n",
      "Example fails:\n",
      "0.7 I don't think, given it's a Friday, that that movie was wonderful.\n",
      "----\n",
      "0.7 I wouldn't say, given my history with movies, that we value that movie.\n",
      "----\n",
      "0.9 I wouldn't say, given my history with movies, that the is a fantastic director.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sentiment\n",
      "\n",
      "Movie genre specific sentiments\n",
      "Test cases:      736\n",
      "Fails (rate):    33 (4.5%)\n",
      "\n",
      "Example fails:\n",
      "1.0 The comedy movie was serious\n",
      "----\n",
      "0.0 This horror movie was frightening\n",
      "----\n",
      "1.0 This horror movie was calming\n",
      "----\n",
      "\n",
      "\n",
      "Movie Industries specific sentiments\n",
      "Test cases:      1200\n",
      "Fails (rate):    1 (0.1%)\n",
      "\n",
      "Example fails:\n",
      "0.5 The Aussiewood movie is horrifying\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Synonym/Antonym\n",
      "\n",
      "Movie sentiments\n",
      "Test cases:      58\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_suite.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-vinyl",
   "metadata": {},
   "source": [
    "#### Random Seed 1 - Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "empirical-phoenix",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"albert-large-v2\"\n",
    "checkpoint_path = \"model-outputs/final-models/rs1-shuffle-train/albert-large-v2_2.pt\"\n",
    "pipeline = BatchedInference.from_model_name(\n",
    "    model_name, checkpoint_path=checkpoint_path, device=\"cuda\"\n",
    ")\n",
    "\n",
    "def pred_and_conf(data, batch_size=32):\n",
    "    data = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    for data in data: \n",
    "        preds, confs = pipeline(data)\n",
    "        preds = preds.numpy().tolist()\n",
    "        confs = confs.numpy()\n",
    "        predictions.append(preds)\n",
    "        confidences.append(confs)\n",
    "    predictions = np.hstack(predictions)\n",
    "    confidences = np.vstack(confidences)\n",
    "    return predictions, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "cheap-silly",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:dxy5q3z0) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 9693<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 4.79MB of 4.79MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_104102-dxy5q3z0/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_104102-dxy5q3z0/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>test</td><td>used to, but now</td></tr><tr><td>_runtime</td><td>91</td></tr><tr><td>_timestamp</td><td>1626950556</td></tr><tr><td>_step</td><td>17</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_step</td><td>▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">rs0-swa-linear-60-start2-drop-shuffle_7_testset_19_07_21</strong>: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/dxy5q3z0\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/dxy5q3z0</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:dxy5q3z0). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: wandb version 0.11.0 is available!  To upgrade, please run:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.22<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">rs1_shuffle_train_2_testset_19_07_21</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ukh/checklist_evaluation\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/2559rvxq\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/2559rvxq</a><br/>\n",
       "                Run data is saved locally in <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_104239-2559rvxq</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Movie sentiments\n",
      "Predicting 58 examples\n",
      "Running Single positive words\n",
      "Predicting 22 examples\n",
      "Running Single negative words\n",
      "Predicting 14 examples\n",
      "Running Sentiment-laden words in context\n",
      "Predicting 1350 examples\n",
      "Running add positive phrases\n",
      "Predicting 5500 examples\n",
      "Running add negative phrases\n",
      "Predicting 5000 examples\n",
      "Running Simple negations: negative\n",
      "Predicting 1350 examples\n",
      "Running Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Predicting 500 examples\n",
      "Running Movie genre specific sentiments\n",
      "Predicting 736 examples\n",
      "Running Change names\n",
      "Predicting 1617 examples\n",
      "Running Polarizing Negative Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Polarizing Positive Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Negative Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Positive Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Change Movie Industries\n",
      "Predicting 252 examples\n",
      "Running Movie Industries specific sentiments\n",
      "Predicting 1200 examples\n",
      "Running change neutral words with BERT\n",
      "Predicting 3846 examples\n",
      "Running used to, but now\n",
      "Predicting 2152 examples\n"
     ]
    }
   ],
   "source": [
    "results_path = \"results/checklist/rs1_shuffle_train_2_testset_19_07_21.json\"\n",
    "config = {\n",
    "    \"project_name\": \"checklist_evaluation\", \n",
    "    \"run_name\": \"rs1_shuffle_train_2_testset_19_07_21\",\n",
    "    \"model\": \"albert-large-v2\", \n",
    "    \"checkpoint\": checkpoint_path, \n",
    "    \"test_suite\": test_suite_path,\n",
    "    \"results_path\": results_path\n",
    "}\n",
    "wandb.init(config=config, project=config[\"project_name\"], name=config[\"run_name\"])\n",
    "\n",
    "test_suite = TestSuite.from_file(test_suite_path)\n",
    "test_suite.run(pred_and_conf, overwrite=True, seed=0)\n",
    "save_test_results(config, test_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "instant-following",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary\n",
      "\n",
      "Single positive words\n",
      "Test cases:      22\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Single negative words\n",
      "Test cases:      14\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Sentiment-laden words in context\n",
      "Test cases:      1350\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add positive phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add negative phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    3 (0.6%)\n",
      "\n",
      "Example fails:\n",
      "0.1 Too bad the former Murphy Brown does n't pop Reese back .\n",
      "0.2 Too bad the former Murphy Brown does n't pop Reese back. I regret it.\n",
      "\n",
      "----\n",
      "0.0 Edited and shot with a syncopated style mimicking the work of his subjects , Pray turns the idea of the documentary on its head , making it rousing , invigorating fun lacking any MTV puffery .\n",
      "0.1 Edited and shot with a syncopated style mimicking the work of his subjects , Pray turns the idea of the documentary on its head , making it rousing , invigorating fun lacking any MTV puffery. I abhor it.\n",
      "0.1 Edited and shot with a syncopated style mimicking the work of his subjects , Pray turns the idea of the documentary on its head , making it rousing , invigorating fun lacking any MTV puffery. I dread it.\n",
      "\n",
      "----\n",
      "0.2 Roger Michell , who did an appealing job directing Persuasion and Notting Hill in England , gets too artsy in his American debut .\n",
      "0.3 Roger Michell , who did an appealing job directing Persuasion and Notting Hill in England , gets too artsy in his American debut. I regret it.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "change neutral words with BERT\n",
      "Test cases:      500\n",
      "Fails (rate):    36 (7.2%)\n",
      "\n",
      "Example fails:\n",
      "0.2 Japan 's premier stylist of sex and blood hits audiences with what may be his most demented film to date .\n",
      "0.6 Japan 's premier stylist blending sex and blood hits audiences with what may be his most demented film to date .\n",
      "0.5 Japan 's premier stylist with sex and blood hits audiences with what may be his most demented film to date .\n",
      "\n",
      "----\n",
      "0.3 An unbelievably fun film just a leading man away from perfection .\n",
      "0.9 An unbelievably fun film just about leading man away from perfection .\n",
      "0.8 An unbelievably fun film just two leading man away from perfection .\n",
      "\n",
      "----\n",
      "0.6 This is how you use special effects .\n",
      "0.2 This is how people use special effects .\n",
      "0.4 This is how they use special effects .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NER\n",
      "\n",
      "Change names\n",
      "Test cases:      147\n",
      "Fails (rate):    4 (2.7%)\n",
      "\n",
      "Example fails:\n",
      "0.4 Based on a David Leavitt story , the film shares that writer 's usual blend of observant cleverness , too-facile coincidence and slightly noxious preciousness .\n",
      "0.5 Based on a John Bailey story , the film shares that writer 's usual blend of observant cleverness , too-facile coincidence and slightly noxious preciousness .\n",
      "\n",
      "----\n",
      "0.7 De Niro may enjoy the same free ride from critics afforded to Clint Eastwood in the lazy Bloodwork .\n",
      "0.4 De Niro may enjoy the same free ride from critics afforded to Daniel Sanders in the lazy Bloodwork .\n",
      "0.5 De Niro may enjoy the same free ride from critics afforded to James Rivera in the lazy Bloodwork .\n",
      "\n",
      "----\n",
      "0.2 ( Howard ) so good as Leon Barlow ... that he hardly seems to be acting .\n",
      "0.5 ( Howard ) so good as James Rivera ... that he hardly seems to be acting .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    3 (1.9%)\n",
      "\n",
      "Example fails:\n",
      "0.3 For Benigni it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.7 For Yvan Attal it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.7 For Crispin Glover it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "\n",
      "----\n",
      "0.8 When your leading ladies are a couple of screen-eating dominatrixes like Goldie Hawn and Susan Sarandon at their raunchy best , even hokum goes down easily .\n",
      "0.3 When your leading ladies are a couple of screen-eating dominatrixes like Goldie Hawn and Britney at their raunchy best , even hokum goes down easily .\n",
      "\n",
      "----\n",
      "0.5 Wasabi is slight fare indeed , with the entire project having the feel of something tossed off quickly ( like one of Hubert 's punches ) , but it should go down smoothly enough with popcorn .\n",
      "0.4 Wasabi is slight fare indeed , with the entire project having the feel of something tossed off quickly ( like one of Adam Rifkin 's punches ) , but it should go down smoothly enough with popcorn .\n",
      "0.4 Wasabi is slight fare indeed , with the entire project having the feel of something tossed off quickly ( like one of Britney 's punches ) , but it should go down smoothly enough with popcorn .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    4 (3.3%)\n",
      "\n",
      "Example fails:\n",
      "0.4 The only thing in Pauline and Paulette that you have n't seen before is a scene featuring a football field-sized Oriental rug crafted out of millions of vibrant flowers .\n",
      "0.6 The only thing in Ellen Pompeo and Paulette that you have n't seen before is a scene featuring a football field-sized Oriental rug crafted out of millions of vibrant flowers .\n",
      "0.6 The only thing in Carl Franklin and Paulette that you have n't seen before is a scene featuring a football field-sized Oriental rug crafted out of millions of vibrant flowers .\n",
      "\n",
      "----\n",
      "0.7 De Niro may enjoy the same free ride from critics afforded to Clint Eastwood in the lazy Bloodwork .\n",
      "0.2 Birot may enjoy the same free ride from critics afforded to Clint Eastwood in the lazy Bloodwork .\n",
      "0.2 De Niro may enjoy the same free ride from critics afforded to Gulpilil in the lazy Bloodwork .\n",
      "\n",
      "----\n",
      "0.2 As written by Michael Berg and Michael J. Wilson from a story by Wilson , this relentless , all-wise-guys-all-the-time approach tries way too hard and gets tiring in no time at all .\n",
      "0.6 As written by Michael Berg and Eric from a story by Wilson , this relentless , all-wise-guys-all-the-time approach tries way too hard and gets tiring in no time at all .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    6 (4.9%)\n",
      "\n",
      "Example fails:\n",
      "0.7 De Niro may enjoy the same free ride from critics afforded to Clint Eastwood in the lazy Bloodwork .\n",
      "0.5 De Niro may enjoy the same free ride from critics afforded to Roberts in the lazy Bloodwork .\n",
      "0.5 Einstein may enjoy the same free ride from critics afforded to Clint Eastwood in the lazy Bloodwork .\n",
      "\n",
      "----\n",
      "0.4 The only thing in Pauline and Paulette that you have n't seen before is a scene featuring a football field-sized Oriental rug crafted out of millions of vibrant flowers .\n",
      "0.6 The only thing in Adam Rifkin and Paulette that you have n't seen before is a scene featuring a football field-sized Oriental rug crafted out of millions of vibrant flowers .\n",
      "0.6 The only thing in Carol Kane and Paulette that you have n't seen before is a scene featuring a football field-sized Oriental rug crafted out of millions of vibrant flowers .\n",
      "\n",
      "----\n",
      "0.2 As written by Michael Berg and Michael J. Wilson from a story by Wilson , this relentless , all-wise-guys-all-the-time approach tries way too hard and gets tiring in no time at all .\n",
      "0.6 As written by Michael Berg and Sarah from a story by Wilson , this relentless , all-wise-guys-all-the-time approach tries way too hard and gets tiring in no time at all .\n",
      "0.5 As written by Michael Berg and Roberts from a story by Wilson , this relentless , all-wise-guys-all-the-time approach tries way too hard and gets tiring in no time at all .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    5 (3.2%)\n",
      "\n",
      "Example fails:\n",
      "0.5 Wasabi is slight fare indeed , with the entire project having the feel of something tossed off quickly ( like one of Hubert 's punches ) , but it should go down smoothly enough with popcorn .\n",
      "0.4 Wasabi is slight fare indeed , with the entire project having the feel of something tossed off quickly ( like one of Ellen Pompeo 's punches ) , but it should go down smoothly enough with popcorn .\n",
      "0.4 Wasabi is slight fare indeed , with the entire project having the feel of something tossed off quickly ( like one of Birot 's punches ) , but it should go down smoothly enough with popcorn .\n",
      "\n",
      "----\n",
      "1.0 Steve Irwin 's method is Ernest Hemmingway at accelerated speed and volume .\n",
      "0.4 Steve Irwin 's method is Birot at accelerated speed and volume .\n",
      "\n",
      "----\n",
      "0.6 ( Villeneuve ) seems to realize intuitively that even morality is reduced to an option by the ultimate mysteries of life and death .\n",
      "0.3 ( Birot ) seems to realize intuitively that even morality is reduced to an option by the ultimate mysteries of life and death .\n",
      "0.4 ( Merchant Ivory ) seems to realize intuitively that even morality is reduced to an option by the ultimate mysteries of life and death .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Change Movie Industries\n",
      "Test cases:      18\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Temporal\n",
      "\n",
      "used to, but now\n",
      "Test cases:      2152\n",
      "Fails (rate):    167 (7.8%)\n",
      "\n",
      "Example fails:\n",
      "0.3 I like this movie, but I used to regret it.\n",
      "----\n",
      "0.2 I value this movie, but I used to dislike it.\n",
      "----\n",
      "0.8 I abhor this movie, but I used to appreciate it.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Negation\n",
      "\n",
      "Simple negations: negative\n",
      "Test cases:      1350\n",
      "Fails (rate):    4 (0.3%)\n",
      "\n",
      "Example fails:\n",
      "0.7 I can't say I appreciate this director.\n",
      "----\n",
      "0.6 I can't say I appreciate that actor.\n",
      "----\n",
      "0.8 I can't say I appreciate that director.\n",
      "----\n",
      "\n",
      "\n",
      "Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Test cases:      500\n",
      "Fails (rate):    44 (8.8%)\n",
      "\n",
      "Example fails:\n",
      "0.5 I wouldn't say, given that I bought it last week, that we love the director.\n",
      "----\n",
      "0.9 I can't say, given that we watched a lot, that the was a beautiful director.\n",
      "----\n",
      "0.8 I don't think, given that I bought it last week, that we appreciate the show.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sentiment\n",
      "\n",
      "Movie genre specific sentiments\n",
      "Test cases:      736\n",
      "Fails (rate):    40 (5.4%)\n",
      "\n",
      "Example fails:\n",
      "0.0 This horror movie was terrifying\n",
      "----\n",
      "0.0 The horror movie is scary\n",
      "----\n",
      "0.0 This horror movie is frightening\n",
      "----\n",
      "\n",
      "\n",
      "Movie Industries specific sentiments\n",
      "Test cases:      1200\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Synonym/Antonym\n",
      "\n",
      "Movie sentiments\n",
      "Test cases:      58\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_suite.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-addition",
   "metadata": {},
   "source": [
    "#### Random Seed 1 - SWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "floral-track",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"albert-large-v2\"\n",
    "checkpoint_path = \"model-outputs/final-models/rs1-swa-linear-75-start2-drop-shuffle/albert-large-v2_4.pt\"\n",
    "pipeline = BatchedInference.from_model_name(\n",
    "    model_name, checkpoint_path=checkpoint_path, device=\"cuda\"\n",
    ")\n",
    "\n",
    "def pred_and_conf(data, batch_size=32):\n",
    "    data = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    for data in data: \n",
    "        preds, confs = pipeline(data)\n",
    "        preds = preds.numpy().tolist()\n",
    "        confs = confs.numpy()\n",
    "        predictions.append(preds)\n",
    "        confidences.append(confs)\n",
    "    predictions = np.hstack(predictions)\n",
    "    confidences = np.vstack(confidences)\n",
    "    return predictions, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "outstanding-telescope",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2559rvxq) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 9738<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 4.61MB of 4.61MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_104239-2559rvxq/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_104239-2559rvxq/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>test</td><td>used to, but now</td></tr><tr><td>_runtime</td><td>93</td></tr><tr><td>_timestamp</td><td>1626950656</td></tr><tr><td>_step</td><td>17</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>▁▁▁▁▁█████████████</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁█████████████</td></tr><tr><td>_step</td><td>▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">rs1_shuffle_train_2_testset_19_07_21</strong>: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/2559rvxq\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/2559rvxq</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2559rvxq). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: wandb version 0.11.0 is available!  To upgrade, please run:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.22<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">rs1-swa-linear-75-start2-drop-shuffle_4_testset_19_07_21</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ukh/checklist_evaluation\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/ap1v4h5f\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/ap1v4h5f</a><br/>\n",
       "                Run data is saved locally in <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_104418-ap1v4h5f</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Movie sentiments\n",
      "Predicting 58 examples\n",
      "Running Single positive words\n",
      "Predicting 22 examples\n",
      "Running Single negative words\n",
      "Predicting 14 examples\n",
      "Running Sentiment-laden words in context\n",
      "Predicting 1350 examples\n",
      "Running add positive phrases\n",
      "Predicting 5500 examples\n",
      "Running add negative phrases\n",
      "Predicting 5000 examples\n",
      "Running Simple negations: negative\n",
      "Predicting 1350 examples\n",
      "Running Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Predicting 500 examples\n",
      "Running Movie genre specific sentiments\n",
      "Predicting 736 examples\n",
      "Running Change names\n",
      "Predicting 1617 examples\n",
      "Running Polarizing Negative Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Polarizing Positive Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Negative Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Positive Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Change Movie Industries\n",
      "Predicting 252 examples\n",
      "Running Movie Industries specific sentiments\n",
      "Predicting 1200 examples\n",
      "Running change neutral words with BERT\n",
      "Predicting 3846 examples\n",
      "Running used to, but now\n",
      "Predicting 2152 examples\n"
     ]
    }
   ],
   "source": [
    "results_path = \"results/checklist/rs1_rs1-swa-linear-75-start2-drop-shuffle_4_testset_19_07_21.json\"\n",
    "config = {\n",
    "    \"project_name\": \"checklist_evaluation\", \n",
    "    \"run_name\": \"rs1-swa-linear-75-start2-drop-shuffle_4_testset_19_07_21\",\n",
    "    \"model\": \"albert-large-v2\", \n",
    "    \"checkpoint\": checkpoint_path, \n",
    "    \"test_suite\": test_suite_path,\n",
    "    \"results_path\": results_path\n",
    "}\n",
    "wandb.init(config=config, project=config[\"project_name\"], name=config[\"run_name\"])\n",
    "\n",
    "test_suite = TestSuite.from_file(test_suite_path)\n",
    "test_suite.run(pred_and_conf, overwrite=True, seed=0)\n",
    "save_test_results(config, test_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "golden-madagascar",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary\n",
      "\n",
      "Single positive words\n",
      "Test cases:      22\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Single negative words\n",
      "Test cases:      14\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Sentiment-laden words in context\n",
      "Test cases:      1350\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add positive phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add negative phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "change neutral words with BERT\n",
      "Test cases:      500\n",
      "Fails (rate):    39 (7.8%)\n",
      "\n",
      "Example fails:\n",
      "0.9 There 's a disreputable air about the whole thing , and that 's what makes it irresistible .\n",
      "0.3 There 's a disreputable air about the whole thing , maybe that 's what makes it irresistible .\n",
      "\n",
      "----\n",
      "0.8 In its ragged , cheap and unassuming way , the movie works .\n",
      "0.0 In its ragged , cheap and unassuming way , the above works .\n",
      "0.2 In its ragged , cheap and unassuming way , the code works .\n",
      "\n",
      "----\n",
      "0.3 A film of precious increments artfully camouflaged as everyday activities .\n",
      "1.0 A film capturing precious increments artfully camouflaged as everyday activities .\n",
      "0.5 speed film of precious increments artfully camouflaged as everyday activities .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NER\n",
      "\n",
      "Change names\n",
      "Test cases:      147\n",
      "Fails (rate):    4 (2.7%)\n",
      "\n",
      "Example fails:\n",
      "0.8 De Niro may enjoy the same free ride from critics afforded to Clint Eastwood in the lazy Bloodwork .\n",
      "0.4 De Niro may enjoy the same free ride from critics afforded to Daniel Sanders in the lazy Bloodwork .\n",
      "0.4 De Niro may enjoy the same free ride from critics afforded to Michael Ward in the lazy Bloodwork .\n",
      "\n",
      "----\n",
      "0.7 Has it ever been possible to say that Williams has truly inhabited a character ?\n",
      "0.4 Has it ever been possible to say that Luke has truly inhabited a character ?\n",
      "0.4 Has it ever been possible to say that Luke has truly inhabited a character ?\n",
      "\n",
      "----\n",
      "0.7 Flat , but with a revelatory performance by Michelle Williams .\n",
      "0.5 Flat , but with a revelatory performance by Ashley Ross .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    6 (4.9%)\n",
      "\n",
      "Example fails:\n",
      "0.4 Adam Sandler is to Gary Cooper what a gnat is to a racehorse .\n",
      "0.6 Adam Sandler is to Hélène Angel what a gnat is to a racehorse .\n",
      "\n",
      "----\n",
      "0.7 Cho 's fans are sure to be entertained ; it 's only fair in the interest of full disclosure to say that -- on the basis of this film alone -- I 'm not one of them .\n",
      "0.5 Ellen Pompeo 's fans are sure to be entertained ; it 's only fair in the interest of full disclosure to say that -- on the basis of this film alone -- I 'm not one of them .\n",
      "0.5 Gosling 's fans are sure to be entertained ; it 's only fair in the interest of full disclosure to say that -- on the basis of this film alone -- I 'm not one of them .\n",
      "\n",
      "----\n",
      "0.5 Imagine if you will a Tony Hawk skating video interspliced with footage from Behind Enemy Lines and set to Jersey shore techno .\n",
      "0.3 Imagine if you will a Birot skating video interspliced with footage from Behind Enemy Lines and set to Jersey shore techno .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    5 (4.1%)\n",
      "\n",
      "Example fails:\n",
      "0.7 Cho 's fans are sure to be entertained ; it 's only fair in the interest of full disclosure to say that -- on the basis of this film alone -- I 'm not one of them .\n",
      "0.5 Michel Gondry 's fans are sure to be entertained ; it 's only fair in the interest of full disclosure to say that -- on the basis of this film alone -- I 'm not one of them .\n",
      "0.5 Mat Hoffman 's fans are sure to be entertained ; it 's only fair in the interest of full disclosure to say that -- on the basis of this film alone -- I 'm not one of them .\n",
      "\n",
      "----\n",
      "0.5 Imagine if you will a Tony Hawk skating video interspliced with footage from Behind Enemy Lines and set to Jersey shore techno .\n",
      "0.3 Imagine if you will a Britney skating video interspliced with footage from Behind Enemy Lines and set to Jersey shore techno .\n",
      "\n",
      "----\n",
      "0.4 Adam Sandler is to Gary Cooper what a gnat is to a racehorse .\n",
      "0.5 Michel Gondry is to Gary Cooper what a gnat is to a racehorse .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    2 (1.3%)\n",
      "\n",
      "Example fails:\n",
      "0.7 As lo-fi as the special effects are , the folks who cobbled Nemesis together indulge the force of humanity over hardware in a way that George Lucas has long forgotten .\n",
      "0.3 As lo-fi as the special effects are , the folks who cobbled Nemesis together indulge the force of humanity over hardware in a way that Gosling has long forgotten .\n",
      "\n",
      "----\n",
      "0.9 More honest about Alzheimer 's disease , I think , than Iris .\n",
      "0.4 More honest about Alzheimer 's disease , I think , than Gosling .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Change Movie Industries\n",
      "Test cases:      18\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Temporal\n",
      "\n",
      "used to, but now\n",
      "Test cases:      2152\n",
      "Fails (rate):    115 (5.3%)\n",
      "\n",
      "Example fails:\n",
      "0.2 I like this movie, but I used to hate it.\n",
      "----\n",
      "0.7 I abhor this movie, but I used to value it.\n",
      "----\n",
      "0.2 I like this movie, but I used to despise it.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Negation\n",
      "\n",
      "Simple negations: negative\n",
      "Test cases:      1350\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Test cases:      500\n",
      "Fails (rate):    37 (7.4%)\n",
      "\n",
      "Example fails:\n",
      "0.6 I can't say, given all that I've seen over the years, that this movie is fantastic.\n",
      "----\n",
      "0.6 I wouldn't say, given that I bought it last week, that this actor is brilliant.\n",
      "----\n",
      "0.8 I can't say, given it's a Friday, that we appreciate that show.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sentiment\n",
      "\n",
      "Movie genre specific sentiments\n",
      "Test cases:      736\n",
      "Fails (rate):    39 (5.3%)\n",
      "\n",
      "Example fails:\n",
      "0.7 This comedy movie is serious, not light-hearted\n",
      "----\n",
      "1.0 This comedy movie is serious, not rib-tickling\n",
      "----\n",
      "0.2 The horror movie is frightening\n",
      "----\n",
      "\n",
      "\n",
      "Movie Industries specific sentiments\n",
      "Test cases:      1200\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Synonym/Antonym\n",
      "\n",
      "Movie sentiments\n",
      "Test cases:      58\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_suite.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-activity",
   "metadata": {},
   "source": [
    "#### Random Seed 2 - Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "incredible-marks",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"albert-large-v2\"\n",
    "checkpoint_path = \"model-outputs/final-models/rs2-shuffle-train/albert-large-v2_5.pt\"\n",
    "pipeline = BatchedInference.from_model_name(\n",
    "    model_name, checkpoint_path=checkpoint_path, device=\"cuda\"\n",
    ")\n",
    "\n",
    "def pred_and_conf(data, batch_size=32):\n",
    "    data = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    for data in data: \n",
    "        preds, confs = pipeline(data)\n",
    "        preds = preds.numpy().tolist()\n",
    "        confs = confs.numpy()\n",
    "        predictions.append(preds)\n",
    "        confidences.append(confs)\n",
    "    predictions = np.hstack(predictions)\n",
    "    confidences = np.vstack(confidences)\n",
    "    return predictions, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "cross-schedule",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:ap1v4h5f) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 9780<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 4.60MB of 4.60MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_104418-ap1v4h5f/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_104418-ap1v4h5f/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>test</td><td>used to, but now</td></tr><tr><td>_runtime</td><td>93</td></tr><tr><td>_timestamp</td><td>1626950757</td></tr><tr><td>_step</td><td>17</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_step</td><td>▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">rs1-swa-linear-75-start2-drop-shuffle_4_testset_19_07_21</strong>: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/ap1v4h5f\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/ap1v4h5f</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:ap1v4h5f). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: wandb version 0.11.0 is available!  To upgrade, please run:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.22<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">rs2-shuffle-train_5_testset_19_07_21</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ukh/checklist_evaluation\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/8vnl7oxg\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/8vnl7oxg</a><br/>\n",
       "                Run data is saved locally in <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_104600-8vnl7oxg</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Movie sentiments\n",
      "Predicting 58 examples\n",
      "Running Single positive words\n",
      "Predicting 22 examples\n",
      "Running Single negative words\n",
      "Predicting 14 examples\n",
      "Running Sentiment-laden words in context\n",
      "Predicting 1350 examples\n",
      "Running add positive phrases\n",
      "Predicting 5500 examples\n",
      "Running add negative phrases\n",
      "Predicting 5000 examples\n",
      "Running Simple negations: negative\n",
      "Predicting 1350 examples\n",
      "Running Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Predicting 500 examples\n",
      "Running Movie genre specific sentiments\n",
      "Predicting 736 examples\n",
      "Running Change names\n",
      "Predicting 1617 examples\n",
      "Running Polarizing Negative Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Polarizing Positive Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Negative Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Positive Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Change Movie Industries\n",
      "Predicting 252 examples\n",
      "Running Movie Industries specific sentiments\n",
      "Predicting 1200 examples\n",
      "Running change neutral words with BERT\n",
      "Predicting 3846 examples\n",
      "Running used to, but now\n",
      "Predicting 2152 examples\n"
     ]
    }
   ],
   "source": [
    "results_path = \"results/checklist/rs2-shuffle-train_5_testset_19_07_21.json\"\n",
    "config = {\n",
    "    \"project_name\": \"checklist_evaluation\", \n",
    "    \"run_name\": \"rs2-shuffle-train_5_testset_19_07_21\",\n",
    "    \"model\": \"albert-large-v2\", \n",
    "    \"checkpoint\": checkpoint_path, \n",
    "    \"test_suite\": test_suite_path,\n",
    "    \"results_path\": results_path\n",
    "}\n",
    "wandb.init(config=config, project=config[\"project_name\"], name=config[\"run_name\"])\n",
    "\n",
    "test_suite = TestSuite.from_file(test_suite_path)\n",
    "test_suite.run(pred_and_conf, overwrite=True, seed=0)\n",
    "save_test_results(config, test_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "stable-trace",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary\n",
      "\n",
      "Single positive words\n",
      "Test cases:      22\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Single negative words\n",
      "Test cases:      14\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Sentiment-laden words in context\n",
      "Test cases:      1350\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add positive phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add negative phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    6 (1.2%)\n",
      "\n",
      "Example fails:\n",
      "0.0 Let 's cut to the consumer-advice bottom line : Stay home .\n",
      "0.1 Let 's cut to the consumer-advice bottom line : Stay home. I abhor it.\n",
      "\n",
      "----\n",
      "0.0 Francophiles will snicker knowingly and you 'll want to slap them .\n",
      "0.1 Francophiles will snicker knowingly and you 'll want to slap them. I abhor it.\n",
      "0.1 Francophiles will snicker knowingly and you 'll want to slap them. I dread it.\n",
      "\n",
      "----\n",
      "0.3 The Transporter is as lively and as fun as it is unapologetically dumb\n",
      "0.5 The Transporter is as lively and as fun as it is unapologetically dumb. I abhor it.\n",
      "0.4 The Transporter is as lively and as fun as it is unapologetically dumb. I dread it.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "change neutral words with BERT\n",
      "Test cases:      500\n",
      "Fails (rate):    38 (7.6%)\n",
      "\n",
      "Example fails:\n",
      "0.0 `` Men in Black II , '' has all the earmarks of a sequel .\n",
      "0.8 `` Men in Black II , '' has all the earmarks of its sequel .\n",
      "\n",
      "----\n",
      "0.6 Audiences conditioned to getting weepy over saucer-eyed , downy-cheeked moppets and their empathetic caretakers will probably feel emotionally cheated by the film 's tart , sugar-free wit .\n",
      "0.2 Audiences conditioned to getting weepy over saucer-eyed , downy-cheeked moppets and their empathetic caretakers will probably feel emotionally cheated from the film 's tart , sugar-free wit .\n",
      "\n",
      "----\n",
      "0.4 The film is just a big , gorgeous , mind-blowing , breath-taking mess .\n",
      "1.0 The film is just this big , gorgeous , mind-blowing , breath-taking mess .\n",
      "0.6 The film is just one big , gorgeous , mind-blowing , breath-taking mess .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NER\n",
      "\n",
      "Change names\n",
      "Test cases:      147\n",
      "Fails (rate):    2 (1.4%)\n",
      "\n",
      "Example fails:\n",
      "0.7 Adam Sandler is to Gary Cooper what a gnat is to a racehorse .\n",
      "0.3 Adam Sandler is to Daniel White what a gnat is to a racehorse .\n",
      "0.3 Adam Sandler is to Christopher Reed what a gnat is to a racehorse .\n",
      "\n",
      "----\n",
      "0.5 De Niro may enjoy the same free ride from critics afforded to Clint Eastwood in the lazy Bloodwork .\n",
      "0.4 De Niro may enjoy the same free ride from critics afforded to Daniel Sanders in the lazy Bloodwork .\n",
      "0.4 De Niro may enjoy the same free ride from critics afforded to David Taylor in the lazy Bloodwork .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    4 (2.5%)\n",
      "\n",
      "Example fails:\n",
      "0.2 For Benigni it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.8 For Einstein it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.8 For Paul Pender it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "\n",
      "----\n",
      "0.7 ( A ) Hollywood sheen bedevils the film from the very beginning ... ( but ) Lohman 's moist , deeply emotional eyes shine through this bogus veneer ...\n",
      "0.2 ( A ) Hollywood sheen bedevils the film from the very beginning ... ( but ) Britney 's moist , deeply emotional eyes shine through this bogus veneer ...\n",
      "0.3 ( A ) Hollywood sheen bedevils the film from the very beginning ... ( but ) Einstein 's moist , deeply emotional eyes shine through this bogus veneer ...\n",
      "\n",
      "----\n",
      "0.4 It suggests the wide-ranging effects of media manipulation , from the kind of reporting that is done by the supposedly liberal media ... to the intimate and ultimately tragic heartache of maverick individuals like Hatfield and Hicks .\n",
      "0.5 It suggests the wide-ranging effects of media manipulation , from the kind of reporting that is done by the supposedly liberal media ... to the intimate and ultimately tragic heartache of maverick individuals like Adam Rifkin and Hicks .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    4 (3.3%)\n",
      "\n",
      "Example fails:\n",
      "0.7 Adam Sandler is to Gary Cooper what a gnat is to a racehorse .\n",
      "0.0 Adam Sandler is to Polanski what a gnat is to a racehorse .\n",
      "0.1 Birot is to Gary Cooper what a gnat is to a racehorse .\n",
      "\n",
      "----\n",
      "0.9 George , hire a real director and good writers for the next installment , please .\n",
      "0.0 Birot , hire a real director and good writers for the next installment , please .\n",
      "0.0 Gosling , hire a real director and good writers for the next installment , please .\n",
      "\n",
      "----\n",
      "0.6 Its lack of quality earns it a place alongside those other two recent Dumas botch-jobs , The Man in the Iron Mask and The Musketeer .\n",
      "0.5 Its lack of quality earns it a place alongside those other two recent Smokey Robinson botch-jobs , The Man in the Iron Mask and The Musketeer .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    6 (4.9%)\n",
      "\n",
      "Example fails:\n",
      "0.3 Based on a David Leavitt story , the film shares that writer 's usual blend of observant cleverness , too-facile coincidence and slightly noxious preciousness .\n",
      "0.7 Based on a Crispin Glover story , the film shares that writer 's usual blend of observant cleverness , too-facile coincidence and slightly noxious preciousness .\n",
      "\n",
      "----\n",
      "0.6 Its lack of quality earns it a place alongside those other two recent Dumas botch-jobs , The Man in the Iron Mask and The Musketeer .\n",
      "0.4 Its lack of quality earns it a place alongside those other two recent Einstein botch-jobs , The Man in the Iron Mask and The Musketeer .\n",
      "\n",
      "----\n",
      "0.7 Adam Sandler is to Gary Cooper what a gnat is to a racehorse .\n",
      "0.2 Adam Sandler is to Roberts what a gnat is to a racehorse .\n",
      "0.2 Adam Sandler is to Sarah what a gnat is to a racehorse .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    3 (1.9%)\n",
      "\n",
      "Example fails:\n",
      "0.2 For Benigni it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "1.0 For Carl Franklin it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.9 For Craig Bartlett it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "\n",
      "----\n",
      "0.7 ( A ) Hollywood sheen bedevils the film from the very beginning ... ( but ) Lohman 's moist , deeply emotional eyes shine through this bogus veneer ...\n",
      "0.4 ( A ) Hollywood sheen bedevils the film from the very beginning ... ( but ) Carl Franklin 's moist , deeply emotional eyes shine through this bogus veneer ...\n",
      "0.4 ( A ) Hollywood sheen bedevils the film from the very beginning ... ( but ) Smokey Robinson 's moist , deeply emotional eyes shine through this bogus veneer ...\n",
      "\n",
      "----\n",
      "0.4 It suggests the wide-ranging effects of media manipulation , from the kind of reporting that is done by the supposedly liberal media ... to the intimate and ultimately tragic heartache of maverick individuals like Hatfield and Hicks .\n",
      "0.6 It suggests the wide-ranging effects of media manipulation , from the kind of reporting that is done by the supposedly liberal media ... to the intimate and ultimately tragic heartache of maverick individuals like Phillip Noyce and Hicks .\n",
      "0.5 It suggests the wide-ranging effects of media manipulation , from the kind of reporting that is done by the supposedly liberal media ... to the intimate and ultimately tragic heartache of maverick individuals like Walt Becker and Hicks .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Change Movie Industries\n",
      "Test cases:      18\n",
      "Fails (rate):    1 (5.6%)\n",
      "\n",
      "Example fails:\n",
      "0.7 ( A ) Hollywood sheen bedevils the film from the very beginning ... ( but ) Lohman 's moist , deeply emotional eyes shine through this bogus veneer ...\n",
      "0.2 ( A ) Nollywood sheen bedevils the film from the very beginning ... ( but ) Lohman 's moist , deeply emotional eyes shine through this bogus veneer ...\n",
      "0.3 ( A ) Ghollywood sheen bedevils the film from the very beginning ... ( but ) Lohman 's moist , deeply emotional eyes shine through this bogus veneer ...\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Temporal\n",
      "\n",
      "used to, but now\n",
      "Test cases:      2152\n",
      "Fails (rate):    122 (5.7%)\n",
      "\n",
      "Example fails:\n",
      "0.5 I used to regret this movie, even though now I love it.\n",
      "----\n",
      "0.5 In the past I would recommend this movie, even though now I abhor it.\n",
      "----\n",
      "0.1 I think this movie is brilliant, but in the past I thought it was bad.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Negation\n",
      "\n",
      "Simple negations: negative\n",
      "Test cases:      1350\n",
      "Fails (rate):    36 (2.7%)\n",
      "\n",
      "Example fails:\n",
      "1.0 I can't say I admire this actor.\n",
      "----\n",
      "1.0 I can't say I admire that actor.\n",
      "----\n",
      "1.0 I can't say I welcome that movie.\n",
      "----\n",
      "\n",
      "\n",
      "Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Test cases:      500\n",
      "Fails (rate):    245 (49.0%)\n",
      "\n",
      "Example fails:\n",
      "1.0 I can't say, given it's a Friday, that the movie is brilliant.\n",
      "----\n",
      "0.6 I wouldn't say, given all that I've seen over the years, that we welcome this scene.\n",
      "----\n",
      "1.0 I can't say, given that we watched a lot, that that actor was wonderful.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sentiment\n",
      "\n",
      "Movie genre specific sentiments\n",
      "Test cases:      736\n",
      "Fails (rate):    39 (5.3%)\n",
      "\n",
      "Example fails:\n",
      "0.4 This comedy movie was rib-tickling\n",
      "----\n",
      "0.6 This comedy movie is scary rather than rib-tickling\n",
      "----\n",
      "0.6 The comedy movie was serious, not light-hearted\n",
      "----\n",
      "\n",
      "\n",
      "Movie Industries specific sentiments\n",
      "Test cases:      1200\n",
      "Fails (rate):    1 (0.1%)\n",
      "\n",
      "Example fails:\n",
      "0.6 Tamalewood movies are tough\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Synonym/Antonym\n",
      "\n",
      "Movie sentiments\n",
      "Test cases:      58\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_suite.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "structural-sixth",
   "metadata": {},
   "source": [
    "#### Random Seed 2 - SWA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "liked-stations",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"albert-large-v2\"\n",
    "checkpoint_path = \"model-outputs/final-models/rs2-swa-linear-60-start2-drop-shuffle/albert-large-v2_4.pt\"\n",
    "pipeline = BatchedInference.from_model_name(\n",
    "    model_name, checkpoint_path=checkpoint_path, device=\"cuda\"\n",
    ")\n",
    "\n",
    "def pred_and_conf(data, batch_size=32):\n",
    "    data = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    for data in data: \n",
    "        preds, confs = pipeline(data)\n",
    "        preds = preds.numpy().tolist()\n",
    "        confs = confs.numpy()\n",
    "        predictions.append(preds)\n",
    "        confidences.append(confs)\n",
    "    predictions = np.hstack(predictions)\n",
    "    confidences = np.vstack(confidences)\n",
    "    return predictions, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "upset-access",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:8vnl7oxg) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 9964<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 4.63MB of 4.63MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_104600-8vnl7oxg/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_104600-8vnl7oxg/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>test</td><td>used to, but now</td></tr><tr><td>_runtime</td><td>92</td></tr><tr><td>_timestamp</td><td>1626950856</td></tr><tr><td>_step</td><td>17</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_step</td><td>▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">rs2-shuffle-train_5_testset_19_07_21</strong>: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/8vnl7oxg\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/8vnl7oxg</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:8vnl7oxg). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: wandb version 0.11.0 is available!  To upgrade, please run:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.22<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">rs2-swa-linear-60-start2-drop-shuffle_4_testset_19_07_21</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ukh/checklist_evaluation\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/2d6sczaz\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/2d6sczaz</a><br/>\n",
       "                Run data is saved locally in <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_104739-2d6sczaz</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Movie sentiments\n",
      "Predicting 58 examples\n",
      "Running Single positive words\n",
      "Predicting 22 examples\n",
      "Running Single negative words\n",
      "Predicting 14 examples\n",
      "Running Sentiment-laden words in context\n",
      "Predicting 1350 examples\n",
      "Running add positive phrases\n",
      "Predicting 5500 examples\n",
      "Running add negative phrases\n",
      "Predicting 5000 examples\n",
      "Running Simple negations: negative\n",
      "Predicting 1350 examples\n",
      "Running Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Predicting 500 examples\n",
      "Running Movie genre specific sentiments\n",
      "Predicting 736 examples\n",
      "Running Change names\n",
      "Predicting 1617 examples\n",
      "Running Polarizing Negative Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Polarizing Positive Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Negative Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Positive Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Change Movie Industries\n",
      "Predicting 252 examples\n",
      "Running Movie Industries specific sentiments\n",
      "Predicting 1200 examples\n",
      "Running change neutral words with BERT\n",
      "Predicting 3846 examples\n",
      "Running used to, but now\n",
      "Predicting 2152 examples\n"
     ]
    }
   ],
   "source": [
    "results_path = \"results/checklist/rs2-swa-linear-60-start2-drop-shuffle_4_testset_19_07_21.json\"\n",
    "config = {\n",
    "    \"project_name\": \"checklist_evaluation\", \n",
    "    \"run_name\": \"rs2-swa-linear-60-start2-drop-shuffle_4_testset_19_07_21\",\n",
    "    \"model\": \"albert-large-v2\", \n",
    "    \"checkpoint\": checkpoint_path, \n",
    "    \"test_suite\": test_suite_path,\n",
    "    \"results_path\": results_path\n",
    "}\n",
    "wandb.init(config=config, project=config[\"project_name\"], name=config[\"run_name\"])\n",
    "\n",
    "test_suite = TestSuite.from_file(test_suite_path)\n",
    "test_suite.run(pred_and_conf, overwrite=True, seed=0)\n",
    "save_test_results(config, test_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "confirmed-ridge",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary\n",
      "\n",
      "Single positive words\n",
      "Test cases:      22\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Single negative words\n",
      "Test cases:      14\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Sentiment-laden words in context\n",
      "Test cases:      1350\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add positive phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add negative phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    1 (0.2%)\n",
      "\n",
      "Example fails:\n",
      "0.0 Roger Michell , who did an appealing job directing Persuasion and Notting Hill in England , gets too artsy in his American debut .\n",
      "0.1 Roger Michell , who did an appealing job directing Persuasion and Notting Hill in England , gets too artsy in his American debut. I regret it.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "change neutral words with BERT\n",
      "Test cases:      500\n",
      "Fails (rate):    37 (7.4%)\n",
      "\n",
      "Example fails:\n",
      "0.8 If you pitch your expectations at an all time low , you could do worse than this oddly cheerful -- but not particularly funny -- body-switching farce .\n",
      "0.0 If you pitch your expectations at an all time low , you could do worse than make oddly cheerful -- but not particularly funny -- body-switching farce .\n",
      "0.0 If you pitch your expectations at an all time low , you could do worse than another oddly cheerful -- but not particularly funny -- body-switching farce .\n",
      "\n",
      "----\n",
      "1.0 Workmanlike , maybe , but still a film with all the elements that made the other three great , scary times at the movies .\n",
      "0.0 Workmanlike , maybe , but still a film lacking all the elements that made the other three great , scary times at the movies .\n",
      "\n",
      "----\n",
      "0.2 I would have preferred a transfer down the hall to Mr. Holland 's class for the music , or to Robin Williams 's lecture so I could listen to a teacher with humor , passion , and verve .\n",
      "0.6 I would have preferred a transfer down the hall to Mr. Holland 's class for the music , than to Robin Williams 's lecture so I could listen to a teacher with humor , passion , and verve .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NER\n",
      "\n",
      "Change names\n",
      "Test cases:      147\n",
      "Fails (rate):    3 (2.0%)\n",
      "\n",
      "Example fails:\n",
      "0.5 Adam Sandler is to Gary Cooper what a gnat is to a racehorse .\n",
      "0.6 Adam Sandler is to David Fisher what a gnat is to a racehorse .\n",
      "0.6 Joshua Nelson is to Gary Cooper what a gnat is to a racehorse .\n",
      "\n",
      "----\n",
      "0.5 De Niro may enjoy the same free ride from critics afforded to Clint Eastwood in the lazy Bloodwork .\n",
      "0.6 De Niro may enjoy the same free ride from critics afforded to Joshua Nelson in the lazy Bloodwork .\n",
      "\n",
      "----\n",
      "0.5 Based on a David Leavitt story , the film shares that writer 's usual blend of observant cleverness , too-facile coincidence and slightly noxious preciousness .\n",
      "0.4 Based on a Michael Ward story , the film shares that writer 's usual blend of observant cleverness , too-facile coincidence and slightly noxious preciousness .\n",
      "0.4 Based on a Joshua Nelson story , the film shares that writer 's usual blend of observant cleverness , too-facile coincidence and slightly noxious preciousness .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    5 (3.2%)\n",
      "\n",
      "Example fails:\n",
      "0.5 When your leading ladies are a couple of screen-eating dominatrixes like Goldie Hawn and Susan Sarandon at their raunchy best , even hokum goes down easily .\n",
      "0.6 When your leading ladies are a couple of screen-eating dominatrixes like Goldie Hawn and Michel Gondry at their raunchy best , even hokum goes down easily .\n",
      "0.6 When your leading ladies are a couple of screen-eating dominatrixes like Goldie Hawn and Yvan Attal at their raunchy best , even hokum goes down easily .\n",
      "\n",
      "----\n",
      "0.4 ( Fessenden ) is much more into ambiguity and creating mood than he is for on screen thrills\n",
      "0.5 ( Crispin Glover ) is much more into ambiguity and creating mood than he is for on screen thrills\n",
      "\n",
      "----\n",
      "0.6 Wasabi is slight fare indeed , with the entire project having the feel of something tossed off quickly ( like one of Hubert 's punches ) , but it should go down smoothly enough with popcorn .\n",
      "0.5 Wasabi is slight fare indeed , with the entire project having the feel of something tossed off quickly ( like one of Jelinek 's punches ) , but it should go down smoothly enough with popcorn .\n",
      "0.5 Wasabi is slight fare indeed , with the entire project having the feel of something tossed off quickly ( like one of Adam Rifkin 's punches ) , but it should go down smoothly enough with popcorn .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    6 (4.9%)\n",
      "\n",
      "Example fails:\n",
      "0.5 Adam Sandler is to Gary Cooper what a gnat is to a racehorse .\n",
      "0.7 Walt Becker is to Gary Cooper what a gnat is to a racehorse .\n",
      "\n",
      "----\n",
      "0.5 Based on a David Leavitt story , the film shares that writer 's usual blend of observant cleverness , too-facile coincidence and slightly noxious preciousness .\n",
      "0.2 Based on a Birot story , the film shares that writer 's usual blend of observant cleverness , too-facile coincidence and slightly noxious preciousness .\n",
      "0.3 Based on a Merchant Ivory story , the film shares that writer 's usual blend of observant cleverness , too-facile coincidence and slightly noxious preciousness .\n",
      "\n",
      "----\n",
      "0.4 Ray Liotta and Jason Patric do some of their best work in their underwritten roles , but do n't be fooled : Nobody deserves any prizes here .\n",
      "0.6 Ray Liotta and Eric do some of their best work in their underwritten roles , but do n't be fooled : Nobody deserves any prizes here .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    5 (4.1%)\n",
      "\n",
      "Example fails:\n",
      "0.5 Based on a David Leavitt story , the film shares that writer 's usual blend of observant cleverness , too-facile coincidence and slightly noxious preciousness .\n",
      "0.3 Based on a Britney story , the film shares that writer 's usual blend of observant cleverness , too-facile coincidence and slightly noxious preciousness .\n",
      "0.4 Based on a Jelinek story , the film shares that writer 's usual blend of observant cleverness , too-facile coincidence and slightly noxious preciousness .\n",
      "\n",
      "----\n",
      "0.4 Ray Liotta and Jason Patric do some of their best work in their underwritten roles , but do n't be fooled : Nobody deserves any prizes here .\n",
      "0.5 Ray Liotta and Roberts do some of their best work in their underwritten roles , but do n't be fooled : Nobody deserves any prizes here .\n",
      "\n",
      "----\n",
      "0.5 Adam Sandler is to Gary Cooper what a gnat is to a racehorse .\n",
      "0.6 Michel Gondry is to Gary Cooper what a gnat is to a racehorse .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    4 (2.5%)\n",
      "\n",
      "Example fails:\n",
      "0.5 When your leading ladies are a couple of screen-eating dominatrixes like Goldie Hawn and Susan Sarandon at their raunchy best , even hokum goes down easily .\n",
      "0.6 When your leading ladies are a couple of screen-eating dominatrixes like Goldie Hawn and Phillip Noyce at their raunchy best , even hokum goes down easily .\n",
      "\n",
      "----\n",
      "0.1 For Benigni it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.5 For Walt Becker it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "\n",
      "----\n",
      "0.4 ( Fessenden ) is much more into ambiguity and creating mood than he is for on screen thrills\n",
      "0.6 ( Carl Franklin ) is much more into ambiguity and creating mood than he is for on screen thrills\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Change Movie Industries\n",
      "Test cases:      18\n",
      "Fails (rate):    2 (11.1%)\n",
      "\n",
      "Example fails:\n",
      "0.7 ( A ) Hollywood sheen bedevils the film from the very beginning ... ( but ) Lohman 's moist , deeply emotional eyes shine through this bogus veneer ...\n",
      "0.4 ( A ) Ghollywood sheen bedevils the film from the very beginning ... ( but ) Lohman 's moist , deeply emotional eyes shine through this bogus veneer ...\n",
      "\n",
      "----\n",
      "0.2 Even when foreign directors ... borrow stuff from Hollywood , they invariably shake up the formula and make it more interesting .\n",
      "0.7 Even when foreign directors ... borrow stuff from Taiwood , they invariably shake up the formula and make it more interesting .\n",
      "0.7 Even when foreign directors ... borrow stuff from Cantonwood , they invariably shake up the formula and make it more interesting .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Temporal\n",
      "\n",
      "used to, but now\n",
      "Test cases:      2152\n",
      "Fails (rate):    96 (4.5%)\n",
      "\n",
      "Example fails:\n",
      "0.4 I used to regret this movie, even though now I appreciate it.\n",
      "----\n",
      "0.5 I value this movie, but I used to dislike it.\n",
      "----\n",
      "0.6 In the past I would value this movie, even though now I hate it.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Negation\n",
      "\n",
      "Simple negations: negative\n",
      "Test cases:      1350\n",
      "Fails (rate):    23 (1.7%)\n",
      "\n",
      "Example fails:\n",
      "1.0 I can't say I welcome that actor.\n",
      "----\n",
      "1.0 I can't say I appreciate that show.\n",
      "----\n",
      "1.0 I can't say I appreciate this actor.\n",
      "----\n",
      "\n",
      "\n",
      "Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Test cases:      500\n",
      "Fails (rate):    14 (2.8%)\n",
      "\n",
      "Example fails:\n",
      "0.7 I wouldn't say, given that I bought it last week, that we love this actor.\n",
      "----\n",
      "0.6 I can't say, given that I bought it last week, that we appreciate that show.\n",
      "----\n",
      "0.7 I can't say, given all that I've seen over the years, that that is a wonderful director.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sentiment\n",
      "\n",
      "Movie genre specific sentiments\n",
      "Test cases:      736\n",
      "Fails (rate):    34 (4.6%)\n",
      "\n",
      "Example fails:\n",
      "1.0 This comedy movie is serious\n",
      "----\n",
      "1.0 The drama movie is funny rather than serious\n",
      "----\n",
      "0.2 The horror movie was frightening\n",
      "----\n",
      "\n",
      "\n",
      "Movie Industries specific sentiments\n",
      "Test cases:      1200\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Synonym/Antonym\n",
      "\n",
      "Movie sentiments\n",
      "Test cases:      58\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_suite.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coated-shanghai",
   "metadata": {},
   "source": [
    "#### Random Seed 3 - Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "familiar-pledge",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"albert-large-v2\"\n",
    "checkpoint_path = \"model-outputs/final-models/rs3-shuffle-train/albert-large-v2_1.pt\"\n",
    "pipeline = BatchedInference.from_model_name(\n",
    "    model_name, checkpoint_path=checkpoint_path, device=\"cuda\"\n",
    ")\n",
    "\n",
    "def pred_and_conf(data, batch_size=32):\n",
    "    data = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    for data in data: \n",
    "        preds, confs = pipeline(data)\n",
    "        preds = preds.numpy().tolist()\n",
    "        confs = confs.numpy()\n",
    "        predictions.append(preds)\n",
    "        confidences.append(confs)\n",
    "    predictions = np.hstack(predictions)\n",
    "    confidences = np.vstack(confidences)\n",
    "    return predictions, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "metropolitan-diversity",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:2d6sczaz) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 10005<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 4.61MB of 4.61MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_104739-2d6sczaz/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_104739-2d6sczaz/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>test</td><td>used to, but now</td></tr><tr><td>_runtime</td><td>92</td></tr><tr><td>_timestamp</td><td>1626950955</td></tr><tr><td>_step</td><td>17</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_step</td><td>▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">rs2-swa-linear-60-start2-drop-shuffle_4_testset_19_07_21</strong>: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/2d6sczaz\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/2d6sczaz</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:2d6sczaz). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: wandb version 0.11.0 is available!  To upgrade, please run:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.22<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">rs3-shuffle-train_1_testset_19_07_21</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ukh/checklist_evaluation\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/lxuokhz0\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/lxuokhz0</a><br/>\n",
       "                Run data is saved locally in <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_104918-lxuokhz0</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Movie sentiments\n",
      "Predicting 58 examples\n",
      "Running Single positive words\n",
      "Predicting 22 examples\n",
      "Running Single negative words\n",
      "Predicting 14 examples\n",
      "Running Sentiment-laden words in context\n",
      "Predicting 1350 examples\n",
      "Running add positive phrases\n",
      "Predicting 5500 examples\n",
      "Running add negative phrases\n",
      "Predicting 5000 examples\n",
      "Running Simple negations: negative\n",
      "Predicting 1350 examples\n",
      "Running Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Predicting 500 examples\n",
      "Running Movie genre specific sentiments\n",
      "Predicting 736 examples\n",
      "Running Change names\n",
      "Predicting 1617 examples\n",
      "Running Polarizing Negative Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Polarizing Positive Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Negative Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Positive Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Change Movie Industries\n",
      "Predicting 252 examples\n",
      "Running Movie Industries specific sentiments\n",
      "Predicting 1200 examples\n",
      "Running change neutral words with BERT\n",
      "Predicting 3846 examples\n",
      "Running used to, but now\n",
      "Predicting 2152 examples\n"
     ]
    }
   ],
   "source": [
    "results_path = \"results/checklist/rs3-shuffle-train_1_testset_19_07_21.json\"\n",
    "config = {\n",
    "    \"project_name\": \"checklist_evaluation\", \n",
    "    \"run_name\": \"rs3-shuffle-train_1_testset_19_07_21\",\n",
    "    \"model\": \"albert-large-v2\", \n",
    "    \"checkpoint\": checkpoint_path, \n",
    "    \"test_suite\": test_suite_path,\n",
    "    \"results_path\": results_path\n",
    "}\n",
    "wandb.init(config=config, project=config[\"project_name\"], name=config[\"run_name\"])\n",
    "\n",
    "test_suite = TestSuite.from_file(test_suite_path)\n",
    "test_suite.run(pred_and_conf, overwrite=True, seed=0)\n",
    "save_test_results(config, test_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "developed-float",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary\n",
      "\n",
      "Single positive words\n",
      "Test cases:      22\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Single negative words\n",
      "Test cases:      14\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Sentiment-laden words in context\n",
      "Test cases:      1350\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add positive phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add negative phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "change neutral words with BERT\n",
      "Test cases:      500\n",
      "Fails (rate):    35 (7.0%)\n",
      "\n",
      "Example fails:\n",
      "0.2 A strong first quarter , slightly less so second quarter , and average second half .\n",
      "0.5 really strong first quarter , slightly less so second quarter , and average second half .\n",
      "\n",
      "----\n",
      "0.9 Evokes a little of the fear that parents have for the possible futures of their children -- and the sometimes bad choices mothers and fathers make in the interests of doing them good .\n",
      "0.0 Evokes very little of the fear that parents have for the possible futures of their children -- and the sometimes bad choices mothers and fathers make in the interests of doing them good .\n",
      "0.0 Evokes is little of the fear that parents have for the possible futures of their children -- and the sometimes bad choices mothers and fathers make in the interests of doing them good .\n",
      "\n",
      "----\n",
      "0.5 Like a south-of-the-border Melrose Place .\n",
      "1.0 Like this south-of-the-border Melrose Place .\n",
      "0.9 Like our south-of-the-border Melrose Place .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NER\n",
      "\n",
      "Change names\n",
      "Test cases:      147\n",
      "Fails (rate):    2 (1.4%)\n",
      "\n",
      "Example fails:\n",
      "0.5 Has it ever been possible to say that Williams has truly inhabited a character ?\n",
      "0.3 Has it ever been possible to say that Luke has truly inhabited a character ?\n",
      "0.3 Has it ever been possible to say that Luke has truly inhabited a character ?\n",
      "\n",
      "----\n",
      "0.3 De Niro may enjoy the same free ride from critics afforded to Clint Eastwood in the lazy Bloodwork .\n",
      "0.6 De Niro may enjoy the same free ride from critics afforded to Joshua Nelson in the lazy Bloodwork .\n",
      "0.5 De Niro may enjoy the same free ride from critics afforded to John Bailey in the lazy Bloodwork .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    1 (0.6%)\n",
      "\n",
      "Example fails:\n",
      "0.3 Steve Irwin 's method is Ernest Hemmingway at accelerated speed and volume .\n",
      "0.9 Steve Irwin 's method is Carol Kane at accelerated speed and volume .\n",
      "0.9 Steve Irwin 's method is Einstein at accelerated speed and volume .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    3 (2.4%)\n",
      "\n",
      "Example fails:\n",
      "0.6 Warmed-over Tarantino by way of wannabe Elmore Leonard .\n",
      "0.3 Warmed-over Tarantino by way of wannabe Foster .\n",
      "0.3 Warmed-over Tarantino by way of wannabe Merchant Ivory .\n",
      "\n",
      "----\n",
      "0.5 Flat , but with a revelatory performance by Michelle Williams .\n",
      "0.6 Flat , but with a revelatory performance by Birot .\n",
      "0.6 Flat , but with a revelatory performance by Gosling .\n",
      "\n",
      "----\n",
      "0.5 Has it ever been possible to say that Williams has truly inhabited a character ?\n",
      "0.2 Has it ever been possible to say that Birot has truly inhabited a character ?\n",
      "0.2 Has it ever been possible to say that Merchant Ivory has truly inhabited a character ?\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    5 (4.1%)\n",
      "\n",
      "Example fails:\n",
      "0.5 Has it ever been possible to say that Williams has truly inhabited a character ?\n",
      "0.2 Has it ever been possible to say that Britney has truly inhabited a character ?\n",
      "0.4 Has it ever been possible to say that Jelinek has truly inhabited a character ?\n",
      "\n",
      "----\n",
      "0.5 ( Director ) Byler may yet have a great movie in him , but Charlotte Sometimes is only half of one .\n",
      "0.4 ( Director ) Britney may yet have a great movie in him , but Charlotte Sometimes is only half of one .\n",
      "\n",
      "----\n",
      "0.3 De Niro may enjoy the same free ride from critics afforded to Clint Eastwood in the lazy Bloodwork .\n",
      "0.6 De Niro may enjoy the same free ride from critics afforded to Sarah in the lazy Bloodwork .\n",
      "0.5 De Niro may enjoy the same free ride from critics afforded to Gary Fleder in the lazy Bloodwork .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    2 (1.3%)\n",
      "\n",
      "Example fails:\n",
      "0.8 More honest about Alzheimer 's disease , I think , than Iris .\n",
      "0.4 More honest about Alzheimer 's disease , I think , than Birot .\n",
      "\n",
      "----\n",
      "0.3 Steve Irwin 's method is Ernest Hemmingway at accelerated speed and volume .\n",
      "1.0 Steve Irwin 's method is Carl Franklin at accelerated speed and volume .\n",
      "0.9 Steve Irwin 's method is Foster at accelerated speed and volume .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Change Movie Industries\n",
      "Test cases:      18\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Temporal\n",
      "\n",
      "used to, but now\n",
      "Test cases:      2152\n",
      "Fails (rate):    123 (5.7%)\n",
      "\n",
      "Example fails:\n",
      "0.4 I like this movie, but I used to abhor it.\n",
      "----\n",
      "0.5 In the past I would recommend this movie, even though now I hate it.\n",
      "----\n",
      "0.7 I abhor this movie, but in the past I would value it.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Negation\n",
      "\n",
      "Simple negations: negative\n",
      "Test cases:      1350\n",
      "Fails (rate):    13 (1.0%)\n",
      "\n",
      "Example fails:\n",
      "0.8 I would never say I admire this director.\n",
      "----\n",
      "0.9 I can't say I appreciate the director.\n",
      "----\n",
      "1.0 I would never say I welcome this director.\n",
      "----\n",
      "\n",
      "\n",
      "Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Test cases:      500\n",
      "Fails (rate):    244 (48.8%)\n",
      "\n",
      "Example fails:\n",
      "1.0 I can't say, given my history with movies, that the movie was fantastic.\n",
      "----\n",
      "0.9 I wouldn't say, given it's a Friday, that that scene was amazing.\n",
      "----\n",
      "0.9 I don't think, given that I bought it last week, that this was a beautiful show.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sentiment\n",
      "\n",
      "Movie genre specific sentiments\n",
      "Test cases:      736\n",
      "Fails (rate):    33 (4.5%)\n",
      "\n",
      "Example fails:\n",
      "1.0 This horror movie is calming\n",
      "----\n",
      "1.0 The comedy movie is serious, not rib-tickling\n",
      "----\n",
      "0.9 This comedy movie was serious, not rib-tickling\n",
      "----\n",
      "\n",
      "\n",
      "Movie Industries specific sentiments\n",
      "Test cases:      1200\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Synonym/Antonym\n",
      "\n",
      "Movie sentiments\n",
      "Test cases:      58\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_suite.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "covered-pocket",
   "metadata": {},
   "source": [
    "#### Random Seed 3 - SWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "induced-slovak",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"albert-large-v2\"\n",
    "checkpoint_path = \"model-outputs/final-models/rs3-swa-linear-60-start2-drop-shuffle/albert-large-v2_8.pt\"\n",
    "pipeline = BatchedInference.from_model_name(\n",
    "    model_name, checkpoint_path=checkpoint_path, device=\"cuda\"\n",
    ")\n",
    "\n",
    "def pred_and_conf(data, batch_size=32):\n",
    "    data = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    for data in data: \n",
    "        preds, confs = pipeline(data)\n",
    "        preds = preds.numpy().tolist()\n",
    "        confs = confs.numpy()\n",
    "        predictions.append(preds)\n",
    "        confidences.append(confs)\n",
    "    predictions = np.hstack(predictions)\n",
    "    confidences = np.vstack(confidences)\n",
    "    return predictions, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "german-focus",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:lxuokhz0) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 10050<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 4.59MB of 4.59MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_104918-lxuokhz0/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_104918-lxuokhz0/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>test</td><td>used to, but now</td></tr><tr><td>_runtime</td><td>93</td></tr><tr><td>_timestamp</td><td>1626951055</td></tr><tr><td>_step</td><td>17</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>▁▁▁▁██████████████</td></tr><tr><td>_timestamp</td><td>▁▁▁▁██████████████</td></tr><tr><td>_step</td><td>▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">rs3-shuffle-train_1_testset_19_07_21</strong>: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/lxuokhz0\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/lxuokhz0</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:lxuokhz0). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: wandb version 0.11.0 is available!  To upgrade, please run:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.22<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">rs3-swa-linear-60-start2-drop-shuffle_8_testset_19_07_21</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ukh/checklist_evaluation\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/1kut0rst\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/1kut0rst</a><br/>\n",
       "                Run data is saved locally in <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_105058-1kut0rst</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Movie sentiments\n",
      "Predicting 58 examples\n",
      "Running Single positive words\n",
      "Predicting 22 examples\n",
      "Running Single negative words\n",
      "Predicting 14 examples\n",
      "Running Sentiment-laden words in context\n",
      "Predicting 1350 examples\n",
      "Running add positive phrases\n",
      "Predicting 5500 examples\n",
      "Running add negative phrases\n",
      "Predicting 5000 examples\n",
      "Running Simple negations: negative\n",
      "Predicting 1350 examples\n",
      "Running Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Predicting 500 examples\n",
      "Running Movie genre specific sentiments\n",
      "Predicting 736 examples\n",
      "Running Change names\n",
      "Predicting 1617 examples\n",
      "Running Polarizing Negative Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Polarizing Positive Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Negative Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Positive Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Change Movie Industries\n",
      "Predicting 252 examples\n",
      "Running Movie Industries specific sentiments\n",
      "Predicting 1200 examples\n",
      "Running change neutral words with BERT\n",
      "Predicting 3846 examples\n",
      "Running used to, but now\n",
      "Predicting 2152 examples\n"
     ]
    }
   ],
   "source": [
    "results_path = \"results/checklist/rs3-swa-linear-60-start2-drop-shuffle_8_testset_19_07_21.json\"\n",
    "config = {\n",
    "    \"project_name\": \"checklist_evaluation\", \n",
    "    \"run_name\": \"rs3-swa-linear-60-start2-drop-shuffle_8_testset_19_07_21\",\n",
    "    \"model\": \"albert-large-v2\", \n",
    "    \"checkpoint\": checkpoint_path, \n",
    "    \"test_suite\": test_suite_path,\n",
    "    \"results_path\": results_path\n",
    "}\n",
    "wandb.init(config=config, project=config[\"project_name\"], name=config[\"run_name\"])\n",
    "\n",
    "test_suite = TestSuite.from_file(test_suite_path)\n",
    "test_suite.run(pred_and_conf, overwrite=True, seed=0)\n",
    "save_test_results(config, test_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "vertical-metabolism",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary\n",
      "\n",
      "Single positive words\n",
      "Test cases:      22\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Single negative words\n",
      "Test cases:      14\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Sentiment-laden words in context\n",
      "Test cases:      1350\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add positive phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add negative phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "change neutral words with BERT\n",
      "Test cases:      500\n",
      "Fails (rate):    40 (8.0%)\n",
      "\n",
      "Example fails:\n",
      "0.2 The 3D images only enhance the film 's otherworldly quality , giving it a strange combo of you-are-there closeness with the disorienting unreality of the seemingly broken-down fourth wall of the movie screen .\n",
      "0.6 The 3D images only enhance the film 's otherworldly quality , giving it a strange combo of you-are-there closeness with the disorienting unreality of the seemingly broken-down fourth wall of the big screen .\n",
      "\n",
      "----\n",
      "1.0 The production values are up there .\n",
      "0.0 The production values are up below .\n",
      "\n",
      "----\n",
      "0.9 Run , do n't walk , to see this barbed and bracing comedy on the big screen .\n",
      "0.1 Run , do n't walk , to see more barbed and bracing comedy on the big screen .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NER\n",
      "\n",
      "Change names\n",
      "Test cases:      147\n",
      "Fails (rate):    3 (2.0%)\n",
      "\n",
      "Example fails:\n",
      "0.6 Imagine the James Woods character from Videodrome making a home movie of Audrey Rose and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "0.3 Imagine the James Woods character from Videodrome making a home movie of Melissa White and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "0.4 Imagine the James Woods character from Videodrome making a home movie of Ashley Hughes and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "\n",
      "----\n",
      "0.5 More honest about Alzheimer 's disease , I think , than Iris .\n",
      "0.4 More honest about Alzheimer 's disease , I think , than Katherine .\n",
      "0.4 More honest about Alzheimer 's disease , I think , than Chelsea .\n",
      "\n",
      "----\n",
      "0.8 Steve Irwin 's method is Ernest Hemmingway at accelerated speed and volume .\n",
      "0.4 Matthew Ross method is Ernest Hemmingway at accelerated speed and volume .\n",
      "0.4 Daniel Sanders method is Ernest Hemmingway at accelerated speed and volume .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    5 (3.2%)\n",
      "\n",
      "Example fails:\n",
      "0.6 For Benigni it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.3 For Britney it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "\n",
      "----\n",
      "0.8 Sam Jones became a very lucky filmmaker the day Wilco got dropped from their record label , proving that one man 's ruin may be another 's fortune .\n",
      "0.5 Britney became a very lucky filmmaker the day Wilco got dropped from their record label , proving that one man 's ruin may be another 's fortune .\n",
      "0.5 Einstein became a very lucky filmmaker the day Wilco got dropped from their record label , proving that one man 's ruin may be another 's fortune .\n",
      "\n",
      "----\n",
      "0.5 More honest about Alzheimer 's disease , I think , than Iris .\n",
      "0.2 More honest about Alzheimer 's disease , I think , than Einstein .\n",
      "0.3 More honest about Alzheimer 's disease , I think , than Carol Kane .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    2 (1.6%)\n",
      "\n",
      "Example fails:\n",
      "0.4 While McFarlane 's animation lifts the film firmly above the level of other coming-of-age films ... it 's also so jarring that it 's hard to get back into the boys ' story .\n",
      "0.6 While Craig Bartlett 's animation lifts the film firmly above the level of other coming-of-age films ... it 's also so jarring that it 's hard to get back into the boys ' story .\n",
      "0.6 While Walt Becker 's animation lifts the film firmly above the level of other coming-of-age films ... it 's also so jarring that it 's hard to get back into the boys ' story .\n",
      "\n",
      "----\n",
      "0.6 Imagine the James Woods character from Videodrome making a home movie of Audrey Rose and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "0.2 Imagine the Birot character from Videodrome making a home movie of Audrey Rose and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "0.3 Imagine the James Woods character from Videodrome making a home movie of Doug Liman and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    4 (3.3%)\n",
      "\n",
      "Example fails:\n",
      "0.6 Imagine the James Woods character from Videodrome making a home movie of Audrey Rose and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "0.4 Imagine the James Woods character from Videodrome making a home movie of Gary Fleder and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "0.5 Imagine the Michel Gondry character from Videodrome making a home movie of Audrey Rose and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "\n",
      "----\n",
      "0.4 While McFarlane 's animation lifts the film firmly above the level of other coming-of-age films ... it 's also so jarring that it 's hard to get back into the boys ' story .\n",
      "0.7 While Adam Rifkin 's animation lifts the film firmly above the level of other coming-of-age films ... it 's also so jarring that it 's hard to get back into the boys ' story .\n",
      "0.6 While Einstein 's animation lifts the film firmly above the level of other coming-of-age films ... it 's also so jarring that it 's hard to get back into the boys ' story .\n",
      "\n",
      "----\n",
      "0.5 Where last time jokes flowed out of Cho 's life story , which provided an engrossing dramatic through line , here the comedian hides behind obviously constructed routines .\n",
      "0.4 Where last time jokes flowed out of Britney 's life story , which provided an engrossing dramatic through line , here the comedian hides behind obviously constructed routines .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    3 (1.9%)\n",
      "\n",
      "Example fails:\n",
      "0.6 With Danilo Donati 's witty designs and Dante Spinotti 's luscious cinematography , this might have made a decent children 's movie -- if only Benigni had n't insisted on casting himself in the title role .\n",
      "0.4 With Danilo Donati 's witty designs and Dante Spinotti 's luscious cinematography , this might have made a decent children 's movie -- if only Gosling had n't insisted on casting himself in the title role .\n",
      "\n",
      "----\n",
      "0.5 More honest about Alzheimer 's disease , I think , than Iris .\n",
      "0.0 More honest about Alzheimer 's disease , I think , than Birot .\n",
      "0.2 More honest about Alzheimer 's disease , I think , than Gosling .\n",
      "\n",
      "----\n",
      "0.5 The whole cast looks to be having so much fun with the slapstick antics and silly street patois , tossing around obscure expressions like Bellini and Mullinski , that the compact 86 minutes breezes by .\n",
      "0.4 The whole cast looks to be having so much fun with the slapstick antics and silly street patois , tossing around obscure expressions like Birot and Mullinski , that the compact 86 minutes breezes by .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Change Movie Industries\n",
      "Test cases:      18\n",
      "Fails (rate):    1 (5.6%)\n",
      "\n",
      "Example fails:\n",
      "0.3 Even when foreign directors ... borrow stuff from Hollywood , they invariably shake up the formula and make it more interesting .\n",
      "0.7 Even when foreign directors ... borrow stuff from Tamalewood , they invariably shake up the formula and make it more interesting .\n",
      "0.7 Even when foreign directors ... borrow stuff from Aussiewood , they invariably shake up the formula and make it more interesting .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Temporal\n",
      "\n",
      "used to, but now\n",
      "Test cases:      2152\n",
      "Fails (rate):    33 (1.5%)\n",
      "\n",
      "Example fails:\n",
      "0.8 I abhor this movie, but in the past I would recommend it.\n",
      "----\n",
      "0.6 In the past I would enjoy this movie, even though now I dread it.\n",
      "----\n",
      "0.3 I value this movie, but I used to despise it.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Negation\n",
      "\n",
      "Simple negations: negative\n",
      "Test cases:      1350\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Test cases:      500\n",
      "Fails (rate):    18 (3.6%)\n",
      "\n",
      "Example fails:\n",
      "0.9 I can't say, given it's a Friday, that the actor was beautiful.\n",
      "----\n",
      "0.9 I don't think, given that I bought it last week, that this actor was amazing.\n",
      "----\n",
      "0.7 I can't say, given my history with movies, that this actor is amazing.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sentiment\n",
      "\n",
      "Movie genre specific sentiments\n",
      "Test cases:      736\n",
      "Fails (rate):    36 (4.9%)\n",
      "\n",
      "Example fails:\n",
      "0.1 This horror movie is frightening\n",
      "----\n",
      "0.6 This comedy movie was scary rather than rib-tickling\n",
      "----\n",
      "1.0 This drama movie was funny rather than serious\n",
      "----\n",
      "\n",
      "\n",
      "Movie Industries specific sentiments\n",
      "Test cases:      1200\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Synonym/Antonym\n",
      "\n",
      "Movie sentiments\n",
      "Test cases:      58\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_suite.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "guilty-phase",
   "metadata": {},
   "source": [
    "#### Random Seed 4 - Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "forced-prairie",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"albert-large-v2\"\n",
    "checkpoint_path = \"model-outputs/final-models/rs4-shuffle-train/albert-large-v2_1.pt\"\n",
    "pipeline = BatchedInference.from_model_name(\n",
    "    model_name, checkpoint_path=checkpoint_path, device=\"cuda\"\n",
    ")\n",
    "\n",
    "def pred_and_conf(data, batch_size=32):\n",
    "    data = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    for data in data: \n",
    "        preds, confs = pipeline(data)\n",
    "        preds = preds.numpy().tolist()\n",
    "        confs = confs.numpy()\n",
    "        predictions.append(preds)\n",
    "        confidences.append(confs)\n",
    "    predictions = np.hstack(predictions)\n",
    "    confidences = np.vstack(confidences)\n",
    "    return predictions, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "worldwide-latter",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1kut0rst) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 10231<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 4.60MB of 4.60MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_105058-1kut0rst/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_105058-1kut0rst/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>test</td><td>used to, but now</td></tr><tr><td>_runtime</td><td>92</td></tr><tr><td>_timestamp</td><td>1626951154</td></tr><tr><td>_step</td><td>17</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_step</td><td>▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">rs3-swa-linear-60-start2-drop-shuffle_8_testset_19_07_21</strong>: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/1kut0rst\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/1kut0rst</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:1kut0rst). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: wandb version 0.11.0 is available!  To upgrade, please run:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.22<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">rs4-shuffle-train_1_testset_19_07_21</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ukh/checklist_evaluation\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/1bxfdwk1\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/1bxfdwk1</a><br/>\n",
       "                Run data is saved locally in <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_105238-1bxfdwk1</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Movie sentiments\n",
      "Predicting 58 examples\n",
      "Running Single positive words\n",
      "Predicting 22 examples\n",
      "Running Single negative words\n",
      "Predicting 14 examples\n",
      "Running Sentiment-laden words in context\n",
      "Predicting 1350 examples\n",
      "Running add positive phrases\n",
      "Predicting 5500 examples\n",
      "Running add negative phrases\n",
      "Predicting 5000 examples\n",
      "Running Simple negations: negative\n",
      "Predicting 1350 examples\n",
      "Running Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Predicting 500 examples\n",
      "Running Movie genre specific sentiments\n",
      "Predicting 736 examples\n",
      "Running Change names\n",
      "Predicting 1617 examples\n",
      "Running Polarizing Negative Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Polarizing Positive Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Negative Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Positive Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Change Movie Industries\n",
      "Predicting 252 examples\n",
      "Running Movie Industries specific sentiments\n",
      "Predicting 1200 examples\n",
      "Running change neutral words with BERT\n",
      "Predicting 3846 examples\n",
      "Running used to, but now\n",
      "Predicting 2152 examples\n"
     ]
    }
   ],
   "source": [
    "results_path = \"results/checklist/rs4-shuffle-train_1_testset_19_07_21.json\"\n",
    "config = {\n",
    "    \"project_name\": \"checklist_evaluation\", \n",
    "    \"run_name\": \"rs4-shuffle-train_1_testset_19_07_21\",\n",
    "    \"model\": \"albert-large-v2\", \n",
    "    \"checkpoint\": checkpoint_path, \n",
    "    \"test_suite\": test_suite_path,\n",
    "    \"results_path\": results_path\n",
    "}\n",
    "wandb.init(config=config, project=config[\"project_name\"], name=config[\"run_name\"])\n",
    "\n",
    "test_suite = TestSuite.from_file(test_suite_path)\n",
    "test_suite.run(pred_and_conf, overwrite=True, seed=0)\n",
    "save_test_results(config, test_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "oriented-louis",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary\n",
      "\n",
      "Single positive words\n",
      "Test cases:      22\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Single negative words\n",
      "Test cases:      14\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Sentiment-laden words in context\n",
      "Test cases:      1350\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add positive phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add negative phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    3 (0.6%)\n",
      "\n",
      "Example fails:\n",
      "0.1 Where last time jokes flowed out of Cho 's life story , which provided an engrossing dramatic through line , here the comedian hides behind obviously constructed routines .\n",
      "0.2 Where last time jokes flowed out of Cho 's life story , which provided an engrossing dramatic through line , here the comedian hides behind obviously constructed routines. Never watching this again.\n",
      "0.2 Where last time jokes flowed out of Cho 's life story , which provided an engrossing dramatic through line , here the comedian hides behind obviously constructed routines. I regret it.\n",
      "\n",
      "----\n",
      "0.0 Roger Michell , who did an appealing job directing Persuasion and Notting Hill in England , gets too artsy in his American debut .\n",
      "0.1 Roger Michell , who did an appealing job directing Persuasion and Notting Hill in England , gets too artsy in his American debut. I regret it.\n",
      "\n",
      "----\n",
      "0.0 The essential problem in Orange County is that , having created an unusually vivid set of characters worthy of its strong cast , the film flounders when it comes to giving them something to do .\n",
      "0.1 The essential problem in Orange County is that , having created an unusually vivid set of characters worthy of its strong cast , the film flounders when it comes to giving them something to do. I regret it.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "change neutral words with BERT\n",
      "Test cases:      500\n",
      "Fails (rate):    39 (7.8%)\n",
      "\n",
      "Example fails:\n",
      "0.3 George , hire a real director and good writers for the next installment , please .\n",
      "0.6 George , hire a real director and good writers for your next installment , please .\n",
      "\n",
      "----\n",
      "0.2 There 's something fundamental missing from this story : something or someone to care about .\n",
      "0.7 There 's something fundamental missing from every story : something or someone to care about .\n",
      "\n",
      "----\n",
      "0.4 A film of precious increments artfully camouflaged as everyday activities .\n",
      "1.0 A film capturing precious increments artfully camouflaged as everyday activities .\n",
      "0.7 A film in precious increments artfully camouflaged as everyday activities .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NER\n",
      "\n",
      "Change names\n",
      "Test cases:      147\n",
      "Fails (rate):    4 (2.7%)\n",
      "\n",
      "Example fails:\n",
      "0.6 Imagine the James Woods character from Videodrome making a home movie of Audrey Rose and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "0.4 Imagine the James Woods character from Videodrome making a home movie of Melissa White and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "\n",
      "----\n",
      "0.3 Sucking all the ` classic ' out of Robert Louis Stevenson 's Treasure Island and filling the void with sci-fi video game graphics and Disney-fied adolescent angst ...\n",
      "0.5 Sucking all the ` classic ' out of James Rivera Treasure Island and filling the void with sci-fi video game graphics and Disney-fied adolescent angst ...\n",
      "0.5 Sucking all the ` classic ' out of William Ross Treasure Island and filling the void with sci-fi video game graphics and Disney-fied adolescent angst ...\n",
      "\n",
      "----\n",
      "0.3 George , hire a real director and good writers for the next installment , please .\n",
      "0.6 Austin , hire a real director and good writers for the next installment , please .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    2 (1.3%)\n",
      "\n",
      "Example fails:\n",
      "0.5 That Zhang would make such a strainingly cute film -- with a blind orphan at its center , no less -- indicates where his ambitions have wandered .\n",
      "0.1 Carol Kane would make such a strainingly cute film -- with a blind orphan at its center , no less -- indicates where his ambitions have wandered .\n",
      "0.1 Britney would make such a strainingly cute film -- with a blind orphan at its center , no less -- indicates where his ambitions have wandered .\n",
      "\n",
      "----\n",
      "0.5 Ms. Fulford-Wierzbicki is almost spooky in her sulky , calculating Lolita turn .\n",
      "0.4 Ms. Jelinek is almost spooky in her sulky , calculating Lolita turn .\n",
      "0.4 Ms. Britney is almost spooky in her sulky , calculating Lolita turn .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    6 (4.9%)\n",
      "\n",
      "Example fails:\n",
      "0.5 Home Alone goes Hollywood , a funny premise until the kids start pulling off stunts not even Steven Spielberg would know how to do .\n",
      "0.4 Home Alone goes Hollywood , a funny premise until the kids start pulling off stunts not even Birot would know how to do .\n",
      "0.4 Home Alone goes Hollywood , a funny premise until the kids start pulling off stunts not even Ellen Pompeo would know how to do .\n",
      "\n",
      "----\n",
      "0.3 George , hire a real director and good writers for the next installment , please .\n",
      "0.7 Foster , hire a real director and good writers for the next installment , please .\n",
      "0.5 Merchant Ivory , hire a real director and good writers for the next installment , please .\n",
      "\n",
      "----\n",
      "0.6 Sluggishly directed by episodic TV veteran Joe Zwick , it 's a sitcom without the snap-crackle .\n",
      "0.5 Sluggishly directed by episodic TV veteran Merchant Ivory , it 's a sitcom without the snap-crackle .\n",
      "0.5 Sluggishly directed by episodic TV veteran Birot , it 's a sitcom without the snap-crackle .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    6 (4.9%)\n",
      "\n",
      "Example fails:\n",
      "0.3 George , hire a real director and good writers for the next installment , please .\n",
      "0.6 Crispin Glover , hire a real director and good writers for the next installment , please .\n",
      "0.6 Michel Gondry , hire a real director and good writers for the next installment , please .\n",
      "\n",
      "----\n",
      "0.8 Watching Haneke 's film is , aptly enough , a challenge and a punishment .\n",
      "0.5 Watching Britney 's film is , aptly enough , a challenge and a punishment .\n",
      "\n",
      "----\n",
      "0.6 Imagine the James Woods character from Videodrome making a home movie of Audrey Rose and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "0.4 Imagine the James Woods character from Videodrome making a home movie of Gary Fleder and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "0.4 Imagine the Yvan Attal character from Videodrome making a home movie of Audrey Rose and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    5 (3.2%)\n",
      "\n",
      "Example fails:\n",
      "0.8 Steve Irwin 's method is Ernest Hemmingway at accelerated speed and volume .\n",
      "0.5 Steve Irwin 's method is Birot at accelerated speed and volume .\n",
      "\n",
      "----\n",
      "0.7 Droll caper-comedy remake of `` Big Deal on Madonna Street '' that 's a sly , amusing , laugh-filled little gem in which the ultimate `` Bellini '' begins to look like a `` real Kaputschnik . ''\n",
      "0.4 Droll caper-comedy remake of `` Big Deal on Madonna Street '' that 's a sly , amusing , laugh-filled little gem in which the ultimate `` Bellini '' begins to look like a `` real Birot . ''\n",
      "0.4 Droll caper-comedy remake of `` Big Deal on Madonna Street '' that 's a sly , amusing , laugh-filled little gem in which the ultimate `` Bellini '' begins to look like a `` real Merchant Ivory . ''\n",
      "\n",
      "----\n",
      "0.5 That Zhang would make such a strainingly cute film -- with a blind orphan at its center , no less -- indicates where his ambitions have wandered .\n",
      "0.1 Birot would make such a strainingly cute film -- with a blind orphan at its center , no less -- indicates where his ambitions have wandered .\n",
      "0.1 Gosling would make such a strainingly cute film -- with a blind orphan at its center , no less -- indicates where his ambitions have wandered .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Change Movie Industries\n",
      "Test cases:      18\n",
      "Fails (rate):    1 (5.6%)\n",
      "\n",
      "Example fails:\n",
      "0.5 Home Alone goes Hollywood , a funny premise until the kids start pulling off stunts not even Steven Spielberg would know how to do .\n",
      "0.2 Home Alone goes Hogawood , a funny premise until the kids start pulling off stunts not even Steven Spielberg would know how to do .\n",
      "0.3 Home Alone goes Ghollywood , a funny premise until the kids start pulling off stunts not even Steven Spielberg would know how to do .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Temporal\n",
      "\n",
      "used to, but now\n",
      "Test cases:      2152\n",
      "Fails (rate):    148 (6.9%)\n",
      "\n",
      "Example fails:\n",
      "0.8 In the past I would like this movie, even though now I dread it.\n",
      "----\n",
      "0.3 I think this movie is beautiful, but I used to think it was bad.\n",
      "----\n",
      "0.9 I despise this movie, but in the past I would recommend it.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Negation\n",
      "\n",
      "Simple negations: negative\n",
      "Test cases:      1350\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Test cases:      500\n",
      "Fails (rate):    25 (5.0%)\n",
      "\n",
      "Example fails:\n",
      "0.7 I don't think, given it's a Friday, that we appreciate the actor.\n",
      "----\n",
      "1.0 I can't say, given it's a Friday, that we appreciate this director.\n",
      "----\n",
      "0.7 I wouldn't say, given that I bought it last week, that I appreciate that show.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sentiment\n",
      "\n",
      "Movie genre specific sentiments\n",
      "Test cases:      736\n",
      "Fails (rate):    35 (4.8%)\n",
      "\n",
      "Example fails:\n",
      "0.9 This comedy movie is serious\n",
      "----\n",
      "0.8 The horror movie was calming\n",
      "----\n",
      "1.0 The comedy movie is serious\n",
      "----\n",
      "\n",
      "\n",
      "Movie Industries specific sentiments\n",
      "Test cases:      1200\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Synonym/Antonym\n",
      "\n",
      "Movie sentiments\n",
      "Test cases:      58\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_suite.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-chart",
   "metadata": {},
   "source": [
    "#### Random Seed 4 - SWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "listed-preparation",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"albert-large-v2\"\n",
    "checkpoint_path = \"model-outputs/final-models/rs4-swa-linear-75-start2-drop-shuffle/albert-large-v2_6.pt\"\n",
    "pipeline = BatchedInference.from_model_name(\n",
    "    model_name, checkpoint_path=checkpoint_path, device=\"cuda\"\n",
    ")\n",
    "\n",
    "def pred_and_conf(data, batch_size=32):\n",
    "    data = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    for data in data: \n",
    "        preds, confs = pipeline(data)\n",
    "        preds = preds.numpy().tolist()\n",
    "        confs = confs.numpy()\n",
    "        predictions.append(preds)\n",
    "        confidences.append(confs)\n",
    "    predictions = np.hstack(predictions)\n",
    "    confidences = np.vstack(confidences)\n",
    "    return predictions, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "european-belize",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1bxfdwk1) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 10276<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 4.60MB of 4.60MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_105238-1bxfdwk1/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_105238-1bxfdwk1/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>test</td><td>used to, but now</td></tr><tr><td>_runtime</td><td>92</td></tr><tr><td>_timestamp</td><td>1626951254</td></tr><tr><td>_step</td><td>17</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_step</td><td>▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">rs4-shuffle-train_1_testset_19_07_21</strong>: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/1bxfdwk1\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/1bxfdwk1</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:1bxfdwk1). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: wandb version 0.11.0 is available!  To upgrade, please run:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.22<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">rs4-swa-linear-75-start2-drop-shuffle_6_testset_19_07_21</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ukh/checklist_evaluation\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/3apn76q3\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/3apn76q3</a><br/>\n",
       "                Run data is saved locally in <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210722_105419-3apn76q3</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Movie sentiments\n",
      "Predicting 58 examples\n",
      "Running Single positive words\n",
      "Predicting 22 examples\n",
      "Running Single negative words\n",
      "Predicting 14 examples\n",
      "Running Sentiment-laden words in context\n",
      "Predicting 1350 examples\n",
      "Running add positive phrases\n",
      "Predicting 5500 examples\n",
      "Running add negative phrases\n",
      "Predicting 5000 examples\n",
      "Running Simple negations: negative\n",
      "Predicting 1350 examples\n",
      "Running Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Predicting 500 examples\n",
      "Running Movie genre specific sentiments\n",
      "Predicting 736 examples\n",
      "Running Change names\n",
      "Predicting 1617 examples\n",
      "Running Polarizing Negative Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Polarizing Positive Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Negative Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Positive Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Change Movie Industries\n",
      "Predicting 252 examples\n",
      "Running Movie Industries specific sentiments\n",
      "Predicting 1200 examples\n",
      "Running change neutral words with BERT\n",
      "Predicting 3846 examples\n",
      "Running used to, but now\n",
      "Predicting 2152 examples\n"
     ]
    }
   ],
   "source": [
    "results_path = \"results/checklist/rs4-swa-linear-75-start2-drop-shuffle_6_testset_19_07_21.json\"\n",
    "config = {\n",
    "    \"project_name\": \"checklist_evaluation\", \n",
    "    \"run_name\": \"rs4-swa-linear-75-start2-drop-shuffle_6_testset_19_07_21\",\n",
    "    \"model\": \"albert-large-v2\", \n",
    "    \"checkpoint\": checkpoint_path, \n",
    "    \"test_suite\": test_suite_path,\n",
    "    \"results_path\": results_path\n",
    "}\n",
    "wandb.init(config=config, project=config[\"project_name\"], name=config[\"run_name\"])\n",
    "\n",
    "test_suite = TestSuite.from_file(test_suite_path)\n",
    "test_suite.run(pred_and_conf, overwrite=True, seed=0)\n",
    "save_test_results(config, test_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "above-heart",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary\n",
      "\n",
      "Single positive words\n",
      "Test cases:      22\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Single negative words\n",
      "Test cases:      14\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Sentiment-laden words in context\n",
      "Test cases:      1350\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add positive phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add negative phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    2 (0.4%)\n",
      "\n",
      "Example fails:\n",
      "0.0 Without September 11 , Collateral Damage would have been just another bad movie .\n",
      "0.1 Without September 11 , Collateral Damage would have been just another bad movie. Never watching this again.\n",
      "\n",
      "----\n",
      "0.2 Is this progress ?\n",
      "0.4 Is this progress. Never watching this again.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "change neutral words with BERT\n",
      "Test cases:      500\n",
      "Fails (rate):    33 (6.6%)\n",
      "\n",
      "Example fails:\n",
      "0.9 The Transporter is as lively and as fun as it is unapologetically dumb\n",
      "0.3 * Transporter is as lively and as fun as it is unapologetically dumb\n",
      "\n",
      "----\n",
      "0.6 If you pitch your expectations at an all time low , you could do worse than this oddly cheerful -- but not particularly funny -- body-switching farce .\n",
      "0.1 If you pitch your expectations at an all time low , you could do worse than make oddly cheerful -- but not particularly funny -- body-switching farce .\n",
      "0.1 If you pitch your expectations at an all time low , you could do worse than watching oddly cheerful -- but not particularly funny -- body-switching farce .\n",
      "\n",
      "----\n",
      "0.8 In its ragged , cheap and unassuming way , the movie works .\n",
      "0.1 In its ragged , cheap and unassuming way , the above works .\n",
      "0.2 In its ragged , cheap and unassuming way , the code works .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NER\n",
      "\n",
      "Change names\n",
      "Test cases:      147\n",
      "Fails (rate):    4 (2.7%)\n",
      "\n",
      "Example fails:\n",
      "0.5 George , hire a real director and good writers for the next installment , please .\n",
      "0.4 Luke , hire a real director and good writers for the next installment , please .\n",
      "0.4 Luke , hire a real director and good writers for the next installment , please .\n",
      "\n",
      "----\n",
      "0.7 Has it ever been possible to say that Williams has truly inhabited a character ?\n",
      "0.3 Has it ever been possible to say that Luke has truly inhabited a character ?\n",
      "0.3 Has it ever been possible to say that Luke has truly inhabited a character ?\n",
      "\n",
      "----\n",
      "0.5 Imagine the James Woods character from Videodrome making a home movie of Audrey Rose and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "0.3 Imagine the James Woods character from Videodrome making a home movie of Melissa White and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "0.3 Imagine the James Woods character from Videodrome making a home movie of Amanda Torres and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    2 (1.3%)\n",
      "\n",
      "Example fails:\n",
      "0.4 For Benigni it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.9 For Paul Pender it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.9 For Michel Gondry it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "\n",
      "----\n",
      "0.5 ( Davis ) has a bright , chipper style that keeps things moving , while never quite managing to connect her wish-fulfilling characters to the human race .\n",
      "0.4 ( Paul Pender ) has a bright , chipper style that keeps things moving , while never quite managing to connect her wish-fulfilling characters to the human race .\n",
      "0.4 ( Einstein ) has a bright , chipper style that keeps things moving , while never quite managing to connect her wish-fulfilling characters to the human race .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    5 (4.1%)\n",
      "\n",
      "Example fails:\n",
      "0.7 Has it ever been possible to say that Williams has truly inhabited a character ?\n",
      "0.1 Has it ever been possible to say that Birot has truly inhabited a character ?\n",
      "0.2 Has it ever been possible to say that Merchant Ivory has truly inhabited a character ?\n",
      "\n",
      "----\n",
      "0.5 Imagine the James Woods character from Videodrome making a home movie of Audrey Rose and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "0.0 Imagine the Birot character from Videodrome making a home movie of Audrey Rose and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "0.3 Imagine the Merchant Ivory character from Videodrome making a home movie of Audrey Rose and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "\n",
      "----\n",
      "0.5 De Niro may enjoy the same free ride from critics afforded to Clint Eastwood in the lazy Bloodwork .\n",
      "0.4 De Niro may enjoy the same free ride from critics afforded to Gulpilil in the lazy Bloodwork .\n",
      "0.4 Birot may enjoy the same free ride from critics afforded to Clint Eastwood in the lazy Bloodwork .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    8 (6.5%)\n",
      "\n",
      "Example fails:\n",
      "0.6 While Benigni ( who stars and co-wrote ) seems to be having a wonderful time , he might be alone in that .\n",
      "0.4 While Britney ( who stars and co-wrote ) seems to be having a wonderful time , he might be alone in that .\n",
      "0.4 While Einstein ( who stars and co-wrote ) seems to be having a wonderful time , he might be alone in that .\n",
      "\n",
      "----\n",
      "0.5 George , hire a real director and good writers for the next installment , please .\n",
      "0.3 Britney , hire a real director and good writers for the next installment , please .\n",
      "\n",
      "----\n",
      "0.5 De Niro may enjoy the same free ride from critics afforded to Clint Eastwood in the lazy Bloodwork .\n",
      "0.3 Einstein may enjoy the same free ride from critics afforded to Clint Eastwood in the lazy Bloodwork .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    3 (1.9%)\n",
      "\n",
      "Example fails:\n",
      "0.4 For Benigni it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.9 For Walt Becker it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.9 For Craig Bartlett it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "\n",
      "----\n",
      "0.5 ( Davis ) has a bright , chipper style that keeps things moving , while never quite managing to connect her wish-fulfilling characters to the human race .\n",
      "0.3 ( Craig Bartlett ) has a bright , chipper style that keeps things moving , while never quite managing to connect her wish-fulfilling characters to the human race .\n",
      "0.4 ( Walt Becker ) has a bright , chipper style that keeps things moving , while never quite managing to connect her wish-fulfilling characters to the human race .\n",
      "\n",
      "----\n",
      "0.9 More honest about Alzheimer 's disease , I think , than Iris .\n",
      "0.1 More honest about Alzheimer 's disease , I think , than Birot .\n",
      "0.5 More honest about Alzheimer 's disease , I think , than Gosling .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Change Movie Industries\n",
      "Test cases:      18\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Temporal\n",
      "\n",
      "used to, but now\n",
      "Test cases:      2152\n",
      "Fails (rate):    49 (2.3%)\n",
      "\n",
      "Example fails:\n",
      "0.0 I think this movie is good, but I used to think it was terrible.\n",
      "----\n",
      "0.4 I like this movie, but I used to despise it.\n",
      "----\n",
      "0.6 I abhor this movie, but I used to recommend it.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Negation\n",
      "\n",
      "Simple negations: negative\n",
      "Test cases:      1350\n",
      "Fails (rate):    3 (0.2%)\n",
      "\n",
      "Example fails:\n",
      "0.5 I would never say I appreciate the actor.\n",
      "----\n",
      "0.7 I can't say I appreciate the director.\n",
      "----\n",
      "0.9 I would never say I appreciate the director.\n",
      "----\n",
      "\n",
      "\n",
      "Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Test cases:      500\n",
      "Fails (rate):    34 (6.8%)\n",
      "\n",
      "Example fails:\n",
      "0.9 I wouldn't say, given it's a Friday, that this director is beautiful.\n",
      "----\n",
      "0.9 I can't say, given it's a Friday, that this is a wonderful movie.\n",
      "----\n",
      "0.9 I can't say, given that I bought it last week, that we appreciate that show.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sentiment\n",
      "\n",
      "Movie genre specific sentiments\n",
      "Test cases:      736\n",
      "Fails (rate):    37 (5.0%)\n",
      "\n",
      "Example fails:\n",
      "0.6 This children movie is scary\n",
      "----\n",
      "1.0 This drama movie is funny rather than serious\n",
      "----\n",
      "0.9 The comedy movie is serious, not light-hearted\n",
      "----\n",
      "\n",
      "\n",
      "Movie Industries specific sentiments\n",
      "Test cases:      1200\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Synonym/Antonym\n",
      "\n",
      "Movie sentiments\n",
      "Test cases:      58\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_suite.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governing-timber",
   "metadata": {},
   "source": [
    "#### Random Seed 5 - Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sophisticated-coach",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"albert-large-v2\"\n",
    "checkpoint_path = \"model-outputs/final-models/rs5-shuffle-train/albert-large-v2_4.pt\"\n",
    "pipeline = BatchedInference.from_model_name(\n",
    "    model_name, checkpoint_path=checkpoint_path, device=\"cuda\"\n",
    ")\n",
    "\n",
    "def pred_and_conf(data, batch_size=32):\n",
    "    data = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    for data in data: \n",
    "        preds, confs = pipeline(data)\n",
    "        preds = preds.numpy().tolist()\n",
    "        confs = confs.numpy()\n",
    "        predictions.append(preds)\n",
    "        confidences.append(confs)\n",
    "    predictions = np.hstack(predictions)\n",
    "    confidences = np.vstack(confidences)\n",
    "    return predictions, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "respected-copper",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mukh\u001B[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.22<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">rs5-shuffle-train_4_testset_19_07_21</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ukh/checklist_evaluation\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/1nvi7z2i\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/1nvi7z2i</a><br/>\n",
       "                Run data is saved locally in <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210914_085853-1nvi7z2i</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Movie sentiments\n",
      "Predicting 58 examples\n",
      "Running Single positive words\n",
      "Predicting 22 examples\n",
      "Running Single negative words\n",
      "Predicting 14 examples\n",
      "Running Sentiment-laden words in context\n",
      "Predicting 1350 examples\n",
      "Running add positive phrases\n",
      "Predicting 5500 examples\n",
      "Running add negative phrases\n",
      "Predicting 5000 examples\n",
      "Running Simple negations: negative\n",
      "Predicting 1350 examples\n",
      "Running Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Predicting 500 examples\n",
      "Running Movie genre specific sentiments\n",
      "Predicting 736 examples\n",
      "Running Change names\n",
      "Predicting 1617 examples\n",
      "Running Polarizing Negative Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Polarizing Positive Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Negative Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Positive Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Change Movie Industries\n",
      "Predicting 252 examples\n",
      "Running Movie Industries specific sentiments\n",
      "Predicting 1200 examples\n",
      "Running change neutral words with BERT\n",
      "Predicting 3846 examples\n",
      "Running used to, but now\n",
      "Predicting 2152 examples\n"
     ]
    }
   ],
   "source": [
    "results_path = \"results/checklist/rs5-shuffle-train_4_testset_19_07_21.json\"\n",
    "config = {\n",
    "    \"project_name\": \"checklist_evaluation\", \n",
    "    \"run_name\": \"rs5-shuffle-train_4_testset_19_07_21\",\n",
    "    \"model\": \"albert-large-v2\", \n",
    "    \"checkpoint\": checkpoint_path, \n",
    "    \"test_suite\": test_suite_path,\n",
    "    \"results_path\": results_path\n",
    "}\n",
    "wandb.init(config=config, project=config[\"project_name\"], name=config[\"run_name\"])\n",
    "\n",
    "test_suite = TestSuite.from_file(test_suite_path)\n",
    "test_suite.run(pred_and_conf, overwrite=True, seed=0)\n",
    "save_test_results(config, test_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "visible-facility",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary\n",
      "\n",
      "Single positive words\n",
      "Test cases:      22\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Single negative words\n",
      "Test cases:      14\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Sentiment-laden words in context\n",
      "Test cases:      1350\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add positive phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add negative phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    39 (7.8%)\n",
      "\n",
      "Example fails:\n",
      "0.0 The issue of faith is not explored very deeply\n",
      "0.1 The issue of faith is not explored very deeply. I despise it.\n",
      "0.1 The issue of faith is not explored very deeply. I regret it.\n",
      "\n",
      "----\n",
      "0.0 Even legends like Alfred Hitchcock and John Huston occasionally directed trifles ... so it 's no surprise to see a world-class filmmaker like Zhang Yimou behind the camera for a yarn that 's ultimately rather inconsequential .\n",
      "0.2 Even legends like Alfred Hitchcock and John Huston occasionally directed trifles ... so it 's no surprise to see a world-class filmmaker like Zhang Yimou behind the camera for a yarn that 's ultimately rather inconsequential. I despise it.\n",
      "0.2 Even legends like Alfred Hitchcock and John Huston occasionally directed trifles ... so it 's no surprise to see a world-class filmmaker like Zhang Yimou behind the camera for a yarn that 's ultimately rather inconsequential. I dread it.\n",
      "\n",
      "----\n",
      "0.0 Too bad the former Murphy Brown does n't pop Reese back .\n",
      "0.1 Too bad the former Murphy Brown does n't pop Reese back. I abhor it.\n",
      "0.1 Too bad the former Murphy Brown does n't pop Reese back. I dread it.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "change neutral words with BERT\n",
      "Test cases:      500\n",
      "Fails (rate):    43 (8.6%)\n",
      "\n",
      "Example fails:\n",
      "1.0 Here 's a British flick gleefully unconcerned with plausibility , yet just as determined to entertain you .\n",
      "0.1 Here 's a British flick gleefully unconcerned with plausibility , yet just as determined to entertain Americans .\n",
      "0.3 Here 's a British flick gleefully unconcerned with plausibility , yet just as determined to entertain itself .\n",
      "\n",
      "----\n",
      "1.0 This is how you use special effects .\n",
      "0.3 This is how people use special effects .\n",
      "0.4 This is how they use special effects .\n",
      "\n",
      "----\n",
      "0.3 He just wants them to be part of the action , the wallpaper of his chosen reality .\n",
      "1.0 He just wants them to be part of that action , that wallpaper of his chosen reality .\n",
      "0.8 He just wants them to be part of this action , this wallpaper of his chosen reality .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NER\n",
      "\n",
      "Change names\n",
      "Test cases:      147\n",
      "Fails (rate):    3 (2.0%)\n",
      "\n",
      "Example fails:\n",
      "0.7 Has it ever been possible to say that Williams has truly inhabited a character ?\n",
      "0.1 Has it ever been possible to say that Luke has truly inhabited a character ?\n",
      "0.1 Has it ever been possible to say that Luke has truly inhabited a character ?\n",
      "\n",
      "----\n",
      "0.5 ` Abandon all hope , ye who enter here ' ... you should definitely let Dante 's gloomy words be your guide .\n",
      "0.6 ` Abandon all hope , ye who enter here ' ... you should definitely let Samuel 's gloomy words be your guide .\n",
      "\n",
      "----\n",
      "0.4 Flat , but with a revelatory performance by Michelle Williams .\n",
      "0.6 Flat , but with a revelatory performance by Elizabeth Nelson .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    6 (3.8%)\n",
      "\n",
      "Example fails:\n",
      "0.6 While not as aggressively impressive as its American counterpart , `` In the Bedroom , '' Moretti 's film makes its own , quieter observations\n",
      "0.4 While not as aggressively impressive as its American counterpart , `` In the Bedroom , '' Britney 's film makes its own , quieter observations\n",
      "\n",
      "----\n",
      "0.5 Steve Irwin 's method is Ernest Hemmingway at accelerated speed and volume .\n",
      "1.0 Steve Irwin 's method is Crispin Glover at accelerated speed and volume .\n",
      "1.0 Steve Irwin 's method is Carol Kane at accelerated speed and volume .\n",
      "\n",
      "----\n",
      "0.8 As lo-fi as the special effects are , the folks who cobbled Nemesis together indulge the force of humanity over hardware in a way that George Lucas has long forgotten .\n",
      "0.4 As lo-fi as the special effects are , the folks who cobbled Nemesis together indulge the force of humanity over hardware in a way that Britney has long forgotten .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    8 (6.5%)\n",
      "\n",
      "Example fails:\n",
      "0.8 George , hire a real director and good writers for the next installment , please .\n",
      "0.1 Birot , hire a real director and good writers for the next installment , please .\n",
      "0.4 Gosling , hire a real director and good writers for the next installment , please .\n",
      "\n",
      "----\n",
      "0.5 Its lack of quality earns it a place alongside those other two recent Dumas botch-jobs , The Man in the Iron Mask and The Musketeer .\n",
      "0.6 Its lack of quality earns it a place alongside those other two recent Phillip Noyce botch-jobs , The Man in the Iron Mask and The Musketeer .\n",
      "\n",
      "----\n",
      "0.7 Has it ever been possible to say that Williams has truly inhabited a character ?\n",
      "0.1 Has it ever been possible to say that Merchant Ivory has truly inhabited a character ?\n",
      "0.2 Has it ever been possible to say that Ellen Pompeo has truly inhabited a character ?\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    6 (4.9%)\n",
      "\n",
      "Example fails:\n",
      "0.4 Flat , but with a revelatory performance by Michelle Williams .\n",
      "0.5 Flat , but with a revelatory performance by Crispin Glover .\n",
      "\n",
      "----\n",
      "0.7 Has it ever been possible to say that Williams has truly inhabited a character ?\n",
      "0.1 Has it ever been possible to say that Britney has truly inhabited a character ?\n",
      "0.2 Has it ever been possible to say that Mat Hoffman has truly inhabited a character ?\n",
      "\n",
      "----\n",
      "0.8 George , hire a real director and good writers for the next installment , please .\n",
      "0.2 Einstein , hire a real director and good writers for the next installment , please .\n",
      "0.3 Britney , hire a real director and good writers for the next installment , please .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    5 (3.2%)\n",
      "\n",
      "Example fails:\n",
      "0.6 More honest about Alzheimer 's disease , I think , than Iris .\n",
      "0.4 More honest about Alzheimer 's disease , I think , than Birot .\n",
      "0.5 More honest about Alzheimer 's disease , I think , than Ellen Pompeo .\n",
      "\n",
      "----\n",
      "0.5 Steve Irwin 's method is Ernest Hemmingway at accelerated speed and volume .\n",
      "1.0 Steve Irwin 's method is Carl Franklin at accelerated speed and volume .\n",
      "1.0 Steve Irwin 's method is Foster at accelerated speed and volume .\n",
      "\n",
      "----\n",
      "0.5 Sam Jones became a very lucky filmmaker the day Wilco got dropped from their record label , proving that one man 's ruin may be another 's fortune .\n",
      "0.2 Birot became a very lucky filmmaker the day Wilco got dropped from their record label , proving that one man 's ruin may be another 's fortune .\n",
      "0.4 Gosling became a very lucky filmmaker the day Wilco got dropped from their record label , proving that one man 's ruin may be another 's fortune .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Change Movie Industries\n",
      "Test cases:      18\n",
      "Fails (rate):    2 (11.1%)\n",
      "\n",
      "Example fails:\n",
      "0.4 Even when foreign directors ... borrow stuff from Hollywood , they invariably shake up the formula and make it more interesting .\n",
      "0.7 Even when foreign directors ... borrow stuff from Aussiewood , they invariably shake up the formula and make it more interesting .\n",
      "0.7 Even when foreign directors ... borrow stuff from Taiwood , they invariably shake up the formula and make it more interesting .\n",
      "\n",
      "----\n",
      "0.5 It 's getting harder and harder to ignore the fact that Hollywood is n't laughing with us , folks .\n",
      "0.3 It 's getting harder and harder to ignore the fact that Hogawood is n't laughing with us , folks .\n",
      "0.4 It 's getting harder and harder to ignore the fact that Kollywood is n't laughing with us , folks .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Temporal\n",
      "\n",
      "used to, but now\n",
      "Test cases:      2152\n",
      "Fails (rate):    49 (2.3%)\n",
      "\n",
      "Example fails:\n",
      "0.1 I welcome this movie, but I used to regret it.\n",
      "----\n",
      "0.3 I think this movie is fantastic, but I used to think it was terrible.\n",
      "----\n",
      "0.3 I recommend this movie, but I used to abhor it.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Negation\n",
      "\n",
      "Simple negations: negative\n",
      "Test cases:      1350\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Test cases:      500\n",
      "Fails (rate):    43 (8.6%)\n",
      "\n",
      "Example fails:\n",
      "1.0 I can't say, given all that I've seen over the years, that this is a fantastic director.\n",
      "----\n",
      "1.0 I can't say, given that I bought it last week, that the actor is wonderful.\n",
      "----\n",
      "1.0 I can't say, given all that I've seen over the years, that that is a wonderful director.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Synonym/Antonym\n",
      "\n",
      "Movie sentiments\n",
      "Test cases:      58\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sentiment\n",
      "\n",
      "Movie genre specific sentiments\n",
      "Test cases:      736\n",
      "Fails (rate):    42 (5.7%)\n",
      "\n",
      "Example fails:\n",
      "1.0 The comedy movie is serious\n",
      "----\n",
      "0.7 This horror movie is laughable, not terrifying\n",
      "----\n",
      "0.8 This drama movie is funny, not moving\n",
      "----\n",
      "\n",
      "\n",
      "Movie Industries specific sentiments\n",
      "Test cases:      1200\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_suite.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confidential-least",
   "metadata": {},
   "source": [
    "#### Random Seed 5 - SWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "attractive-thong",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"albert-large-v2\"\n",
    "checkpoint_path = \"model-outputs/final-models/rs5-swa-linear-60-start2-drop-shuffle/albert-large-v2_3.pt\"\n",
    "pipeline = BatchedInference.from_model_name(\n",
    "    model_name, checkpoint_path=checkpoint_path, device=\"cuda\"\n",
    ")\n",
    "\n",
    "def pred_and_conf(data, batch_size=32):\n",
    "    data = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    for data in data: \n",
    "        preds, confs = pipeline(data)\n",
    "        preds = preds.numpy().tolist()\n",
    "        confs = confs.numpy()\n",
    "        predictions.append(preds)\n",
    "        confidences.append(confs)\n",
    "    predictions = np.hstack(predictions)\n",
    "    confidences = np.vstack(confidences)\n",
    "    return predictions, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "equivalent-bracket",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1nvi7z2i) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 10590<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 4.67MB of 4.67MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210914_085853-1nvi7z2i/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210914_085853-1nvi7z2i/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>test</td><td>used to, but now</td></tr><tr><td>_runtime</td><td>91</td></tr><tr><td>_timestamp</td><td>1631610025</td></tr><tr><td>_step</td><td>17</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_step</td><td>▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">rs5-shuffle-train_4_testset_19_07_21</strong>: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/1nvi7z2i\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/1nvi7z2i</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:1nvi7z2i). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.22<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">rs5-swa-linear-60-start2-drop-shuffle_3_testset_19_07_21</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ukh/checklist_evaluation\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/1zpj851s\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/1zpj851s</a><br/>\n",
       "                Run data is saved locally in <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210914_090253-1zpj851s</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Movie sentiments\n",
      "Predicting 58 examples\n",
      "Running Single positive words\n",
      "Predicting 22 examples\n",
      "Running Single negative words\n",
      "Predicting 14 examples\n",
      "Running Sentiment-laden words in context\n",
      "Predicting 1350 examples\n",
      "Running add positive phrases\n",
      "Predicting 5500 examples\n",
      "Running add negative phrases\n",
      "Predicting 5000 examples\n",
      "Running Simple negations: negative\n",
      "Predicting 1350 examples\n",
      "Running Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Predicting 500 examples\n",
      "Running Movie genre specific sentiments\n",
      "Predicting 736 examples\n",
      "Running Change names\n",
      "Predicting 1617 examples\n",
      "Running Polarizing Negative Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Polarizing Positive Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Negative Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Positive Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Change Movie Industries\n",
      "Predicting 252 examples\n",
      "Running Movie Industries specific sentiments\n",
      "Predicting 1200 examples\n",
      "Running change neutral words with BERT\n",
      "Predicting 3846 examples\n",
      "Running used to, but now\n",
      "Predicting 2152 examples\n"
     ]
    }
   ],
   "source": [
    "results_path = \"results/checklist/rs5-swa-linear-60-start2-drop-shuffle_3_testset_19_07_21.json\"\n",
    "config = {\n",
    "    \"project_name\": \"checklist_evaluation\", \n",
    "    \"run_name\": \"rs5-swa-linear-60-start2-drop-shuffle_3_testset_19_07_21\",\n",
    "    \"model\": \"albert-large-v2\", \n",
    "    \"checkpoint\": checkpoint_path, \n",
    "    \"test_suite\": test_suite_path,\n",
    "    \"results_path\": results_path\n",
    "}\n",
    "wandb.init(config=config, project=config[\"project_name\"], name=config[\"run_name\"])\n",
    "\n",
    "test_suite = TestSuite.from_file(test_suite_path)\n",
    "test_suite.run(pred_and_conf, overwrite=True, seed=0)\n",
    "save_test_results(config, test_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bronze-december",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary\n",
      "\n",
      "Single positive words\n",
      "Test cases:      22\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Single negative words\n",
      "Test cases:      14\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Sentiment-laden words in context\n",
      "Test cases:      1350\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add positive phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    1 (0.2%)\n",
      "\n",
      "Example fails:\n",
      "0.9 Is n't it great ?\n",
      "0.0 Is n't it great. I would watch this again.\n",
      "0.1 Is n't it great. I value it.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "add negative phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    9 (1.8%)\n",
      "\n",
      "Example fails:\n",
      "0.0 You would be better off investing in the worthy EMI recording that serves as the soundtrack , or the home video of the 1992 Malfitano-Domingo production .\n",
      "0.1 You would be better off investing in the worthy EMI recording that serves as the soundtrack , or the home video of the 1992 Malfitano-Domingo production. I regret it.\n",
      "\n",
      "----\n",
      "0.0 Schindler 's List it ai n't .\n",
      "0.2 Schindler 's List it ai n't. I regret it.\n",
      "\n",
      "----\n",
      "0.1 This pep-talk for faith , hope and charity does little to offend , but if saccharine earnestness were a crime , the film 's producers would be in the clink for life .\n",
      "0.2 This pep-talk for faith , hope and charity does little to offend , but if saccharine earnestness were a crime , the film 's producers would be in the clink for life. I dread it.\n",
      "0.2 This pep-talk for faith , hope and charity does little to offend , but if saccharine earnestness were a crime , the film 's producers would be in the clink for life. I abhor it.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "change neutral words with BERT\n",
      "Test cases:      500\n",
      "Fails (rate):    41 (8.2%)\n",
      "\n",
      "Example fails:\n",
      "0.9 Happily for Mr. Chin -- though unhappily for his subjects -- the invisible hand of the marketplace wrote a script that no human screenwriter could have hoped to match .\n",
      "0.5 Happily for Mr. Chin -- though unhappily for his subjects -- some invisible hand of some marketplace wrote a script that no human screenwriter could have hoped to match .\n",
      "\n",
      "----\n",
      "1.0 Who knows what exactly Godard is on about in this film , but his words and images do n't have to add up to mesmerize you .\n",
      "0.0 Who knows what exactly Godard is on about in this film , but his words and images do n't seem to add up to mesmerize you .\n",
      "0.0 Who knows what exactly Godard is on about in this film , but his words and images do n't have to add up to mesmerize either .\n",
      "\n",
      "----\n",
      "0.7 Run , do n't walk , to see this barbed and bracing comedy on the big screen .\n",
      "0.2 Run , do n't walk , to see more barbed and bracing comedy on the big screen .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NER\n",
      "\n",
      "Change names\n",
      "Test cases:      147\n",
      "Fails (rate):    3 (2.0%)\n",
      "\n",
      "Example fails:\n",
      "0.5 Based on a David Leavitt story , the film shares that writer 's usual blend of observant cleverness , too-facile coincidence and slightly noxious preciousness .\n",
      "0.4 Based on a Michael Ward story , the film shares that writer 's usual blend of observant cleverness , too-facile coincidence and slightly noxious preciousness .\n",
      "0.4 Based on a Matthew Ross story , the film shares that writer 's usual blend of observant cleverness , too-facile coincidence and slightly noxious preciousness .\n",
      "\n",
      "----\n",
      "0.5 Steve Irwin 's method is Ernest Hemmingway at accelerated speed and volume .\n",
      "0.1 Daniel Sanders method is Ernest Hemmingway at accelerated speed and volume .\n",
      "0.1 Michael Ward method is Ernest Hemmingway at accelerated speed and volume .\n",
      "\n",
      "----\n",
      "0.4 Adam Sandler is to Gary Cooper what a gnat is to a racehorse .\n",
      "0.8 Joshua Nelson is to Gary Cooper what a gnat is to a racehorse .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    2 (1.3%)\n",
      "\n",
      "Example fails:\n",
      "0.5 Watching Beanie and his gang put together his slasher video from spare parts and borrowed materials is as much fun as it must have been for them to make it .\n",
      "0.8 Watching Crispin Glover and his gang put together his slasher video from spare parts and borrowed materials is as much fun as it must have been for them to make it .\n",
      "0.8 Watching Carol Kane and his gang put together his slasher video from spare parts and borrowed materials is as much fun as it must have been for them to make it .\n",
      "\n",
      "----\n",
      "0.3 For Benigni it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.8 For Paul Pender it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.8 For Jelinek it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    2 (1.6%)\n",
      "\n",
      "Example fails:\n",
      "0.4 Adam Sandler is to Gary Cooper what a gnat is to a racehorse .\n",
      "0.7 Walt Becker is to Gary Cooper what a gnat is to a racehorse .\n",
      "\n",
      "----\n",
      "0.5 Based on a David Leavitt story , the film shares that writer 's usual blend of observant cleverness , too-facile coincidence and slightly noxious preciousness .\n",
      "0.3 Based on a Merchant Ivory story , the film shares that writer 's usual blend of observant cleverness , too-facile coincidence and slightly noxious preciousness .\n",
      "0.4 Based on a Birot story , the film shares that writer 's usual blend of observant cleverness , too-facile coincidence and slightly noxious preciousness .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    2 (1.6%)\n",
      "\n",
      "Example fails:\n",
      "0.5 Based on a David Leavitt story , the film shares that writer 's usual blend of observant cleverness , too-facile coincidence and slightly noxious preciousness .\n",
      "0.3 Based on a Britney story , the film shares that writer 's usual blend of observant cleverness , too-facile coincidence and slightly noxious preciousness .\n",
      "0.4 Based on a Yvan Attal story , the film shares that writer 's usual blend of observant cleverness , too-facile coincidence and slightly noxious preciousness .\n",
      "\n",
      "----\n",
      "0.4 Adam Sandler is to Gary Cooper what a gnat is to a racehorse .\n",
      "0.6 Michel Gondry is to Gary Cooper what a gnat is to a racehorse .\n",
      "0.6 Yvan Attal is to Gary Cooper what a gnat is to a racehorse .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    3 (1.9%)\n",
      "\n",
      "Example fails:\n",
      "0.5 Watching Beanie and his gang put together his slasher video from spare parts and borrowed materials is as much fun as it must have been for them to make it .\n",
      "0.9 Watching Walt Becker and his gang put together his slasher video from spare parts and borrowed materials is as much fun as it must have been for them to make it .\n",
      "0.7 Watching Gosling and his gang put together his slasher video from spare parts and borrowed materials is as much fun as it must have been for them to make it .\n",
      "\n",
      "----\n",
      "0.3 For Benigni it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.8 For Carl Franklin it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.8 For Walt Becker it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "\n",
      "----\n",
      "0.5 More honest about Alzheimer 's disease , I think , than Iris .\n",
      "0.3 More honest about Alzheimer 's disease , I think , than Birot .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Change Movie Industries\n",
      "Test cases:      18\n",
      "Fails (rate):    1 (5.6%)\n",
      "\n",
      "Example fails:\n",
      "0.5 ( A ) Hollywood sheen bedevils the film from the very beginning ... ( but ) Lohman 's moist , deeply emotional eyes shine through this bogus veneer ...\n",
      "0.6 ( A ) Hogawood sheen bedevils the film from the very beginning ... ( but ) Lohman 's moist , deeply emotional eyes shine through this bogus veneer ...\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Temporal\n",
      "\n",
      "used to, but now\n",
      "Test cases:      2152\n",
      "Fails (rate):    99 (4.6%)\n",
      "\n",
      "Example fails:\n",
      "0.2 I value this movie, but I used to hate it.\n",
      "----\n",
      "0.6 In the past I would admire this movie, even though now I hate it.\n",
      "----\n",
      "0.6 In the past I would like this movie, even though now I dislike it.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Negation\n",
      "\n",
      "Simple negations: negative\n",
      "Test cases:      1350\n",
      "Fails (rate):    6 (0.4%)\n",
      "\n",
      "Example fails:\n",
      "0.6 I can't say I welcome this scene.\n",
      "----\n",
      "0.9 I can't say I welcome the scene.\n",
      "----\n",
      "0.8 I can't say I welcome this movie.\n",
      "----\n",
      "\n",
      "\n",
      "Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Test cases:      500\n",
      "Fails (rate):    80 (16.0%)\n",
      "\n",
      "Example fails:\n",
      "1.0 I can't say, given my history with movies, that this actor is amazing.\n",
      "----\n",
      "1.0 I can't say, given that I bought it last week, that the actor is wonderful.\n",
      "----\n",
      "0.8 I can't say, given that we watched a lot, that the was a beautiful director.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Synonym/Antonym\n",
      "\n",
      "Movie sentiments\n",
      "Test cases:      58\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sentiment\n",
      "\n",
      "Movie genre specific sentiments\n",
      "Test cases:      736\n",
      "Fails (rate):    39 (5.3%)\n",
      "\n",
      "Example fails:\n",
      "1.0 This comedy movie is serious, not rib-tickling\n",
      "----\n",
      "1.0 The comedy movie is serious\n",
      "----\n",
      "1.0 The comedy movie was serious, not rib-tickling\n",
      "----\n",
      "\n",
      "\n",
      "Movie Industries specific sentiments\n",
      "Test cases:      1200\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_suite.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "initial-gilbert",
   "metadata": {},
   "source": [
    "#### Random Seed 6 - Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "heated-composite",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"albert-large-v2\"\n",
    "checkpoint_path = \"model-outputs/final-models/rs6-shuffle-train/albert-large-v2_2.pt\"\n",
    "pipeline = BatchedInference.from_model_name(\n",
    "    model_name, checkpoint_path=checkpoint_path, device=\"cuda\"\n",
    ")\n",
    "\n",
    "def pred_and_conf(data, batch_size=32):\n",
    "    data = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    for data in data: \n",
    "        preds, confs = pipeline(data)\n",
    "        preds = preds.numpy().tolist()\n",
    "        confs = confs.numpy()\n",
    "        predictions.append(preds)\n",
    "        confidences.append(confs)\n",
    "    predictions = np.hstack(predictions)\n",
    "    confidences = np.vstack(confidences)\n",
    "    return predictions, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "injured-interference",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1zpj851s) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 10827<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 4.60MB of 4.60MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210914_090253-1zpj851s/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210914_090253-1zpj851s/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>test</td><td>used to, but now</td></tr><tr><td>_runtime</td><td>90</td></tr><tr><td>_timestamp</td><td>1631610269</td></tr><tr><td>_step</td><td>17</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_step</td><td>▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">rs5-swa-linear-60-start2-drop-shuffle_3_testset_19_07_21</strong>: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/1zpj851s\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/1zpj851s</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:1zpj851s). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.22<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">rs6-shuffle-train_2_testset_19_07_21</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ukh/checklist_evaluation\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/1g7pzo4y\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/1g7pzo4y</a><br/>\n",
       "                Run data is saved locally in <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210914_090645-1g7pzo4y</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Movie sentiments\n",
      "Predicting 58 examples\n",
      "Running Single positive words\n",
      "Predicting 22 examples\n",
      "Running Single negative words\n",
      "Predicting 14 examples\n",
      "Running Sentiment-laden words in context\n",
      "Predicting 1350 examples\n",
      "Running add positive phrases\n",
      "Predicting 5500 examples\n",
      "Running add negative phrases\n",
      "Predicting 5000 examples\n",
      "Running Simple negations: negative\n",
      "Predicting 1350 examples\n",
      "Running Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Predicting 500 examples\n",
      "Running Movie genre specific sentiments\n",
      "Predicting 736 examples\n",
      "Running Change names\n",
      "Predicting 1617 examples\n",
      "Running Polarizing Negative Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Polarizing Positive Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Negative Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Positive Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Change Movie Industries\n",
      "Predicting 252 examples\n",
      "Running Movie Industries specific sentiments\n",
      "Predicting 1200 examples\n",
      "Running change neutral words with BERT\n",
      "Predicting 3846 examples\n",
      "Running used to, but now\n",
      "Predicting 2152 examples\n"
     ]
    }
   ],
   "source": [
    "results_path = \"results/checklist/rs6-shuffle-train_2_testset_19_07_21.json\"\n",
    "config = {\n",
    "    \"project_name\": \"checklist_evaluation\", \n",
    "    \"run_name\": \"rs6-shuffle-train_2_testset_19_07_21\",\n",
    "    \"model\": \"albert-large-v2\", \n",
    "    \"checkpoint\": checkpoint_path, \n",
    "    \"test_suite\": test_suite_path,\n",
    "    \"results_path\": results_path\n",
    "}\n",
    "wandb.init(config=config, project=config[\"project_name\"], name=config[\"run_name\"])\n",
    "\n",
    "test_suite = TestSuite.from_file(test_suite_path)\n",
    "test_suite.run(pred_and_conf, overwrite=True, seed=0)\n",
    "save_test_results(config, test_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "interesting-ideal",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary\n",
      "\n",
      "Single positive words\n",
      "Test cases:      22\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Single negative words\n",
      "Test cases:      14\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Sentiment-laden words in context\n",
      "Test cases:      1350\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add positive phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add negative phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    11 (2.2%)\n",
      "\n",
      "Example fails:\n",
      "0.1 And in truth , cruel as it may sound , he makes Arnold Schwarzenegger look like Spencer Tracy .\n",
      "0.2 And in truth , cruel as it may sound , he makes Arnold Schwarzenegger look like Spencer Tracy. I abhor it.\n",
      "0.2 And in truth , cruel as it may sound , he makes Arnold Schwarzenegger look like Spencer Tracy. I despise it.\n",
      "\n",
      "----\n",
      "0.2 ( Director ) Byler may yet have a great movie in him , but Charlotte Sometimes is only half of one .\n",
      "0.3 ( Director ) Byler may yet have a great movie in him , but Charlotte Sometimes is only half of one. I dread it.\n",
      "\n",
      "----\n",
      "0.1 Though the book runs only about 300 pages , it is so densely packed ... that even an ambitious adaptation and elaborate production like Mr. Schepisi 's seems skimpy and unclear .\n",
      "0.2 Though the book runs only about 300 pages , it is so densely packed ... that even an ambitious adaptation and elaborate production like Mr. Schepisi 's seems skimpy and unclear. I abhor it.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "change neutral words with BERT\n",
      "Test cases:      500\n",
      "Fails (rate):    46 (9.2%)\n",
      "\n",
      "Example fails:\n",
      "0.9 Must be seen to be believed .\n",
      "0.5 Must be seen before be believed .\n",
      "\n",
      "----\n",
      "0.7 A film of precious increments artfully camouflaged as everyday activities .\n",
      "0.5 making film of precious increments artfully camouflaged as everyday activities .\n",
      "\n",
      "----\n",
      "0.3 The stories here suffer from the chosen format .\n",
      "0.9 The stories here suffer in the chosen format .\n",
      "0.7 The stories here suffer through the chosen format .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NER\n",
      "\n",
      "Change names\n",
      "Test cases:      147\n",
      "Fails (rate):    3 (2.0%)\n",
      "\n",
      "Example fails:\n",
      "0.4 I would have preferred a transfer down the hall to Mr. Holland 's class for the music , or to Robin Williams 's lecture so I could listen to a teacher with humor , passion , and verve .\n",
      "0.7 I would have preferred a transfer down the hall to Mr. Holland 's class for the music , or to Sarah Bennett lecture so I could listen to a teacher with humor , passion , and verve .\n",
      "0.6 I would have preferred a transfer down the hall to Mr. Holland 's class for the music , or to Jennifer Cruz lecture so I could listen to a teacher with humor , passion , and verve .\n",
      "\n",
      "----\n",
      "0.4 Arnold 's jump from little screen to big will leave frowns on more than a few faces .\n",
      "0.5 Nathaniel 's jump from little screen to big will leave frowns on more than a few faces .\n",
      "\n",
      "----\n",
      "0.8 Not so much funny as aggressively sitcom-cute , it 's full of throwaway one-liners , not-quite jokes , and a determined TV amiability that Allen personifies .\n",
      "0.3 Not so much funny as aggressively sitcom-cute , it 's full of throwaway one-liners , not-quite jokes , and a determined TV amiability that Luke personifies .\n",
      "0.3 Not so much funny as aggressively sitcom-cute , it 's full of throwaway one-liners , not-quite jokes , and a determined TV amiability that Luke personifies .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    3 (1.9%)\n",
      "\n",
      "Example fails:\n",
      "0.4 That Zhang would make such a strainingly cute film -- with a blind orphan at its center , no less -- indicates where his ambitions have wandered .\n",
      "0.8 Adam Rifkin would make such a strainingly cute film -- with a blind orphan at its center , no less -- indicates where his ambitions have wandered .\n",
      "0.8 Michel Gondry would make such a strainingly cute film -- with a blind orphan at its center , no less -- indicates where his ambitions have wandered .\n",
      "\n",
      "----\n",
      "0.4 For Benigni it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.8 For Michel Gondry it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.7 For Adam Rifkin it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "\n",
      "----\n",
      "0.4 ( Fessenden ) is much more into ambiguity and creating mood than he is for on screen thrills\n",
      "0.5 ( Einstein ) is much more into ambiguity and creating mood than he is for on screen thrills\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    5 (4.1%)\n",
      "\n",
      "Example fails:\n",
      "0.6 Imagine the James Woods character from Videodrome making a home movie of Audrey Rose and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "0.4 Imagine the Birot character from Videodrome making a home movie of Audrey Rose and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "\n",
      "----\n",
      "0.9 George , hire a real director and good writers for the next installment , please .\n",
      "0.1 Birot , hire a real director and good writers for the next installment , please .\n",
      "\n",
      "----\n",
      "0.4 Arnold 's jump from little screen to big will leave frowns on more than a few faces .\n",
      "0.7 Phillip Noyce 's jump from little screen to big will leave frowns on more than a few faces .\n",
      "0.6 Smokey Robinson 's jump from little screen to big will leave frowns on more than a few faces .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    4 (3.3%)\n",
      "\n",
      "Example fails:\n",
      "0.8 Not so much funny as aggressively sitcom-cute , it 's full of throwaway one-liners , not-quite jokes , and a determined TV amiability that Allen personifies .\n",
      "0.4 Not so much funny as aggressively sitcom-cute , it 's full of throwaway one-liners , not-quite jokes , and a determined TV amiability that Britney personifies .\n",
      "0.4 Not so much funny as aggressively sitcom-cute , it 's full of throwaway one-liners , not-quite jokes , and a determined TV amiability that Einstein personifies .\n",
      "\n",
      "----\n",
      "0.4 While Benigni ( who stars and co-wrote ) seems to be having a wonderful time , he might be alone in that .\n",
      "0.5 While Michel Gondry ( who stars and co-wrote ) seems to be having a wonderful time , he might be alone in that .\n",
      "0.5 While Adam Rifkin ( who stars and co-wrote ) seems to be having a wonderful time , he might be alone in that .\n",
      "\n",
      "----\n",
      "0.5 Director Brian Levant , who never strays far from his sitcom roots , skates blithely from one implausible situation to another , pausing only to tie up loose ends with more bows than you 'll find on a French poodle .\n",
      "0.7 Director Yvan Attal , who never strays far from his sitcom roots , skates blithely from one implausible situation to another , pausing only to tie up loose ends with more bows than you 'll find on a French poodle .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    4 (2.5%)\n",
      "\n",
      "Example fails:\n",
      "0.4 ( Fessenden ) is much more into ambiguity and creating mood than he is for on screen thrills\n",
      "0.6 ( Carl Franklin ) is much more into ambiguity and creating mood than he is for on screen thrills\n",
      "\n",
      "----\n",
      "0.4 For Benigni it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.8 For Walt Becker it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.7 For Carl Franklin it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "\n",
      "----\n",
      "0.4 That Zhang would make such a strainingly cute film -- with a blind orphan at its center , no less -- indicates where his ambitions have wandered .\n",
      "0.9 Walt Becker would make such a strainingly cute film -- with a blind orphan at its center , no less -- indicates where his ambitions have wandered .\n",
      "0.8 Phillip Noyce would make such a strainingly cute film -- with a blind orphan at its center , no less -- indicates where his ambitions have wandered .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Change Movie Industries\n",
      "Test cases:      18\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Temporal\n",
      "\n",
      "used to, but now\n",
      "Test cases:      2152\n",
      "Fails (rate):    151 (7.0%)\n",
      "\n",
      "Example fails:\n",
      "0.1 I recommend this movie, but I used to dislike it.\n",
      "----\n",
      "0.3 I appreciate this movie, but I used to dislike it.\n",
      "----\n",
      "1.0 I hate this movie, but I used to recommend it.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Negation\n",
      "\n",
      "Simple negations: negative\n",
      "Test cases:      1350\n",
      "Fails (rate):    16 (1.2%)\n",
      "\n",
      "Example fails:\n",
      "1.0 I can't say I appreciate this director.\n",
      "----\n",
      "1.0 I can't say I appreciate the actor.\n",
      "----\n",
      "0.7 I can't say I admire this director.\n",
      "----\n",
      "\n",
      "\n",
      "Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Test cases:      500\n",
      "Fails (rate):    88 (17.6%)\n",
      "\n",
      "Example fails:\n",
      "1.0 I can't say, given that I bought it last week, that this was a brilliant movie.\n",
      "----\n",
      "1.0 I wouldn't say, given all that I've seen over the years, that this actor is wonderful.\n",
      "----\n",
      "0.8 I don't think, given it's a Friday, that this director is amazing.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Synonym/Antonym\n",
      "\n",
      "Movie sentiments\n",
      "Test cases:      58\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sentiment\n",
      "\n",
      "Movie genre specific sentiments\n",
      "Test cases:      736\n",
      "Fails (rate):    42 (5.7%)\n",
      "\n",
      "Example fails:\n",
      "1.0 The comedy movie is serious, not rib-tickling\n",
      "----\n",
      "0.3 This comedy movie was rib-tickling\n",
      "----\n",
      "0.0 This horror movie was terrifying\n",
      "----\n",
      "\n",
      "\n",
      "Movie Industries specific sentiments\n",
      "Test cases:      1200\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_suite.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "artificial-popularity",
   "metadata": {},
   "source": [
    "#### Random Seed 6 - SWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "stuffed-baseline",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"albert-large-v2\"\n",
    "checkpoint_path = \"model-outputs/final-models/rs6-swa-linear-60-start2-drop-shuffle/albert-large-v2_7.pt\"\n",
    "pipeline = BatchedInference.from_model_name(\n",
    "    model_name, checkpoint_path=checkpoint_path, device=\"cuda\"\n",
    ")\n",
    "\n",
    "def pred_and_conf(data, batch_size=32):\n",
    "    data = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    for data in data: \n",
    "        preds, confs = pipeline(data)\n",
    "        preds = preds.numpy().tolist()\n",
    "        confs = confs.numpy()\n",
    "        predictions.append(preds)\n",
    "        confidences.append(confs)\n",
    "    predictions = np.hstack(predictions)\n",
    "    confidences = np.vstack(confidences)\n",
    "    return predictions, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "retained-neighborhood",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1g7pzo4y) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 11053<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 4.63MB of 4.63MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210914_090645-1g7pzo4y/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210914_090645-1g7pzo4y/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>test</td><td>used to, but now</td></tr><tr><td>_runtime</td><td>90</td></tr><tr><td>_timestamp</td><td>1631610499</td></tr><tr><td>_step</td><td>17</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_step</td><td>▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">rs6-shuffle-train_2_testset_19_07_21</strong>: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/1g7pzo4y\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/1g7pzo4y</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:1g7pzo4y). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.22<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">rs6-swa-linear-60-start2-drop-shuffle_7_testset_19_07_21</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ukh/checklist_evaluation\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/1899lrs4\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/1899lrs4</a><br/>\n",
       "                Run data is saved locally in <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210914_091640-1899lrs4</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Movie sentiments\n",
      "Predicting 58 examples\n",
      "Running Single positive words\n",
      "Predicting 22 examples\n",
      "Running Single negative words\n",
      "Predicting 14 examples\n",
      "Running Sentiment-laden words in context\n",
      "Predicting 1350 examples\n",
      "Running add positive phrases\n",
      "Predicting 5500 examples\n",
      "Running add negative phrases\n",
      "Predicting 5000 examples\n",
      "Running Simple negations: negative\n",
      "Predicting 1350 examples\n",
      "Running Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Predicting 500 examples\n",
      "Running Movie genre specific sentiments\n",
      "Predicting 736 examples\n",
      "Running Change names\n",
      "Predicting 1617 examples\n",
      "Running Polarizing Negative Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Polarizing Positive Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Negative Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Positive Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Change Movie Industries\n",
      "Predicting 252 examples\n",
      "Running Movie Industries specific sentiments\n",
      "Predicting 1200 examples\n",
      "Running change neutral words with BERT\n",
      "Predicting 3846 examples\n",
      "Running used to, but now\n",
      "Predicting 2152 examples\n"
     ]
    }
   ],
   "source": [
    "results_path = \"results/checklist/rs6-swa-linear-60-start2-drop-shuffle_7_testset_19_07_21.json\"\n",
    "config = {\n",
    "    \"project_name\": \"checklist_evaluation\", \n",
    "    \"run_name\": \"rs6-swa-linear-60-start2-drop-shuffle_7_testset_19_07_21\",\n",
    "    \"model\": \"albert-large-v2\", \n",
    "    \"checkpoint\": checkpoint_path, \n",
    "    \"test_suite\": test_suite_path,\n",
    "    \"results_path\": results_path\n",
    "}\n",
    "wandb.init(config=config, project=config[\"project_name\"], name=config[\"run_name\"])\n",
    "\n",
    "test_suite = TestSuite.from_file(test_suite_path)\n",
    "test_suite.run(pred_and_conf, overwrite=True, seed=0)\n",
    "save_test_results(config, test_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "surprising-wales",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary\n",
      "\n",
      "Single positive words\n",
      "Test cases:      22\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Single negative words\n",
      "Test cases:      14\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Sentiment-laden words in context\n",
      "Test cases:      1350\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add positive phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    1 (0.2%)\n",
      "\n",
      "Example fails:\n",
      "1.0 Is n't it great ?\n",
      "0.0 Is n't it great. I would watch this again.\n",
      "0.0 Is n't it great. I value it.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "add negative phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    3 (0.6%)\n",
      "\n",
      "Example fails:\n",
      "0.0 Director Dirk Shafer and co-writer Greg Hinton ride the dubious divide where gay porn reaches for serious drama .\n",
      "0.1 Director Dirk Shafer and co-writer Greg Hinton ride the dubious divide where gay porn reaches for serious drama. I abhor it.\n",
      "\n",
      "----\n",
      "0.0 Roger Michell , who did an appealing job directing Persuasion and Notting Hill in England , gets too artsy in his American debut .\n",
      "0.1 Roger Michell , who did an appealing job directing Persuasion and Notting Hill in England , gets too artsy in his American debut. I abhor it.\n",
      "\n",
      "----\n",
      "0.0 This pep-talk for faith , hope and charity does little to offend , but if saccharine earnestness were a crime , the film 's producers would be in the clink for life .\n",
      "0.1 This pep-talk for faith , hope and charity does little to offend , but if saccharine earnestness were a crime , the film 's producers would be in the clink for life. I abhor it.\n",
      "0.1 This pep-talk for faith , hope and charity does little to offend , but if saccharine earnestness were a crime , the film 's producers would be in the clink for life. I regret it.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "change neutral words with BERT\n",
      "Test cases:      500\n",
      "Fails (rate):    34 (6.8%)\n",
      "\n",
      "Example fails:\n",
      "0.3 It is not a mass-market entertainment but an uncompromising attempt by one artist to think about another .\n",
      "0.8 It is not a mass-market entertainment but an uncompromising attempt by one artist to think with another .\n",
      "0.7 It is not a mass-market entertainment but the uncompromising attempt by one artist to think about another .\n",
      "\n",
      "----\n",
      "0.9 In its ragged , cheap and unassuming way , the movie works .\n",
      "0.4 In its ragged , cheap and unassuming way , the above works .\n",
      "\n",
      "----\n",
      "0.0 The film is just a big , gorgeous , mind-blowing , breath-taking mess .\n",
      "1.0 The film is just this big , gorgeous , mind-blowing , breath-taking mess .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NER\n",
      "\n",
      "Change names\n",
      "Test cases:      147\n",
      "Fails (rate):    4 (2.7%)\n",
      "\n",
      "Example fails:\n",
      "0.3 George , hire a real director and good writers for the next installment , please .\n",
      "1.0 Austin , hire a real director and good writers for the next installment , please .\n",
      "1.0 Scott , hire a real director and good writers for the next installment , please .\n",
      "\n",
      "----\n",
      "0.6 Adam Sandler is to Gary Cooper what a gnat is to a racehorse .\n",
      "0.3 John Bailey is to Gary Cooper what a gnat is to a racehorse .\n",
      "0.3 Joshua Nelson is to Gary Cooper what a gnat is to a racehorse .\n",
      "\n",
      "----\n",
      "0.4 Arnold 's jump from little screen to big will leave frowns on more than a few faces .\n",
      "0.7 Nathaniel 's jump from little screen to big will leave frowns on more than a few faces .\n",
      "0.5 Luke 's jump from little screen to big will leave frowns on more than a few faces .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    7 (4.5%)\n",
      "\n",
      "Example fails:\n",
      "0.2 For Benigni it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.8 For Paul Pender it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.8 For Mat Hoffman it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "\n",
      "----\n",
      "0.6 A sensual performance from Abbass buoys the flimsy story , but her inner journey is largely unexplored and we 're left wondering about this exotic-looking woman whose emotional depths are only hinted at .\n",
      "0.4 A sensual performance from Britney buoys the flimsy story , but her inner journey is largely unexplored and we 're left wondering about this exotic-looking woman whose emotional depths are only hinted at .\n",
      "0.4 A sensual performance from Crispin Glover buoys the flimsy story , but her inner journey is largely unexplored and we 're left wondering about this exotic-looking woman whose emotional depths are only hinted at .\n",
      "\n",
      "----\n",
      "0.1 More honest about Alzheimer 's disease , I think , than Iris .\n",
      "0.8 More honest about Alzheimer 's disease , I think , than Paul Pender .\n",
      "0.6 More honest about Alzheimer 's disease , I think , than Adam Rifkin .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    6 (4.9%)\n",
      "\n",
      "Example fails:\n",
      "0.3 George , hire a real director and good writers for the next installment , please .\n",
      "1.0 Foster , hire a real director and good writers for the next installment , please .\n",
      "1.0 Walt Becker , hire a real director and good writers for the next installment , please .\n",
      "\n",
      "----\n",
      "0.4 Arnold 's jump from little screen to big will leave frowns on more than a few faces .\n",
      "0.6 Walt Becker 's jump from little screen to big will leave frowns on more than a few faces .\n",
      "0.6 Phillip Noyce 's jump from little screen to big will leave frowns on more than a few faces .\n",
      "\n",
      "----\n",
      "0.8 Has it ever been possible to say that Williams has truly inhabited a character ?\n",
      "0.3 Has it ever been possible to say that Merchant Ivory has truly inhabited a character ?\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    9 (7.3%)\n",
      "\n",
      "Example fails:\n",
      "0.3 While Benigni ( who stars and co-wrote ) seems to be having a wonderful time , he might be alone in that .\n",
      "0.5 While Michel Gondry ( who stars and co-wrote ) seems to be having a wonderful time , he might be alone in that .\n",
      "0.5 While Adam Rifkin ( who stars and co-wrote ) seems to be having a wonderful time , he might be alone in that .\n",
      "\n",
      "----\n",
      "0.3 Based on a David Leavitt story , the film shares that writer 's usual blend of observant cleverness , too-facile coincidence and slightly noxious preciousness .\n",
      "0.9 Based on a Crispin Glover story , the film shares that writer 's usual blend of observant cleverness , too-facile coincidence and slightly noxious preciousness .\n",
      "\n",
      "----\n",
      "0.6 Home Alone goes Hollywood , a funny premise until the kids start pulling off stunts not even Steven Spielberg would know how to do .\n",
      "0.3 Home Alone goes Hollywood , a funny premise until the kids start pulling off stunts not even Jelinek would know how to do .\n",
      "0.3 Home Alone goes Hollywood , a funny premise until the kids start pulling off stunts not even Crispin Glover would know how to do .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    7 (4.5%)\n",
      "\n",
      "Example fails:\n",
      "0.8 Sam Jones became a very lucky filmmaker the day Wilco got dropped from their record label , proving that one man 's ruin may be another 's fortune .\n",
      "0.2 Merchant Ivory became a very lucky filmmaker the day Wilco got dropped from their record label , proving that one man 's ruin may be another 's fortune .\n",
      "\n",
      "----\n",
      "0.6 A sensual performance from Abbass buoys the flimsy story , but her inner journey is largely unexplored and we 're left wondering about this exotic-looking woman whose emotional depths are only hinted at .\n",
      "0.4 A sensual performance from Ellen Pompeo buoys the flimsy story , but her inner journey is largely unexplored and we 're left wondering about this exotic-looking woman whose emotional depths are only hinted at .\n",
      "0.4 A sensual performance from Carl Franklin buoys the flimsy story , but her inner journey is largely unexplored and we 're left wondering about this exotic-looking woman whose emotional depths are only hinted at .\n",
      "\n",
      "----\n",
      "0.1 More honest about Alzheimer 's disease , I think , than Iris .\n",
      "0.7 More honest about Alzheimer 's disease , I think , than Craig Bartlett .\n",
      "0.6 More honest about Alzheimer 's disease , I think , than Carl Franklin .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Change Movie Industries\n",
      "Test cases:      18\n",
      "Fails (rate):    2 (11.1%)\n",
      "\n",
      "Example fails:\n",
      "0.6 Home Alone goes Hollywood , a funny premise until the kids start pulling off stunts not even Steven Spielberg would know how to do .\n",
      "0.4 Home Alone goes Hogawood , a funny premise until the kids start pulling off stunts not even Steven Spielberg would know how to do .\n",
      "\n",
      "----\n",
      "0.1 Even when foreign directors ... borrow stuff from Hollywood , they invariably shake up the formula and make it more interesting .\n",
      "0.9 Even when foreign directors ... borrow stuff from Cantonwood , they invariably shake up the formula and make it more interesting .\n",
      "0.9 Even when foreign directors ... borrow stuff from Taiwood , they invariably shake up the formula and make it more interesting .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Temporal\n",
      "\n",
      "used to, but now\n",
      "Test cases:      2152\n",
      "Fails (rate):    68 (3.2%)\n",
      "\n",
      "Example fails:\n",
      "0.0 I think this movie is brilliant, but I used to think it was bad.\n",
      "----\n",
      "0.7 I despise this movie, but in the past I would recommend it.\n",
      "----\n",
      "0.3 I value this movie, but I used to hate it.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Negation\n",
      "\n",
      "Simple negations: negative\n",
      "Test cases:      1350\n",
      "Fails (rate):    4 (0.3%)\n",
      "\n",
      "Example fails:\n",
      "1.0 I can't say I appreciate this actor.\n",
      "----\n",
      "0.9 I can't say I appreciate that actor.\n",
      "----\n",
      "1.0 I can't say I appreciate the director.\n",
      "----\n",
      "\n",
      "\n",
      "Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Test cases:      500\n",
      "Fails (rate):    50 (10.0%)\n",
      "\n",
      "Example fails:\n",
      "1.0 I can't say, given that I bought it last week, that this was a brilliant movie.\n",
      "----\n",
      "0.8 I can't say, given it's a Friday, that we appreciate this director.\n",
      "----\n",
      "1.0 I can't say, given my history with movies, that the actor is wonderful.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Synonym/Antonym\n",
      "\n",
      "Movie sentiments\n",
      "Test cases:      58\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sentiment\n",
      "\n",
      "Movie genre specific sentiments\n",
      "Test cases:      736\n",
      "Fails (rate):    37 (5.0%)\n",
      "\n",
      "Example fails:\n",
      "1.0 This comedy movie is serious\n",
      "----\n",
      "0.6 This comedy movie is scary rather than rib-tickling\n",
      "----\n",
      "0.0 The horror movie was frightening\n",
      "----\n",
      "\n",
      "\n",
      "Movie Industries specific sentiments\n",
      "Test cases:      1200\n",
      "Fails (rate):    4 (0.3%)\n",
      "\n",
      "Example fails:\n",
      "0.5 Hallyuwood movies are tough\n",
      "----\n",
      "0.6 Hogawood movies are tough\n",
      "----\n",
      "0.5 The Tamalewood movie is tough\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_suite.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "improved-therapist",
   "metadata": {},
   "source": [
    "#### Random Seed 7 - Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ceramic-pantyhose",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"albert-large-v2\"\n",
    "checkpoint_path = \"model-outputs/final-models/rs7-shuffle-train/albert-large-v2_2.pt\"\n",
    "pipeline = BatchedInference.from_model_name(\n",
    "    model_name, checkpoint_path=checkpoint_path, device=\"cuda\"\n",
    ")\n",
    "\n",
    "def pred_and_conf(data, batch_size=32):\n",
    "    data = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    for data in data: \n",
    "        preds, confs = pipeline(data)\n",
    "        preds = preds.numpy().tolist()\n",
    "        confs = confs.numpy()\n",
    "        predictions.append(preds)\n",
    "        confidences.append(confs)\n",
    "    predictions = np.hstack(predictions)\n",
    "    confidences = np.vstack(confidences)\n",
    "    return predictions, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "focused-reception",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1899lrs4) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 11471<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 4.62MB of 4.62MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210914_091640-1899lrs4/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210914_091640-1899lrs4/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>test</td><td>used to, but now</td></tr><tr><td>_runtime</td><td>90</td></tr><tr><td>_timestamp</td><td>1631611094</td></tr><tr><td>_step</td><td>17</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_step</td><td>▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">rs6-swa-linear-60-start2-drop-shuffle_7_testset_19_07_21</strong>: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/1899lrs4\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/1899lrs4</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:1899lrs4). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.22<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">rs7-shuffle-train_2_testset_19_07_21</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ukh/checklist_evaluation\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/9274g0l6\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/9274g0l6</a><br/>\n",
       "                Run data is saved locally in <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210914_091842-9274g0l6</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Movie sentiments\n",
      "Predicting 58 examples\n",
      "Running Single positive words\n",
      "Predicting 22 examples\n",
      "Running Single negative words\n",
      "Predicting 14 examples\n",
      "Running Sentiment-laden words in context\n",
      "Predicting 1350 examples\n",
      "Running add positive phrases\n",
      "Predicting 5500 examples\n",
      "Running add negative phrases\n",
      "Predicting 5000 examples\n",
      "Running Simple negations: negative\n",
      "Predicting 1350 examples\n",
      "Running Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Predicting 500 examples\n",
      "Running Movie genre specific sentiments\n",
      "Predicting 736 examples\n",
      "Running Change names\n",
      "Predicting 1617 examples\n",
      "Running Polarizing Negative Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Polarizing Positive Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Negative Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Positive Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Change Movie Industries\n",
      "Predicting 252 examples\n",
      "Running Movie Industries specific sentiments\n",
      "Predicting 1200 examples\n",
      "Running change neutral words with BERT\n",
      "Predicting 3846 examples\n",
      "Running used to, but now\n",
      "Predicting 2152 examples\n"
     ]
    }
   ],
   "source": [
    "results_path = \"results/checklist/rs7-shuffle-train_2_testset_19_07_21.json\"\n",
    "config = {\n",
    "    \"project_name\": \"checklist_evaluation\", \n",
    "    \"run_name\": \"rs7-shuffle-train_2_testset_19_07_21\",\n",
    "    \"model\": \"albert-large-v2\", \n",
    "    \"checkpoint\": checkpoint_path, \n",
    "    \"test_suite\": test_suite_path,\n",
    "    \"results_path\": results_path\n",
    "}\n",
    "wandb.init(config=config, project=config[\"project_name\"], name=config[\"run_name\"])\n",
    "\n",
    "test_suite = TestSuite.from_file(test_suite_path)\n",
    "test_suite.run(pred_and_conf, overwrite=True, seed=0)\n",
    "save_test_results(config, test_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "optical-bulgarian",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary\n",
      "\n",
      "Single positive words\n",
      "Test cases:      22\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Single negative words\n",
      "Test cases:      14\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Sentiment-laden words in context\n",
      "Test cases:      1350\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add positive phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add negative phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    2 (0.4%)\n",
      "\n",
      "Example fails:\n",
      "0.0 Too bad the former Murphy Brown does n't pop Reese back .\n",
      "0.1 Too bad the former Murphy Brown does n't pop Reese back. I regret it.\n",
      "\n",
      "----\n",
      "0.9 This is such a high-energy movie where the drumming and the marching are so excellent , who cares if the story 's a little weak .\n",
      "0.9 This is such a high-energy movie where the drumming and the marching are so excellent , who cares if the story 's a little weak. I dread it.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "change neutral words with BERT\n",
      "Test cases:      500\n",
      "Fails (rate):    39 (7.8%)\n",
      "\n",
      "Example fails:\n",
      "0.9 Disney 's live-action division has a history of releasing cinematic flotsam , but this is one occasion when they have unearthed a rare gem .\n",
      "0.4 Disney 's live-action division has a history of releasing cinematic flotsam , but this is one occasion when they seemingly unearthed a rare gem .\n",
      "\n",
      "----\n",
      "1.0 An impressive if flawed effort that indicates real talent .\n",
      "0.0 An impressive if flawed effort hardly indicates real talent .\n",
      "0.1 An impressive if flawed effort rarely indicates real talent .\n",
      "\n",
      "----\n",
      "0.5 In its ragged , cheap and unassuming way , the movie works .\n",
      "0.0 In its ragged , cheap and unassuming way , the above works .\n",
      "0.1 In its ragged , cheap and unassuming way , the code works .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NER\n",
      "\n",
      "Change names\n",
      "Test cases:      147\n",
      "Fails (rate):    1 (0.7%)\n",
      "\n",
      "Example fails:\n",
      "0.5 George , hire a real director and good writers for the next installment , please .\n",
      "0.4 Luke , hire a real director and good writers for the next installment , please .\n",
      "0.4 Luke , hire a real director and good writers for the next installment , please .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    4 (2.5%)\n",
      "\n",
      "Example fails:\n",
      "0.5 For Benigni it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.7 For Paul Pender it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.7 For Einstein it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "\n",
      "----\n",
      "0.0 Who knows what exactly Godard is on about in this film , but his words and images do n't have to add up to mesmerize you .\n",
      "1.0 Who knows what exactly Crispin Glover is on about in this film , but his words and images do n't have to add up to mesmerize you .\n",
      "\n",
      "----\n",
      "0.2 Droll caper-comedy remake of `` Big Deal on Madonna Street '' that 's a sly , amusing , laugh-filled little gem in which the ultimate `` Bellini '' begins to look like a `` real Kaputschnik . ''\n",
      "1.0 Droll caper-comedy remake of `` Big Deal on Madonna Street '' that 's a sly , amusing , laugh-filled little gem in which the ultimate `` Bellini '' begins to look like a `` real Mat Hoffman . ''\n",
      "1.0 Droll caper-comedy remake of `` Big Deal on Madonna Street '' that 's a sly , amusing , laugh-filled little gem in which the ultimate `` Bellini '' begins to look like a `` real Carol Kane . ''\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    5 (4.1%)\n",
      "\n",
      "Example fails:\n",
      "0.8 Imagine the James Woods character from Videodrome making a home movie of Audrey Rose and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "0.2 Imagine the Birot character from Videodrome making a home movie of Audrey Rose and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "0.4 Imagine the James Woods character from Videodrome making a home movie of Polanski and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "\n",
      "----\n",
      "0.4 Warmed-over Tarantino by way of wannabe Elmore Leonard .\n",
      "0.5 Warmed-over Tarantino by way of wannabe Walt Becker .\n",
      "\n",
      "----\n",
      "0.7 Watching Haneke 's film is , aptly enough , a challenge and a punishment .\n",
      "0.5 Watching Birot 's film is , aptly enough , a challenge and a punishment .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    5 (4.1%)\n",
      "\n",
      "Example fails:\n",
      "0.6 Adam Sandler is to Gary Cooper what a gnat is to a racehorse .\n",
      "0.4 Adam Sandler is to Reginald Hudlin what a gnat is to a racehorse .\n",
      "0.4 Adam Sandler is to Reginald Hudlin what a gnat is to a racehorse .\n",
      "\n",
      "----\n",
      "0.7 Watching Haneke 's film is , aptly enough , a challenge and a punishment .\n",
      "0.4 Watching Britney 's film is , aptly enough , a challenge and a punishment .\n",
      "\n",
      "----\n",
      "0.6 I would have preferred a transfer down the hall to Mr. Holland 's class for the music , or to Robin Williams 's lecture so I could listen to a teacher with humor , passion , and verve .\n",
      "0.5 I would have preferred a transfer down the hall to Mr. Yvan Attal 's class for the music , or to Robin Williams 's lecture so I could listen to a teacher with humor , passion , and verve .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    3 (1.9%)\n",
      "\n",
      "Example fails:\n",
      "0.5 For Benigni it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.8 For Carl Franklin it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.7 For Walt Becker it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "\n",
      "----\n",
      "0.7 More honest about Alzheimer 's disease , I think , than Iris .\n",
      "0.3 More honest about Alzheimer 's disease , I think , than Birot .\n",
      "0.5 More honest about Alzheimer 's disease , I think , than Foster .\n",
      "\n",
      "----\n",
      "0.2 Droll caper-comedy remake of `` Big Deal on Madonna Street '' that 's a sly , amusing , laugh-filled little gem in which the ultimate `` Bellini '' begins to look like a `` real Kaputschnik . ''\n",
      "1.0 Droll caper-comedy remake of `` Big Deal on Madonna Street '' that 's a sly , amusing , laugh-filled little gem in which the ultimate `` Bellini '' begins to look like a `` real Walt Becker . ''\n",
      "1.0 Droll caper-comedy remake of `` Big Deal on Madonna Street '' that 's a sly , amusing , laugh-filled little gem in which the ultimate `` Bellini '' begins to look like a `` real Carl Franklin . ''\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Change Movie Industries\n",
      "Test cases:      18\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Temporal\n",
      "\n",
      "used to, but now\n",
      "Test cases:      2152\n",
      "Fails (rate):    94 (4.4%)\n",
      "\n",
      "Example fails:\n",
      "0.3 I think this movie is fantastic, but I used to think it was terrible.\n",
      "----\n",
      "0.2 I appreciate this movie, but I used to hate it.\n",
      "----\n",
      "0.1 I admire this movie, but I used to hate it.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Negation\n",
      "\n",
      "Simple negations: negative\n",
      "Test cases:      1350\n",
      "Fails (rate):    11 (0.8%)\n",
      "\n",
      "Example fails:\n",
      "1.0 I would never say I appreciate this director.\n",
      "----\n",
      "1.0 I can't say I appreciate this actor.\n",
      "----\n",
      "1.0 I would never say I appreciate the director.\n",
      "----\n",
      "\n",
      "\n",
      "Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Test cases:      500\n",
      "Fails (rate):    70 (14.0%)\n",
      "\n",
      "Example fails:\n",
      "1.0 I wouldn't say, given all that I've seen over the years, that this actor is wonderful.\n",
      "----\n",
      "0.8 I can't say, given that I bought it last week, that that movie was amazing.\n",
      "----\n",
      "0.6 I wouldn't say, given that we watched a lot, that the director is wonderful.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Synonym/Antonym\n",
      "\n",
      "Movie sentiments\n",
      "Test cases:      58\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sentiment\n",
      "\n",
      "Movie genre specific sentiments\n",
      "Test cases:      736\n",
      "Fails (rate):    32 (4.3%)\n",
      "\n",
      "Example fails:\n",
      "1.0 The comedy movie is serious, not rib-tickling\n",
      "----\n",
      "0.8 The drama movie was funny rather than serious\n",
      "----\n",
      "0.9 This drama movie is funny rather than serious\n",
      "----\n",
      "\n",
      "\n",
      "Movie Industries specific sentiments\n",
      "Test cases:      1200\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_suite.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ahead-maldives",
   "metadata": {},
   "source": [
    "#### Random Seed 7 - SWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "taken-packet",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"albert-large-v2\"\n",
    "checkpoint_path = \"model-outputs/final-models/rs7-swa-linear-60-start2-drop-shuffle/albert-large-v2_6.pt\"\n",
    "pipeline = BatchedInference.from_model_name(\n",
    "    model_name, checkpoint_path=checkpoint_path, device=\"cuda\"\n",
    ")\n",
    "\n",
    "def pred_and_conf(data, batch_size=32):\n",
    "    data = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    for data in data: \n",
    "        preds, confs = pipeline(data)\n",
    "        preds = preds.numpy().tolist()\n",
    "        confs = confs.numpy()\n",
    "        predictions.append(preds)\n",
    "        confidences.append(confs)\n",
    "    predictions = np.hstack(predictions)\n",
    "    confidences = np.vstack(confidences)\n",
    "    return predictions, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "imposed-prophet",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:9274g0l6) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 11515<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 4.60MB of 4.60MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210914_091842-9274g0l6/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210914_091842-9274g0l6/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>test</td><td>used to, but now</td></tr><tr><td>_runtime</td><td>92</td></tr><tr><td>_timestamp</td><td>1631611217</td></tr><tr><td>_step</td><td>17</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_step</td><td>▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">rs7-shuffle-train_2_testset_19_07_21</strong>: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/9274g0l6\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/9274g0l6</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:9274g0l6). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.22<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">rs7-swa-linear-60-start2-drop-shuffle_6_testset_19_07_21</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ukh/checklist_evaluation\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/4vpi7k6i\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/4vpi7k6i</a><br/>\n",
       "                Run data is saved locally in <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210914_092029-4vpi7k6i</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Movie sentiments\n",
      "Predicting 58 examples\n",
      "Running Single positive words\n",
      "Predicting 22 examples\n",
      "Running Single negative words\n",
      "Predicting 14 examples\n",
      "Running Sentiment-laden words in context\n",
      "Predicting 1350 examples\n",
      "Running add positive phrases\n",
      "Predicting 5500 examples\n",
      "Running add negative phrases\n",
      "Predicting 5000 examples\n",
      "Running Simple negations: negative\n",
      "Predicting 1350 examples\n",
      "Running Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Predicting 500 examples\n",
      "Running Movie genre specific sentiments\n",
      "Predicting 736 examples\n",
      "Running Change names\n",
      "Predicting 1617 examples\n",
      "Running Polarizing Negative Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Polarizing Positive Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Negative Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Positive Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Change Movie Industries\n",
      "Predicting 252 examples\n",
      "Running Movie Industries specific sentiments\n",
      "Predicting 1200 examples\n",
      "Running change neutral words with BERT\n",
      "Predicting 3846 examples\n",
      "Running used to, but now\n",
      "Predicting 2152 examples\n"
     ]
    }
   ],
   "source": [
    "results_path = \"results/checklist/rs7-swa-linear-60-start2-drop-shuffle_6_testset_19_07_21.json\"\n",
    "config = {\n",
    "    \"project_name\": \"checklist_evaluation\", \n",
    "    \"run_name\": \"rs7-swa-linear-60-start2-drop-shuffle_6_testset_19_07_21\",\n",
    "    \"model\": \"albert-large-v2\", \n",
    "    \"checkpoint\": checkpoint_path, \n",
    "    \"test_suite\": test_suite_path,\n",
    "    \"results_path\": results_path\n",
    "}\n",
    "wandb.init(config=config, project=config[\"project_name\"], name=config[\"run_name\"])\n",
    "\n",
    "test_suite = TestSuite.from_file(test_suite_path)\n",
    "test_suite.run(pred_and_conf, overwrite=True, seed=0)\n",
    "save_test_results(config, test_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "incorporated-palestinian",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary\n",
      "\n",
      "Single positive words\n",
      "Test cases:      22\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Single negative words\n",
      "Test cases:      14\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Sentiment-laden words in context\n",
      "Test cases:      1350\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add positive phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add negative phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    1 (0.2%)\n",
      "\n",
      "Example fails:\n",
      "0.0 Schindler 's List it ai n't .\n",
      "0.2 Schindler 's List it ai n't. I regret it.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "change neutral words with BERT\n",
      "Test cases:      500\n",
      "Fails (rate):    34 (6.8%)\n",
      "\n",
      "Example fails:\n",
      "0.8 Like a south-of-the-border Melrose Place .\n",
      "0.1 Like another south-of-the-border Melrose Place .\n",
      "0.5 Like in south-of-the-border Melrose Place .\n",
      "\n",
      "----\n",
      "1.0 Workmanlike , maybe , but still a film with all the elements that made the other three great , scary times at the movies .\n",
      "0.0 Workmanlike , maybe , but still a film lacking all the elements that made the other three great , scary times at the movies .\n",
      "\n",
      "----\n",
      "1.0 In its ragged , cheap and unassuming way , the movie works .\n",
      "0.3 In its ragged , cheap and unassuming way , the above works .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NER\n",
      "\n",
      "Change names\n",
      "Test cases:      147\n",
      "Fails (rate):    4 (2.7%)\n",
      "\n",
      "Example fails:\n",
      "0.6 Imagine the James Woods character from Videodrome making a home movie of Audrey Rose and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "0.4 Imagine the Joseph Phillips character from Videodrome making a home movie of Audrey Rose and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "0.5 Imagine the James Woods character from Videodrome making a home movie of Melissa White and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "\n",
      "----\n",
      "0.6 ( Davis ) has a bright , chipper style that keeps things moving , while never quite managing to connect her wish-fulfilling characters to the human race .\n",
      "0.5 ( Luke ) has a bright , chipper style that keeps things moving , while never quite managing to connect her wish-fulfilling characters to the human race .\n",
      "0.5 ( Luke ) has a bright , chipper style that keeps things moving , while never quite managing to connect her wish-fulfilling characters to the human race .\n",
      "\n",
      "----\n",
      "0.6 The principals in this cast are all fine , but Bishop and Stevenson are standouts .\n",
      "0.2 The principals in this cast are all fine , but Bishop and William are standouts .\n",
      "0.4 The principals in this cast are all fine , but Bishop and Luke are standouts .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    4 (2.5%)\n",
      "\n",
      "Example fails:\n",
      "0.8 ( A ) Hollywood sheen bedevils the film from the very beginning ... ( but ) Lohman 's moist , deeply emotional eyes shine through this bogus veneer ...\n",
      "0.2 ( A ) Hollywood sheen bedevils the film from the very beginning ... ( but ) Einstein 's moist , deeply emotional eyes shine through this bogus veneer ...\n",
      "0.3 ( A ) Hollywood sheen bedevils the film from the very beginning ... ( but ) Britney 's moist , deeply emotional eyes shine through this bogus veneer ...\n",
      "\n",
      "----\n",
      "0.7 For Benigni it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.3 For Britney it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "\n",
      "----\n",
      "0.6 ( Davis ) has a bright , chipper style that keeps things moving , while never quite managing to connect her wish-fulfilling characters to the human race .\n",
      "0.3 ( Einstein ) has a bright , chipper style that keeps things moving , while never quite managing to connect her wish-fulfilling characters to the human race .\n",
      "0.5 ( Crispin Glover ) has a bright , chipper style that keeps things moving , while never quite managing to connect her wish-fulfilling characters to the human race .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    5 (4.1%)\n",
      "\n",
      "Example fails:\n",
      "0.6 Imagine the James Woods character from Videodrome making a home movie of Audrey Rose and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "0.2 Imagine the Birot character from Videodrome making a home movie of Audrey Rose and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "0.5 Imagine the Craig Bartlett character from Videodrome making a home movie of Audrey Rose and showing it to the kid from The Sixth Sense and you 've imagined The Ring .\n",
      "\n",
      "----\n",
      "0.3 Oedekerk wrote Patch Adams , for which he should not be forgiven .\n",
      "0.8 Oedekerk wrote Carl Franklin , for which he should not be forgiven .\n",
      "\n",
      "----\n",
      "0.7 Its lack of quality earns it a place alongside those other two recent Dumas botch-jobs , The Man in the Iron Mask and The Musketeer .\n",
      "0.5 Its lack of quality earns it a place alongside those other two recent Gosling botch-jobs , The Man in the Iron Mask and The Musketeer .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    5 (4.1%)\n",
      "\n",
      "Example fails:\n",
      "0.5 The only thing in Pauline and Paulette that you have n't seen before is a scene featuring a football field-sized Oriental rug crafted out of millions of vibrant flowers .\n",
      "0.8 The only thing in Jelinek and Paulette that you have n't seen before is a scene featuring a football field-sized Oriental rug crafted out of millions of vibrant flowers .\n",
      "0.7 The only thing in Crispin Glover and Paulette that you have n't seen before is a scene featuring a football field-sized Oriental rug crafted out of millions of vibrant flowers .\n",
      "\n",
      "----\n",
      "0.2 Has it ever been possible to say that Williams has truly inhabited a character ?\n",
      "0.7 Has it ever been possible to say that Michel Gondry has truly inhabited a character ?\n",
      "\n",
      "----\n",
      "0.3 Oedekerk wrote Patch Adams , for which he should not be forgiven .\n",
      "0.8 Oedekerk wrote Einstein , for which he should not be forgiven .\n",
      "0.5 Oedekerk wrote Crispin Glover , for which he should not be forgiven .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    3 (1.9%)\n",
      "\n",
      "Example fails:\n",
      "0.8 ( A ) Hollywood sheen bedevils the film from the very beginning ... ( but ) Lohman 's moist , deeply emotional eyes shine through this bogus veneer ...\n",
      "0.3 ( A ) Hollywood sheen bedevils the film from the very beginning ... ( but ) Smokey Robinson 's moist , deeply emotional eyes shine through this bogus veneer ...\n",
      "0.4 ( A ) Hollywood sheen bedevils the film from the very beginning ... ( but ) Carl Franklin 's moist , deeply emotional eyes shine through this bogus veneer ...\n",
      "\n",
      "----\n",
      "0.6 ( Davis ) has a bright , chipper style that keeps things moving , while never quite managing to connect her wish-fulfilling characters to the human race .\n",
      "0.5 ( Birot ) has a bright , chipper style that keeps things moving , while never quite managing to connect her wish-fulfilling characters to the human race .\n",
      "0.5 ( Smokey Robinson ) has a bright , chipper style that keeps things moving , while never quite managing to connect her wish-fulfilling characters to the human race .\n",
      "\n",
      "----\n",
      "0.8 More honest about Alzheimer 's disease , I think , than Iris .\n",
      "0.2 More honest about Alzheimer 's disease , I think , than Birot .\n",
      "0.2 More honest about Alzheimer 's disease , I think , than Gosling .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Change Movie Industries\n",
      "Test cases:      18\n",
      "Fails (rate):    1 (5.6%)\n",
      "\n",
      "Example fails:\n",
      "0.4 Home Alone goes Hollywood , a funny premise until the kids start pulling off stunts not even Steven Spielberg would know how to do .\n",
      "0.6 Home Alone goes Tollywood , a funny premise until the kids start pulling off stunts not even Steven Spielberg would know how to do .\n",
      "0.6 Home Alone goes Ghollywood , a funny premise until the kids start pulling off stunts not even Steven Spielberg would know how to do .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Temporal\n",
      "\n",
      "used to, but now\n",
      "Test cases:      2152\n",
      "Fails (rate):    90 (4.2%)\n",
      "\n",
      "Example fails:\n",
      "0.4 I welcome this movie, but I used to hate it.\n",
      "----\n",
      "0.9 I despise this movie, but I used to value it.\n",
      "----\n",
      "0.7 I hate this movie, but I used to appreciate it.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Negation\n",
      "\n",
      "Simple negations: negative\n",
      "Test cases:      1350\n",
      "Fails (rate):    97 (7.2%)\n",
      "\n",
      "Example fails:\n",
      "1.0 I would never say I enjoy this actor.\n",
      "----\n",
      "1.0 I can't say I love this show.\n",
      "----\n",
      "1.0 I can't say I appreciate the director.\n",
      "----\n",
      "\n",
      "\n",
      "Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Test cases:      500\n",
      "Fails (rate):    248 (49.6%)\n",
      "\n",
      "Example fails:\n",
      "1.0 I can't say, given all that I've seen over the years, that the show is good.\n",
      "----\n",
      "1.0 I wouldn't say, given that I bought it last week, that we love the director.\n",
      "----\n",
      "1.0 I can't say, given all that I've seen over the years, that I welcome that scene.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Synonym/Antonym\n",
      "\n",
      "Movie sentiments\n",
      "Test cases:      58\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sentiment\n",
      "\n",
      "Movie genre specific sentiments\n",
      "Test cases:      736\n",
      "Fails (rate):    34 (4.6%)\n",
      "\n",
      "Example fails:\n",
      "1.0 This drama movie was funny rather than serious\n",
      "----\n",
      "0.1 This horror movie was frightening\n",
      "----\n",
      "0.3 The horror movie was frightening\n",
      "----\n",
      "\n",
      "\n",
      "Movie Industries specific sentiments\n",
      "Test cases:      1200\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_suite.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-being",
   "metadata": {},
   "source": [
    "#### Random Seed 8 - Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "personalized-bikini",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"albert-large-v2\"\n",
    "checkpoint_path = \"model-outputs/final-models/rs8-shuffle-train/albert-large-v2_3.pt\"\n",
    "pipeline = BatchedInference.from_model_name(\n",
    "    model_name, checkpoint_path=checkpoint_path, device=\"cuda\"\n",
    ")\n",
    "\n",
    "def pred_and_conf(data, batch_size=32):\n",
    "    data = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    for data in data: \n",
    "        preds, confs = pipeline(data)\n",
    "        preds = preds.numpy().tolist()\n",
    "        confs = confs.numpy()\n",
    "        predictions.append(preds)\n",
    "        confidences.append(confs)\n",
    "    predictions = np.hstack(predictions)\n",
    "    confidences = np.vstack(confidences)\n",
    "    return predictions, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "absent-carroll",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:4vpi7k6i) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 11743<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 4.63MB of 4.63MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210914_092029-4vpi7k6i/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210914_092029-4vpi7k6i/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>test</td><td>used to, but now</td></tr><tr><td>_runtime</td><td>92</td></tr><tr><td>_timestamp</td><td>1631611325</td></tr><tr><td>_step</td><td>17</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>▁▁▁▁▁▁▁▁▁▁▁▁██████</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁▁▁▁▁▁▁██████</td></tr><tr><td>_step</td><td>▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">rs7-swa-linear-60-start2-drop-shuffle_6_testset_19_07_21</strong>: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/4vpi7k6i\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/4vpi7k6i</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:4vpi7k6i). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.22<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">rs8-shuffle-train_3_testset_19_07_21</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ukh/checklist_evaluation\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/10s085s5\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/10s085s5</a><br/>\n",
       "                Run data is saved locally in <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210914_092248-10s085s5</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Movie sentiments\n",
      "Predicting 58 examples\n",
      "Running Single positive words\n",
      "Predicting 22 examples\n",
      "Running Single negative words\n",
      "Predicting 14 examples\n",
      "Running Sentiment-laden words in context\n",
      "Predicting 1350 examples\n",
      "Running add positive phrases\n",
      "Predicting 5500 examples\n",
      "Running add negative phrases\n",
      "Predicting 5000 examples\n",
      "Running Simple negations: negative\n",
      "Predicting 1350 examples\n",
      "Running Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Predicting 500 examples\n",
      "Running Movie genre specific sentiments\n",
      "Predicting 736 examples\n",
      "Running Change names\n",
      "Predicting 1617 examples\n",
      "Running Polarizing Negative Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Polarizing Positive Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Negative Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Positive Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Change Movie Industries\n",
      "Predicting 252 examples\n",
      "Running Movie Industries specific sentiments\n",
      "Predicting 1200 examples\n",
      "Running change neutral words with BERT\n",
      "Predicting 3846 examples\n",
      "Running used to, but now\n",
      "Predicting 2152 examples\n"
     ]
    }
   ],
   "source": [
    "results_path = \"results/checklist/rs8-shuffle-train_3_testset_19_07_21.json\"\n",
    "config = {\n",
    "    \"project_name\": \"checklist_evaluation\", \n",
    "    \"run_name\": \"rs8-shuffle-train_3_testset_19_07_21\",\n",
    "    \"model\": \"albert-large-v2\", \n",
    "    \"checkpoint\": checkpoint_path, \n",
    "    \"test_suite\": test_suite_path,\n",
    "    \"results_path\": results_path\n",
    "}\n",
    "wandb.init(config=config, project=config[\"project_name\"], name=config[\"run_name\"])\n",
    "\n",
    "test_suite = TestSuite.from_file(test_suite_path)\n",
    "test_suite.run(pred_and_conf, overwrite=True, seed=0)\n",
    "save_test_results(config, test_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "honest-cabinet",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary\n",
      "\n",
      "Single positive words\n",
      "Test cases:      22\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Single negative words\n",
      "Test cases:      14\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Sentiment-laden words in context\n",
      "Test cases:      1350\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add positive phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    1 (0.2%)\n",
      "\n",
      "Example fails:\n",
      "0.9 Is n't it great ?\n",
      "0.0 Is n't it great. I would watch this again.\n",
      "0.4 Is n't it great. I recommend it.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "add negative phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    2 (0.4%)\n",
      "\n",
      "Example fails:\n",
      "0.1 The only thing that could possibly make them less interesting than they already are is for them to get full montied into a scrappy , jovial team .\n",
      "0.2 The only thing that could possibly make them less interesting than they already are is for them to get full montied into a scrappy , jovial team. Never watching this again.\n",
      "\n",
      "----\n",
      "0.0 Jolie 's performance vanishes somewhere between her hair and her lips .\n",
      "0.1 Jolie 's performance vanishes somewhere between her hair and her lips. Never watching this again.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "change neutral words with BERT\n",
      "Test cases:      500\n",
      "Fails (rate):    42 (8.4%)\n",
      "\n",
      "Example fails:\n",
      "0.2 A strong first quarter , slightly less so second quarter , and average second half .\n",
      "0.9 A strong first quarter , slightly less so second quarter , below average second half .\n",
      "0.8 extremely strong first quarter , slightly less so second quarter , and average second half .\n",
      "\n",
      "----\n",
      "0.8 If your senses have n't been dulled by slasher films and gorefests , if you 're a connoisseur of psychological horror , this is your ticket .\n",
      "0.2 If your senses already n't been dulled by slasher films and gorefests , if you 're a connoisseur of psychological horror , this is your ticket .\n",
      "\n",
      "----\n",
      "0.4 Do n't plan on the perfect ending , but Sweet Home Alabama hits the mark with critics who escaped from a small town life .\n",
      "0.8 Do n't plan on the perfect ending , but Sweet Home Alabama hits the mark in critics who escaped from a small town life .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NER\n",
      "\n",
      "Change names\n",
      "Test cases:      147\n",
      "Fails (rate):    4 (2.7%)\n",
      "\n",
      "Example fails:\n",
      "0.7 De Niro may enjoy the same free ride from critics afforded to Clint Eastwood in the lazy Bloodwork .\n",
      "0.3 De Niro may enjoy the same free ride from critics afforded to Daniel Sanders in the lazy Bloodwork .\n",
      "0.4 De Niro may enjoy the same free ride from critics afforded to Joseph Phillips in the lazy Bloodwork .\n",
      "\n",
      "----\n",
      "0.5 Tim Story 's not there yet - but ` Barbershop ' shows he 's on his way .\n",
      "0.3 Matthew Ross 's not there yet - but ` Barbershop ' shows he 's on his way .\n",
      "0.3 Michael Ward 's not there yet - but ` Barbershop ' shows he 's on his way .\n",
      "\n",
      "----\n",
      "0.6 ( Davis ) has a bright , chipper style that keeps things moving , while never quite managing to connect her wish-fulfilling characters to the human race .\n",
      "0.5 ( Luke ) has a bright , chipper style that keeps things moving , while never quite managing to connect her wish-fulfilling characters to the human race .\n",
      "0.5 ( Luke ) has a bright , chipper style that keeps things moving , while never quite managing to connect her wish-fulfilling characters to the human race .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    8 (5.1%)\n",
      "\n",
      "Example fails:\n",
      "0.4 With Danilo Donati 's witty designs and Dante Spinotti 's luscious cinematography , this might have made a decent children 's movie -- if only Benigni had n't insisted on casting himself in the title role .\n",
      "0.5 With Danilo Donati 's witty designs and Dante Spinotti 's luscious cinematography , this might have made a decent children 's movie -- if only Einstein had n't insisted on casting himself in the title role .\n",
      "\n",
      "----\n",
      "0.4 Not everything works , but the average is higher than in Mary and most other recent comedies .\n",
      "0.5 Not everything works , but the average is higher than in Yvan Attal and most other recent comedies .\n",
      "0.5 Not everything works , but the average is higher than in Crispin Glover and most other recent comedies .\n",
      "\n",
      "----\n",
      "0.4 As lo-fi as the special effects are , the folks who cobbled Nemesis together indulge the force of humanity over hardware in a way that George Lucas has long forgotten .\n",
      "0.6 As lo-fi as the special effects are , the folks who cobbled Nemesis together indulge the force of humanity over hardware in a way that Einstein has long forgotten .\n",
      "0.6 As lo-fi as the special effects are , the folks who cobbled Nemesis together indulge the force of humanity over hardware in a way that Crispin Glover has long forgotten .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    5 (4.1%)\n",
      "\n",
      "Example fails:\n",
      "0.8 Flat , but with a revelatory performance by Michelle Williams .\n",
      "0.5 Flat , but with a revelatory performance by Birot .\n",
      "\n",
      "----\n",
      "0.4 Being author Wells ' great-grandson , you 'd think filmmaker Simon Wells would have more reverence for the material .\n",
      "0.5 Being author Walt Becker ' great-grandson , you 'd think filmmaker Simon Walt Becker would have more reverence for the material .\n",
      "\n",
      "----\n",
      "0.7 De Niro may enjoy the same free ride from critics afforded to Clint Eastwood in the lazy Bloodwork .\n",
      "0.2 De Niro may enjoy the same free ride from critics afforded to Gulpilil in the lazy Bloodwork .\n",
      "0.3 De Niro may enjoy the same free ride from critics afforded to Polanski in the lazy Bloodwork .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    3 (2.4%)\n",
      "\n",
      "Example fails:\n",
      "0.8 Watching Haneke 's film is , aptly enough , a challenge and a punishment .\n",
      "0.3 Watching Michel Gondry 's film is , aptly enough , a challenge and a punishment .\n",
      "\n",
      "----\n",
      "0.8 Cho 's fans are sure to be entertained ; it 's only fair in the interest of full disclosure to say that -- on the basis of this film alone -- I 'm not one of them .\n",
      "0.5 Michel Gondry 's fans are sure to be entertained ; it 's only fair in the interest of full disclosure to say that -- on the basis of this film alone -- I 'm not one of them .\n",
      "\n",
      "----\n",
      "0.7 De Niro may enjoy the same free ride from critics afforded to Clint Eastwood in the lazy Bloodwork .\n",
      "0.4 De Niro may enjoy the same free ride from critics afforded to Seagal in the lazy Bloodwork .\n",
      "0.4 De Niro may enjoy the same free ride from critics afforded to Reginald Hudlin in the lazy Bloodwork .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    9 (5.7%)\n",
      "\n",
      "Example fails:\n",
      "0.5 Ms. Fulford-Wierzbicki is almost spooky in her sulky , calculating Lolita turn .\n",
      "0.4 Ms. Birot is almost spooky in her sulky , calculating Lolita turn .\n",
      "\n",
      "----\n",
      "0.4 With Danilo Donati 's witty designs and Dante Spinotti 's luscious cinematography , this might have made a decent children 's movie -- if only Benigni had n't insisted on casting himself in the title role .\n",
      "0.5 With Danilo Donati 's witty designs and Dante Spinotti 's luscious cinematography , this might have made a decent children 's movie -- if only Merchant Ivory had n't insisted on casting himself in the title role .\n",
      "\n",
      "----\n",
      "0.5 Tim Story 's not there yet - but ` Barbershop ' shows he 's on his way .\n",
      "0.2 Birot 's not there yet - but ` Barbershop ' shows he 's on his way .\n",
      "0.2 Craig Bartlett 's not there yet - but ` Barbershop ' shows he 's on his way .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Change Movie Industries\n",
      "Test cases:      18\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Temporal\n",
      "\n",
      "used to, but now\n",
      "Test cases:      2152\n",
      "Fails (rate):    157 (7.3%)\n",
      "\n",
      "Example fails:\n",
      "0.3 I enjoy this movie, but in the past I would hate it.\n",
      "----\n",
      "0.2 I like this movie, but in the past I would hate it.\n",
      "----\n",
      "0.1 I value this movie, but I used to regret it.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Negation\n",
      "\n",
      "Simple negations: negative\n",
      "Test cases:      1350\n",
      "Fails (rate):    2 (0.1%)\n",
      "\n",
      "Example fails:\n",
      "0.5 I would never say I admire this director.\n",
      "----\n",
      "0.5 I would never say I appreciate this director.\n",
      "----\n",
      "\n",
      "\n",
      "Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Test cases:      500\n",
      "Fails (rate):    144 (28.8%)\n",
      "\n",
      "Example fails:\n",
      "0.8 I don't think, given all that I've seen over the years, that the scene is amazing.\n",
      "----\n",
      "0.6 I don't think, given my history with movies, that this movie was beautiful.\n",
      "----\n",
      "1.0 I don't think, given that I bought it last week, that we appreciate the show.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Synonym/Antonym\n",
      "\n",
      "Movie sentiments\n",
      "Test cases:      58\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sentiment\n",
      "\n",
      "Movie genre specific sentiments\n",
      "Test cases:      736\n",
      "Fails (rate):    34 (4.6%)\n",
      "\n",
      "Example fails:\n",
      "0.1 This drama movie was serious\n",
      "----\n",
      "1.0 This comedy movie is serious, not rib-tickling\n",
      "----\n",
      "0.0 The horror movie is terrifying\n",
      "----\n",
      "\n",
      "\n",
      "Movie Industries specific sentiments\n",
      "Test cases:      1200\n",
      "Fails (rate):    3 (0.2%)\n",
      "\n",
      "Example fails:\n",
      "0.6 Hogawood movies are tough\n",
      "----\n",
      "0.5 Tamalewood movies are tough\n",
      "----\n",
      "0.5 Hallyuwood movies are tough\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_suite.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "extra-booking",
   "metadata": {},
   "source": [
    "#### Random Seed 8 - SWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "useful-decrease",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"albert-large-v2\"\n",
    "checkpoint_path = \"model-outputs/final-models/rs8-swa-linear-60-start2-drop-shuffle/albert-large-v2_4.pt\"\n",
    "pipeline = BatchedInference.from_model_name(\n",
    "    model_name, checkpoint_path=checkpoint_path, device=\"cuda\"\n",
    ")\n",
    "\n",
    "def pred_and_conf(data, batch_size=32):\n",
    "    data = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    for data in data: \n",
    "        preds, confs = pipeline(data)\n",
    "        preds = preds.numpy().tolist()\n",
    "        confs = confs.numpy()\n",
    "        predictions.append(preds)\n",
    "        confidences.append(confs)\n",
    "    predictions = np.hstack(predictions)\n",
    "    confidences = np.vstack(confidences)\n",
    "    return predictions, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "exotic-rating",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:10s085s5) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 11785<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 4.62MB of 4.62MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210914_092248-10s085s5/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210914_092248-10s085s5/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>test</td><td>used to, but now</td></tr><tr><td>_runtime</td><td>91</td></tr><tr><td>_timestamp</td><td>1631611463</td></tr><tr><td>_step</td><td>17</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_step</td><td>▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">rs8-shuffle-train_3_testset_19_07_21</strong>: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/10s085s5\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/10s085s5</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:10s085s5). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.22<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">rs8-swa-linear-60-start2-drop-shuffle_4_testset_19_07_21</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ukh/checklist_evaluation\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/3c1x8jur\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/3c1x8jur</a><br/>\n",
       "                Run data is saved locally in <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210914_092426-3c1x8jur</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Movie sentiments\n",
      "Predicting 58 examples\n",
      "Running Single positive words\n",
      "Predicting 22 examples\n",
      "Running Single negative words\n",
      "Predicting 14 examples\n",
      "Running Sentiment-laden words in context\n",
      "Predicting 1350 examples\n",
      "Running add positive phrases\n",
      "Predicting 5500 examples\n",
      "Running add negative phrases\n",
      "Predicting 5000 examples\n",
      "Running Simple negations: negative\n",
      "Predicting 1350 examples\n",
      "Running Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Predicting 500 examples\n",
      "Running Movie genre specific sentiments\n",
      "Predicting 736 examples\n",
      "Running Change names\n",
      "Predicting 1617 examples\n",
      "Running Polarizing Negative Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Polarizing Positive Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Negative Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Positive Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Change Movie Industries\n",
      "Predicting 252 examples\n",
      "Running Movie Industries specific sentiments\n",
      "Predicting 1200 examples\n",
      "Running change neutral words with BERT\n",
      "Predicting 3846 examples\n",
      "Running used to, but now\n",
      "Predicting 2152 examples\n"
     ]
    }
   ],
   "source": [
    "results_path = \"results/checklist/rs8-swa-linear-60-start2-drop-shuffle_4_testset_19_07_21.json\"\n",
    "config = {\n",
    "    \"project_name\": \"checklist_evaluation\", \n",
    "    \"run_name\": \"rs8-swa-linear-60-start2-drop-shuffle_4_testset_19_07_21\",\n",
    "    \"model\": \"albert-large-v2\", \n",
    "    \"checkpoint\": checkpoint_path, \n",
    "    \"test_suite\": test_suite_path,\n",
    "    \"results_path\": results_path\n",
    "}\n",
    "wandb.init(config=config, project=config[\"project_name\"], name=config[\"run_name\"])\n",
    "\n",
    "test_suite = TestSuite.from_file(test_suite_path)\n",
    "test_suite.run(pred_and_conf, overwrite=True, seed=0)\n",
    "save_test_results(config, test_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "medical-affect",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary\n",
      "\n",
      "Single positive words\n",
      "Test cases:      22\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Single negative words\n",
      "Test cases:      14\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Sentiment-laden words in context\n",
      "Test cases:      1350\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add positive phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add negative phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "change neutral words with BERT\n",
      "Test cases:      500\n",
      "Fails (rate):    46 (9.2%)\n",
      "\n",
      "Example fails:\n",
      "1.0 The production values are up there .\n",
      "0.0 The production values are up below .\n",
      "0.3 The production values are up by .\n",
      "\n",
      "----\n",
      "1.0 Workmanlike , maybe , but still a film with all the elements that made the other three great , scary times at the movies .\n",
      "0.0 Workmanlike , maybe , but still a film lacking all the elements that made the other three great , scary times at the movies .\n",
      "\n",
      "----\n",
      "1.0 Run , do n't walk , to see this barbed and bracing comedy on the big screen .\n",
      "0.3 Run , do n't walk , to see more barbed and bracing comedy on the big screen .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NER\n",
      "\n",
      "Change names\n",
      "Test cases:      147\n",
      "Fails (rate):    2 (1.4%)\n",
      "\n",
      "Example fails:\n",
      "0.4 Tim Story 's not there yet - but ` Barbershop ' shows he 's on his way .\n",
      "0.5 Joseph Phillips 's not there yet - but ` Barbershop ' shows he 's on his way .\n",
      "0.5 Joshua Nelson 's not there yet - but ` Barbershop ' shows he 's on his way .\n",
      "\n",
      "----\n",
      "0.5 Adam Sandler is to Gary Cooper what a gnat is to a racehorse .\n",
      "0.7 John Bailey is to Gary Cooper what a gnat is to a racehorse .\n",
      "0.6 Joshua Nelson is to Gary Cooper what a gnat is to a racehorse .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    6 (3.8%)\n",
      "\n",
      "Example fails:\n",
      "0.9 While not as aggressively impressive as its American counterpart , `` In the Bedroom , '' Moretti 's film makes its own , quieter observations\n",
      "0.5 While not as aggressively impressive as its American counterpart , `` In the Bedroom , '' Carol Kane 's film makes its own , quieter observations\n",
      "\n",
      "----\n",
      "0.6 The whole cast looks to be having so much fun with the slapstick antics and silly street patois , tossing around obscure expressions like Bellini and Mullinski , that the compact 86 minutes breezes by .\n",
      "0.5 The whole cast looks to be having so much fun with the slapstick antics and silly street patois , tossing around obscure expressions like Bellini and Seagal , that the compact 86 minutes breezes by .\n",
      "0.5 The whole cast looks to be having so much fun with the slapstick antics and silly street patois , tossing around obscure expressions like Yvan Attal and Mullinski , that the compact 86 minutes breezes by .\n",
      "\n",
      "----\n",
      "0.4 Tim Story 's not there yet - but ` Barbershop ' shows he 's on his way .\n",
      "0.9 Crispin Glover 's not there yet - but ` Barbershop ' shows he 's on his way .\n",
      "0.9 Yvan Attal 's not there yet - but ` Barbershop ' shows he 's on his way .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    5 (4.1%)\n",
      "\n",
      "Example fails:\n",
      "0.3 Based on a David Leavitt story , the film shares that writer 's usual blend of observant cleverness , too-facile coincidence and slightly noxious preciousness .\n",
      "0.5 Based on a Carl Franklin story , the film shares that writer 's usual blend of observant cleverness , too-facile coincidence and slightly noxious preciousness .\n",
      "0.5 Based on a Walt Becker story , the film shares that writer 's usual blend of observant cleverness , too-facile coincidence and slightly noxious preciousness .\n",
      "\n",
      "----\n",
      "0.4 De Niro may enjoy the same free ride from critics afforded to Clint Eastwood in the lazy Bloodwork .\n",
      "0.6 De Niro may enjoy the same free ride from critics afforded to Hélène Angel in the lazy Bloodwork .\n",
      "0.6 De Niro may enjoy the same free ride from critics afforded to Eric in the lazy Bloodwork .\n",
      "\n",
      "----\n",
      "0.5 Adam Sandler is to Gary Cooper what a gnat is to a racehorse .\n",
      "0.7 Walt Becker is to Gary Cooper what a gnat is to a racehorse .\n",
      "0.6 Craig Bartlett is to Gary Cooper what a gnat is to a racehorse .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    5 (4.1%)\n",
      "\n",
      "Example fails:\n",
      "0.5 Being author Wells ' great-grandson , you 'd think filmmaker Simon Wells would have more reverence for the material .\n",
      "0.6 Being author Paul Pender ' great-grandson , you 'd think filmmaker Simon Paul Pender would have more reverence for the material .\n",
      "\n",
      "----\n",
      "0.3 Based on a David Leavitt story , the film shares that writer 's usual blend of observant cleverness , too-facile coincidence and slightly noxious preciousness .\n",
      "1.0 Based on a Crispin Glover story , the film shares that writer 's usual blend of observant cleverness , too-facile coincidence and slightly noxious preciousness .\n",
      "\n",
      "----\n",
      "0.4 De Niro may enjoy the same free ride from critics afforded to Clint Eastwood in the lazy Bloodwork .\n",
      "0.6 De Niro may enjoy the same free ride from critics afforded to Roberts in the lazy Bloodwork .\n",
      "0.5 De Niro may enjoy the same free ride from critics afforded to Reginald Hudlin in the lazy Bloodwork .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    5 (3.2%)\n",
      "\n",
      "Example fails:\n",
      "0.5 For Benigni it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.7 For Walt Becker it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.7 For Carl Franklin it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "\n",
      "----\n",
      "0.4 Tim Story 's not there yet - but ` Barbershop ' shows he 's on his way .\n",
      "0.8 Merchant Ivory 's not there yet - but ` Barbershop ' shows he 's on his way .\n",
      "0.8 Gosling 's not there yet - but ` Barbershop ' shows he 's on his way .\n",
      "\n",
      "----\n",
      "0.6 When your leading ladies are a couple of screen-eating dominatrixes like Goldie Hawn and Susan Sarandon at their raunchy best , even hokum goes down easily .\n",
      "0.4 When your leading ladies are a couple of screen-eating dominatrixes like Goldie Hawn and Birot at their raunchy best , even hokum goes down easily .\n",
      "0.4 When your leading ladies are a couple of screen-eating dominatrixes like Goldie Hawn and Merchant Ivory at their raunchy best , even hokum goes down easily .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Change Movie Industries\n",
      "Test cases:      18\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Temporal\n",
      "\n",
      "used to, but now\n",
      "Test cases:      2152\n",
      "Fails (rate):    66 (3.1%)\n",
      "\n",
      "Example fails:\n",
      "0.5 I admire this movie, but I used to despise it.\n",
      "----\n",
      "0.8 In the past I would recommend this movie, although now I regret it.\n",
      "----\n",
      "0.0 In the past I would dislike this movie, even though now I liked it.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Negation\n",
      "\n",
      "Simple negations: negative\n",
      "Test cases:      1350\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Test cases:      500\n",
      "Fails (rate):    38 (7.6%)\n",
      "\n",
      "Example fails:\n",
      "0.6 I wouldn't say, given that we watched a lot, that the director is wonderful.\n",
      "----\n",
      "0.9 I wouldn't say, given that we watched a lot, that this movie is amazing.\n",
      "----\n",
      "1.0 I wouldn't say, given all that I've seen over the years, that this actor is wonderful.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Synonym/Antonym\n",
      "\n",
      "Movie sentiments\n",
      "Test cases:      58\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sentiment\n",
      "\n",
      "Movie genre specific sentiments\n",
      "Test cases:      736\n",
      "Fails (rate):    34 (4.6%)\n",
      "\n",
      "Example fails:\n",
      "0.7 This comedy movie was serious\n",
      "----\n",
      "1.0 This comedy movie is serious, not rib-tickling\n",
      "----\n",
      "1.0 The comedy movie was serious, not rib-tickling\n",
      "----\n",
      "\n",
      "\n",
      "Movie Industries specific sentiments\n",
      "Test cases:      1200\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_suite.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "prepared-pregnancy",
   "metadata": {},
   "source": [
    "#### Random Seed 9 - Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "understood-apartment",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"albert-large-v2\"\n",
    "checkpoint_path = \"model-outputs/final-models/rs9-shuffle-train/albert-large-v2_4.pt\"\n",
    "pipeline = BatchedInference.from_model_name(\n",
    "    model_name, checkpoint_path=checkpoint_path, device=\"cuda\"\n",
    ")\n",
    "\n",
    "def pred_and_conf(data, batch_size=32):\n",
    "    data = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    for data in data: \n",
    "        preds, confs = pipeline(data)\n",
    "        preds = preds.numpy().tolist()\n",
    "        confs = confs.numpy()\n",
    "        predictions.append(preds)\n",
    "        confidences.append(confs)\n",
    "    predictions = np.hstack(predictions)\n",
    "    confidences = np.vstack(confidences)\n",
    "    return predictions, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "nasty-acting",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3c1x8jur) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 11830<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 4.61MB of 4.61MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210914_092426-3c1x8jur/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210914_092426-3c1x8jur/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>test</td><td>used to, but now</td></tr><tr><td>_runtime</td><td>92</td></tr><tr><td>_timestamp</td><td>1631611562</td></tr><tr><td>_step</td><td>17</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>_step</td><td>▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">rs8-swa-linear-60-start2-drop-shuffle_4_testset_19_07_21</strong>: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/3c1x8jur\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/3c1x8jur</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:3c1x8jur). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.22<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">rs9-shuffle-train_4_testset_19_07_21</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ukh/checklist_evaluation\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/1a3adugv\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/1a3adugv</a><br/>\n",
       "                Run data is saved locally in <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210914_092605-1a3adugv</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Movie sentiments\n",
      "Predicting 58 examples\n",
      "Running Single positive words\n",
      "Predicting 22 examples\n",
      "Running Single negative words\n",
      "Predicting 14 examples\n",
      "Running Sentiment-laden words in context\n",
      "Predicting 1350 examples\n",
      "Running add positive phrases\n",
      "Predicting 5500 examples\n",
      "Running add negative phrases\n",
      "Predicting 5000 examples\n",
      "Running Simple negations: negative\n",
      "Predicting 1350 examples\n",
      "Running Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Predicting 500 examples\n",
      "Running Movie genre specific sentiments\n",
      "Predicting 736 examples\n",
      "Running Change names\n",
      "Predicting 1617 examples\n",
      "Running Polarizing Negative Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Polarizing Positive Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Negative Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Positive Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Change Movie Industries\n",
      "Predicting 252 examples\n",
      "Running Movie Industries specific sentiments\n",
      "Predicting 1200 examples\n",
      "Running change neutral words with BERT\n",
      "Predicting 3846 examples\n",
      "Running used to, but now\n",
      "Predicting 2152 examples\n"
     ]
    }
   ],
   "source": [
    "results_path = \"results/checklist/rs9-shuffle-train_4_testset_19_07_21.json\"\n",
    "config = {\n",
    "    \"project_name\": \"checklist_evaluation\", \n",
    "    \"run_name\": \"rs9-shuffle-train_4_testset_19_07_21\",\n",
    "    \"model\": \"albert-large-v2\", \n",
    "    \"checkpoint\": checkpoint_path, \n",
    "    \"test_suite\": test_suite_path,\n",
    "    \"results_path\": results_path\n",
    "}\n",
    "wandb.init(config=config, project=config[\"project_name\"], name=config[\"run_name\"])\n",
    "\n",
    "test_suite = TestSuite.from_file(test_suite_path)\n",
    "test_suite.run(pred_and_conf, overwrite=True, seed=0)\n",
    "save_test_results(config, test_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ideal-gallery",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary\n",
      "\n",
      "Single positive words\n",
      "Test cases:      22\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Single negative words\n",
      "Test cases:      14\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Sentiment-laden words in context\n",
      "Test cases:      1350\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add positive phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add negative phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "change neutral words with BERT\n",
      "Test cases:      500\n",
      "Fails (rate):    34 (6.8%)\n",
      "\n",
      "Example fails:\n",
      "0.6 Like a south-of-the-border Melrose Place .\n",
      "0.1 Like another south-of-the-border Melrose Place .\n",
      "0.3 Like in south-of-the-border Melrose Place .\n",
      "\n",
      "----\n",
      "1.0 Workmanlike , maybe , but still a film with all the elements that made the other three great , scary times at the movies .\n",
      "0.0 Workmanlike , maybe , but still a film lacking all the elements that made the other three great , scary times at the movies .\n",
      "\n",
      "----\n",
      "0.4 In its ragged , cheap and unassuming way , the movie works .\n",
      "0.6 In its ragged , cheap and unassuming way , the technique works .\n",
      "0.6 In its ragged , cheap and unassuming way , this movie works .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NER\n",
      "\n",
      "Change names\n",
      "Test cases:      147\n",
      "Fails (rate):    1 (0.7%)\n",
      "\n",
      "Example fails:\n",
      "0.0 More honest about Alzheimer 's disease , I think , than Iris .\n",
      "0.8 More honest about Alzheimer 's disease , I think , than Taylor .\n",
      "0.7 More honest about Alzheimer 's disease , I think , than Maria .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    5 (3.2%)\n",
      "\n",
      "Example fails:\n",
      "0.7 ( A ) Hollywood sheen bedevils the film from the very beginning ... ( but ) Lohman 's moist , deeply emotional eyes shine through this bogus veneer ...\n",
      "0.5 ( A ) Hollywood sheen bedevils the film from the very beginning ... ( but ) Britney 's moist , deeply emotional eyes shine through this bogus veneer ...\n",
      "0.5 ( A ) Hollywood sheen bedevils the film from the very beginning ... ( but ) Einstein 's moist , deeply emotional eyes shine through this bogus veneer ...\n",
      "\n",
      "----\n",
      "0.6 It suggests the wide-ranging effects of media manipulation , from the kind of reporting that is done by the supposedly liberal media ... to the intimate and ultimately tragic heartache of maverick individuals like Hatfield and Hicks .\n",
      "0.4 It suggests the wide-ranging effects of media manipulation , from the kind of reporting that is done by the supposedly liberal media ... to the intimate and ultimately tragic heartache of maverick individuals like Britney and Hicks .\n",
      "0.4 It suggests the wide-ranging effects of media manipulation , from the kind of reporting that is done by the supposedly liberal media ... to the intimate and ultimately tragic heartache of maverick individuals like Crispin Glover and Hicks .\n",
      "\n",
      "----\n",
      "0.3 For Benigni it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.6 For Einstein it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.6 For Paul Pender it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    4 (3.3%)\n",
      "\n",
      "Example fails:\n",
      "0.6 Watching Haneke 's film is , aptly enough , a challenge and a punishment .\n",
      "0.3 Watching Foster 's film is , aptly enough , a challenge and a punishment .\n",
      "\n",
      "----\n",
      "0.5 De Niro may enjoy the same free ride from critics afforded to Clint Eastwood in the lazy Bloodwork .\n",
      "0.7 De Niro may enjoy the same free ride from critics afforded to Eric in the lazy Bloodwork .\n",
      "0.6 De Niro may enjoy the same free ride from critics afforded to Yong Kang in the lazy Bloodwork .\n",
      "\n",
      "----\n",
      "0.2 Flat , but with a revelatory performance by Michelle Williams .\n",
      "0.8 Flat , but with a revelatory performance by Gosling .\n",
      "0.6 Flat , but with a revelatory performance by Merchant Ivory .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    5 (4.1%)\n",
      "\n",
      "Example fails:\n",
      "0.5 De Niro may enjoy the same free ride from critics afforded to Clint Eastwood in the lazy Bloodwork .\n",
      "0.7 De Niro may enjoy the same free ride from critics afforded to Sarah in the lazy Bloodwork .\n",
      "0.6 De Niro may enjoy the same free ride from critics afforded to Reginald Hudlin in the lazy Bloodwork .\n",
      "\n",
      "----\n",
      "0.6 Watching Haneke 's film is , aptly enough , a challenge and a punishment .\n",
      "0.2 Watching Britney 's film is , aptly enough , a challenge and a punishment .\n",
      "0.3 Watching Einstein 's film is , aptly enough , a challenge and a punishment .\n",
      "\n",
      "----\n",
      "0.8 The only thing in Pauline and Paulette that you have n't seen before is a scene featuring a football field-sized Oriental rug crafted out of millions of vibrant flowers .\n",
      "0.5 The only thing in Britney and Paulette that you have n't seen before is a scene featuring a football field-sized Oriental rug crafted out of millions of vibrant flowers .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    5 (3.2%)\n",
      "\n",
      "Example fails:\n",
      "0.0 More honest about Alzheimer 's disease , I think , than Iris .\n",
      "0.9 More honest about Alzheimer 's disease , I think , than Carl Franklin .\n",
      "0.8 More honest about Alzheimer 's disease , I think , than Phillip Noyce .\n",
      "\n",
      "----\n",
      "0.9 Benefits from a strong performance from Zhao , but it 's Dong Jie 's face you remember at the end .\n",
      "0.3 Benefits from a strong performance from Birot , but it 's Dong Jie 's face you remember at the end .\n",
      "\n",
      "----\n",
      "0.9 Steve Irwin 's method is Ernest Hemmingway at accelerated speed and volume .\n",
      "0.0 Steve Irwin 's method is Birot at accelerated speed and volume .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Change Movie Industries\n",
      "Test cases:      18\n",
      "Fails (rate):    3 (16.7%)\n",
      "\n",
      "Example fails:\n",
      "0.7 I kept wishing I was watching a documentary about the wartime Navajos and what they accomplished instead of all this specious Hollywood hoo-ha .\n",
      "0.2 I kept wishing I was watching a documentary about the wartime Navajos and what they accomplished instead of all this specious Aussiewood hoo-ha .\n",
      "0.2 I kept wishing I was watching a documentary about the wartime Navajos and what they accomplished instead of all this specious Peruliwood hoo-ha .\n",
      "\n",
      "----\n",
      "0.2 Even when foreign directors ... borrow stuff from Hollywood , they invariably shake up the formula and make it more interesting .\n",
      "0.8 Even when foreign directors ... borrow stuff from Cantonwood , they invariably shake up the formula and make it more interesting .\n",
      "0.8 Even when foreign directors ... borrow stuff from Aussiewood , they invariably shake up the formula and make it more interesting .\n",
      "\n",
      "----\n",
      "0.8 An epic of grandeur and scale that 's been decades gone from the popcorn pushing sound stages of Hollywood .\n",
      "0.2 An epic of grandeur and scale that 's been decades gone from the popcorn pushing sound stages of Aussiewood .\n",
      "0.2 An epic of grandeur and scale that 's been decades gone from the popcorn pushing sound stages of Hallyuwood .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Temporal\n",
      "\n",
      "used to, but now\n",
      "Test cases:      2152\n",
      "Fails (rate):    76 (3.5%)\n",
      "\n",
      "Example fails:\n",
      "0.3 I like this movie, but in the past I would regret it.\n",
      "----\n",
      "0.7 In the past I would like this movie, even though now I dread it.\n",
      "----\n",
      "0.3 I like this movie, but I used to despise it.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Negation\n",
      "\n",
      "Simple negations: negative\n",
      "Test cases:      1350\n",
      "Fails (rate):    15 (1.1%)\n",
      "\n",
      "Example fails:\n",
      "0.7 I can't say I welcome that director.\n",
      "----\n",
      "1.0 I can't say I welcome this movie.\n",
      "----\n",
      "0.6 I can't say I welcome that actor.\n",
      "----\n",
      "\n",
      "\n",
      "Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Test cases:      500\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Synonym/Antonym\n",
      "\n",
      "Movie sentiments\n",
      "Test cases:      58\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sentiment\n",
      "\n",
      "Movie genre specific sentiments\n",
      "Test cases:      736\n",
      "Fails (rate):    37 (5.0%)\n",
      "\n",
      "Example fails:\n",
      "0.0 This horror movie was scary\n",
      "----\n",
      "0.7 This horror movie was calming\n",
      "----\n",
      "0.0 The horror movie was scary\n",
      "----\n",
      "\n",
      "\n",
      "Movie Industries specific sentiments\n",
      "Test cases:      1200\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_suite.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-infrastructure",
   "metadata": {},
   "source": [
    "#### Random Seed 9 - SWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "declared-humidity",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at albert-large-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.bias', 'predictions.LayerNorm.weight', 'predictions.LayerNorm.bias', 'predictions.dense.weight', 'predictions.dense.bias', 'predictions.decoder.weight', 'predictions.decoder.bias']\n",
      "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-large-v2 and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"albert-large-v2\"\n",
    "checkpoint_path = \"model-outputs/final-models/rs9-swa-linear-75-start2-drop-shuffle/albert-large-v2_6.pt\"\n",
    "pipeline = BatchedInference.from_model_name(\n",
    "    model_name, checkpoint_path=checkpoint_path, device=\"cuda\"\n",
    ")\n",
    "\n",
    "def pred_and_conf(data, batch_size=32):\n",
    "    data = [data[i:i + batch_size] for i in range(0, len(data), batch_size)]\n",
    "    predictions = []\n",
    "    confidences = []\n",
    "    for data in data: \n",
    "        preds, confs = pipeline(data)\n",
    "        preds = preds.numpy().tolist()\n",
    "        confs = confs.numpy()\n",
    "        predictions.append(preds)\n",
    "        confidences.append(confs)\n",
    "    predictions = np.hstack(predictions)\n",
    "    confidences = np.vstack(confidences)\n",
    "    return predictions, confidences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "peaceful-reunion",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:1a3adugv) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 12077<br/>Program ended successfully."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value=' 4.59MB of 4.59MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find user logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210914_092605-1a3adugv/logs/debug.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find internal logs for this run at: <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210914_092605-1a3adugv/logs/debug-internal.log</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run summary:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>test</td><td>used to, but now</td></tr><tr><td>_runtime</td><td>93</td></tr><tr><td>_timestamp</td><td>1631611661</td></tr><tr><td>_step</td><td>17</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h3>Run history:</h3><br/><style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    </style><table class=\"wandb\">\n",
       "<tr><td>_runtime</td><td>▁▁▁▁▁▁▁▁▁▁████████</td></tr><tr><td>_timestamp</td><td>▁▁▁▁▁▁▁▁▁▁████████</td></tr><tr><td>_step</td><td>▁▁▂▂▃▃▃▄▄▅▅▆▆▆▇▇██</td></tr></table><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 2 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    <br/>Synced <strong style=\"color:#cdcd00\">rs9-shuffle-train_4_testset_19_07_21</strong>: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/1a3adugv\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/1a3adugv</a><br/>\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "...Successfully finished last run (ID:1a3adugv). Initializing new run:<br/><br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: wandb version 0.12.1 is available!  To upgrade, please run:\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.22<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">rs9-swa-linear-75-start2-drop-shuffle_6_testset_19_07_21</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/ukh/checklist_evaluation\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/ukh/checklist_evaluation/runs/2syltlim\" target=\"_blank\">https://wandb.ai/ukh/checklist_evaluation/runs/2syltlim</a><br/>\n",
       "                Run data is saved locally in <code>/home/ukvu/generalize-checklist/data-exploration/sst/wandb/run-20210914_092743-2syltlim</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Movie sentiments\n",
      "Predicting 58 examples\n",
      "Running Single positive words\n",
      "Predicting 22 examples\n",
      "Running Single negative words\n",
      "Predicting 14 examples\n",
      "Running Sentiment-laden words in context\n",
      "Predicting 1350 examples\n",
      "Running add positive phrases\n",
      "Predicting 5500 examples\n",
      "Running add negative phrases\n",
      "Predicting 5000 examples\n",
      "Running Simple negations: negative\n",
      "Predicting 1350 examples\n",
      "Running Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Predicting 500 examples\n",
      "Running Movie genre specific sentiments\n",
      "Predicting 736 examples\n",
      "Running Change names\n",
      "Predicting 1617 examples\n",
      "Running Polarizing Negative Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Polarizing Positive Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Negative Names - Negative Instances\n",
      "Predicting 1353 examples\n",
      "Running Polarizing Positive Names - Positive Instances\n",
      "Predicting 1727 examples\n",
      "Running Change Movie Industries\n",
      "Predicting 252 examples\n",
      "Running Movie Industries specific sentiments\n",
      "Predicting 1200 examples\n",
      "Running change neutral words with BERT\n",
      "Predicting 3846 examples\n",
      "Running used to, but now\n",
      "Predicting 2152 examples\n"
     ]
    }
   ],
   "source": [
    "results_path = \"results/checklist/rs9-swa-linear-75-start2-drop-shuffle_6_testset_19_07_21.json\"\n",
    "config = {\n",
    "    \"project_name\": \"checklist_evaluation\", \n",
    "    \"run_name\": \"rs9-swa-linear-75-start2-drop-shuffle_6_testset_19_07_21\",\n",
    "    \"model\": \"albert-large-v2\", \n",
    "    \"checkpoint\": checkpoint_path, \n",
    "    \"test_suite\": test_suite_path,\n",
    "    \"results_path\": results_path\n",
    "}\n",
    "wandb.init(config=config, project=config[\"project_name\"], name=config[\"run_name\"])\n",
    "\n",
    "test_suite = TestSuite.from_file(test_suite_path)\n",
    "test_suite.run(pred_and_conf, overwrite=True, seed=0)\n",
    "save_test_results(config, test_suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "popular-harrison",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary\n",
      "\n",
      "Single positive words\n",
      "Test cases:      22\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Single negative words\n",
      "Test cases:      14\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "Sentiment-laden words in context\n",
      "Test cases:      1350\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add positive phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "add negative phrases\n",
      "Test cases:      500\n",
      "Fails (rate):    1 (0.2%)\n",
      "\n",
      "Example fails:\n",
      "0.1 In the end , Punch-Drunk Love is one of those films that I wanted to like much more than I actually did .\n",
      "0.3 In the end , Punch-Drunk Love is one of those films that I wanted to like much more than I actually did. I dread it.\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "change neutral words with BERT\n",
      "Test cases:      500\n",
      "Fails (rate):    39 (7.8%)\n",
      "\n",
      "Example fails:\n",
      "0.1 Ecks this one off your must-see list .\n",
      "0.6 Ecks just one off your must-see list .\n",
      "\n",
      "----\n",
      "0.4 Must be seen to be believed .\n",
      "1.0 Must be seen must be believed .\n",
      "\n",
      "----\n",
      "0.9 Absorbing and disturbing -- perhaps more disturbing than originally intended -- but a little clarity would have gone a long way .\n",
      "0.0 Absorbing was disturbing -- perhaps more disturbing than originally intended -- but a little clarity would have gone a long way .\n",
      "0.0 Absorbing is disturbing -- perhaps more disturbing than originally intended -- but a little clarity would have gone a long way .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "NER\n",
      "\n",
      "Change names\n",
      "Test cases:      147\n",
      "Fails (rate):    4 (2.7%)\n",
      "\n",
      "Example fails:\n",
      "0.2 After seeing SWEPT AWAY , I feel sorry for Madonna .\n",
      "0.6 After seeing SWEPT AWAY , I feel sorry for Chelsea .\n",
      "0.5 After seeing SWEPT AWAY , I feel sorry for Nicole .\n",
      "\n",
      "----\n",
      "0.5 De Niro may enjoy the same free ride from critics afforded to Clint Eastwood in the lazy Bloodwork .\n",
      "0.7 De Niro may enjoy the same free ride from critics afforded to John Bailey in the lazy Bloodwork .\n",
      "0.6 De Niro may enjoy the same free ride from critics afforded to Joshua Nelson in the lazy Bloodwork .\n",
      "\n",
      "----\n",
      "0.2 George , hire a real director and good writers for the next installment , please .\n",
      "0.6 Scott , hire a real director and good writers for the next installment , please .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    4 (2.5%)\n",
      "\n",
      "Example fails:\n",
      "0.3 For Benigni it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.6 For Michel Gondry it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.6 For Paul Pender it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "\n",
      "----\n",
      "0.6 Wasabi is slight fare indeed , with the entire project having the feel of something tossed off quickly ( like one of Hubert 's punches ) , but it should go down smoothly enough with popcorn .\n",
      "0.4 Wasabi is slight fare indeed , with the entire project having the feel of something tossed off quickly ( like one of Yvan Attal 's punches ) , but it should go down smoothly enough with popcorn .\n",
      "0.4 Wasabi is slight fare indeed , with the entire project having the feel of something tossed off quickly ( like one of Jelinek 's punches ) , but it should go down smoothly enough with popcorn .\n",
      "\n",
      "----\n",
      "0.7 Sam Jones became a very lucky filmmaker the day Wilco got dropped from their record label , proving that one man 's ruin may be another 's fortune .\n",
      "0.3 Einstein became a very lucky filmmaker the day Wilco got dropped from their record label , proving that one man 's ruin may be another 's fortune .\n",
      "0.3 Britney became a very lucky filmmaker the day Wilco got dropped from their record label , proving that one man 's ruin may be another 's fortune .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    7 (5.7%)\n",
      "\n",
      "Example fails:\n",
      "0.6 Cho 's fans are sure to be entertained ; it 's only fair in the interest of full disclosure to say that -- on the basis of this film alone -- I 'm not one of them .\n",
      "0.4 Ellen Pompeo 's fans are sure to be entertained ; it 's only fair in the interest of full disclosure to say that -- on the basis of this film alone -- I 'm not one of them .\n",
      "0.4 Phillip Noyce 's fans are sure to be entertained ; it 's only fair in the interest of full disclosure to say that -- on the basis of this film alone -- I 'm not one of them .\n",
      "\n",
      "----\n",
      "0.5 De Niro may enjoy the same free ride from critics afforded to Clint Eastwood in the lazy Bloodwork .\n",
      "0.7 Walt Becker may enjoy the same free ride from critics afforded to Clint Eastwood in the lazy Bloodwork .\n",
      "\n",
      "----\n",
      "0.4 The only thing in Pauline and Paulette that you have n't seen before is a scene featuring a football field-sized Oriental rug crafted out of millions of vibrant flowers .\n",
      "0.6 The only thing in Ellen Pompeo and Paulette that you have n't seen before is a scene featuring a football field-sized Oriental rug crafted out of millions of vibrant flowers .\n",
      "0.6 The only thing in Walt Becker and Paulette that you have n't seen before is a scene featuring a football field-sized Oriental rug crafted out of millions of vibrant flowers .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Negative Names - Negative Instances\n",
      "Test cases:      123\n",
      "Fails (rate):    10 (8.1%)\n",
      "\n",
      "Example fails:\n",
      "0.2 After seeing SWEPT AWAY , I feel sorry for Madonna .\n",
      "0.7 After seeing SWEPT AWAY , I feel sorry for Yvan Attal .\n",
      "0.5 After seeing SWEPT AWAY , I feel sorry for Jelinek .\n",
      "\n",
      "----\n",
      "0.2 George , hire a real director and good writers for the next installment , please .\n",
      "0.8 Paul Pender , hire a real director and good writers for the next installment , please .\n",
      "0.8 Crispin Glover , hire a real director and good writers for the next installment , please .\n",
      "\n",
      "----\n",
      "0.6 Cho 's fans are sure to be entertained ; it 's only fair in the interest of full disclosure to say that -- on the basis of this film alone -- I 'm not one of them .\n",
      "0.4 Carol Kane 's fans are sure to be entertained ; it 's only fair in the interest of full disclosure to say that -- on the basis of this film alone -- I 'm not one of them .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Polarizing Positive Names - Positive Instances\n",
      "Test cases:      157\n",
      "Fails (rate):    4 (2.5%)\n",
      "\n",
      "Example fails:\n",
      "0.3 For Benigni it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.7 For Carl Franklin it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "0.7 For Walt Becker it was n't Shakespeare whom he wanted to define his career with but Pinocchio .\n",
      "\n",
      "----\n",
      "0.8 More honest about Alzheimer 's disease , I think , than Iris .\n",
      "0.0 More honest about Alzheimer 's disease , I think , than Birot .\n",
      "0.2 More honest about Alzheimer 's disease , I think , than Gosling .\n",
      "\n",
      "----\n",
      "0.6 When your leading ladies are a couple of screen-eating dominatrixes like Goldie Hawn and Susan Sarandon at their raunchy best , even hokum goes down easily .\n",
      "0.4 When your leading ladies are a couple of screen-eating dominatrixes like Goldie Hawn and Walt Becker at their raunchy best , even hokum goes down easily .\n",
      "0.4 When your leading ladies are a couple of screen-eating dominatrixes like Goldie Hawn and Carl Franklin at their raunchy best , even hokum goes down easily .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "Change Movie Industries\n",
      "Test cases:      18\n",
      "Fails (rate):    1 (5.6%)\n",
      "\n",
      "Example fails:\n",
      "0.4 Home Alone goes Hollywood , a funny premise until the kids start pulling off stunts not even Steven Spielberg would know how to do .\n",
      "0.6 Home Alone goes Kollywood , a funny premise until the kids start pulling off stunts not even Steven Spielberg would know how to do .\n",
      "0.5 Home Alone goes Nollywood , a funny premise until the kids start pulling off stunts not even Steven Spielberg would know how to do .\n",
      "\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Temporal\n",
      "\n",
      "used to, but now\n",
      "Test cases:      2152\n",
      "Fails (rate):    84 (3.9%)\n",
      "\n",
      "Example fails:\n",
      "0.3 I think this movie is wonderful, but in the past I thought it was terrible.\n",
      "----\n",
      "0.4 I welcome this movie, but I used to dislike it.\n",
      "----\n",
      "0.6 I abhor this movie, but I used to like it.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Negation\n",
      "\n",
      "Simple negations: negative\n",
      "Test cases:      1350\n",
      "Fails (rate):    159 (11.8%)\n",
      "\n",
      "Example fails:\n",
      "1.0 I would never say I welcome this director.\n",
      "----\n",
      "0.8 I can't say I value that scene.\n",
      "----\n",
      "1.0 I can't say I love the actor.\n",
      "----\n",
      "\n",
      "\n",
      "Hard: Negation of positive with neutral stuff in the middle (should be negative)\n",
      "Test cases:      500\n",
      "Fails (rate):    234 (46.8%)\n",
      "\n",
      "Example fails:\n",
      "1.0 I can't say, given that we watched a lot, that we welcome this director.\n",
      "----\n",
      "1.0 I can't say, given all that I've seen over the years, that we welcome the director.\n",
      "----\n",
      "1.0 I wouldn't say, given it's a Friday, that I welcome this show.\n",
      "----\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Synonym/Antonym\n",
      "\n",
      "Movie sentiments\n",
      "Test cases:      58\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Sentiment\n",
      "\n",
      "Movie genre specific sentiments\n",
      "Test cases:      736\n",
      "Fails (rate):    38 (5.2%)\n",
      "\n",
      "Example fails:\n",
      "1.0 The horror movie is calming\n",
      "----\n",
      "0.6 This comedy movie is serious\n",
      "----\n",
      "1.0 This drama movie was funny rather than serious\n",
      "----\n",
      "\n",
      "\n",
      "Movie Industries specific sentiments\n",
      "Test cases:      1200\n",
      "Fails (rate):    0 (0.0%)\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_suite.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-skating",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}