{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "animal-miracle",
   "metadata": {},
   "source": [
    "MIT License\n",
    "\n",
    "Copyright (c) 2020 Marco Tulio Correia Ribeiro\n",
    "\n",
    "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "of this software and associated documentation files (the \"Software\"), to deal\n",
    "in the Software without restriction, including without limitation the rights\n",
    "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "copies of the Software, and to permit persons to whom the Software is\n",
    "furnished to do so, subject to the following conditions:\n",
    "\n",
    "The above copyright notice and this permission notice shall be included in all\n",
    "copies or substantial portions of the Software.\n",
    "\n",
    "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
    "SOFTWARE.\n",
    "\n",
    "Notebook modified from: https://github.com/marcotcr/checklist/blob/master/notebooks/Sentiment.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-loading",
   "metadata": {},
   "source": [
    "# SST CheckList Capabilities on Test Set\n",
    "\n",
    "In this notebook, we generate the CheckList capabilities for robustness testing. Specifically, we generate test cases from scratch and augment instances from the SST-2 test set. \n",
    "\n",
    "## Import and Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "random-conditions",
   "metadata": {},
   "outputs": [],
   "source": [
    "import checklist\n",
    "from checklist.editor import Editor\n",
    "from checklist.perturb import Perturb\n",
    "from checklist.test_types import MFT, INV, DIR\n",
    "from checklist.test_suite import TestSuite\n",
    "from checklist.expect import Expect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attempted-bernard",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import spacy\n",
    "import json\n",
    "import numpy as np\n",
    "processor = spacy.load('en_core_web_sm')\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "recognized-sudan",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from checklist.perturb import process_ret\n",
    "\n",
    "def change_names_sst2(doc, meta=False, n=10, seed=None, negative_names=False): \n",
    "    \"\"\"\n",
    "    \n",
    "    Function that perturbs names present in the test set with names from the training set that were mostly only present in positive or negative\n",
    "    instances to check for possible biases of the model. \n",
    "    \n",
    "    Args: \n",
    "        negative_names (bool): Boolean indicating if instances should be perturbed only with names that occur in negative train instances.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "            np.random.seed(seed)\n",
    "    \n",
    "    with open(\"entities_sst2_train.json\", \"r\") as f:\n",
    "        entities_sst2 = json.load(f)\n",
    "        \n",
    "    with open(\"entities_sst2_test.json\", \"r\") as f: \n",
    "        entities_sst2_test = json.load(f)\n",
    "\n",
    "    names = [k for k, v in entities_sst2.items() if np.isclose(v[\"mean\"], 1.0) and np.isclose(v[\"std\"], 0.0)]\n",
    "    if negative_names: \n",
    "        names = [k for k, v in entities_sst2.items() if np.isclose(v[\"mean\"], 0.0) and np.isclose(v[\"std\"], 0.0)]\n",
    "    ents = [x.text for x in doc.ents if np.all([a.ent_type_ == 'PERSON' for a in x])]\n",
    "    ret = []\n",
    "    ret_m = []\n",
    "    for x in ents:\n",
    "        if x not in entities_sst2_test.keys(): \n",
    "            continue\n",
    "        to_use = np.random.choice(names, n)\n",
    "        for y in to_use:\n",
    "            ret.append(re.sub(r'\\b%s\\b' % re.escape(x), y, doc.text))\n",
    "            ret_m.append((f, y))            \n",
    "    return process_ret(ret, ret_m=ret_m, n=n, meta=meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "irish-pound",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_hollywood(doc, meta=False, seed=None):\n",
    "    \"\"\"\n",
    "    \n",
    "    Function that perturbs the name Hollywood (if present in the instance) with other movie industry names. \n",
    "    \n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    movie_industries = [\"Bollywood\", \"Nollywood\", \"Cantonwood\", \"Chinawood\", \"Taiwood\", \"Hallyuwood\", \"Hogawood\", \"Tollywood\", \"Kollywood\", \"Tamalewood\", \"Aussiewood\", \"Peruliwood\", \"Ghollywood\"]\n",
    "    n = len(movie_industries)\n",
    "    ret = []\n",
    "    ret_m = []\n",
    "    x = \"Hollywood\"\n",
    "    if x in doc.text:\n",
    "        sub_re = re.compile(r'\\b%s\\b' % re.escape(x))\n",
    "        to_use = np.random.choice(movie_industries, n, replace=False)\n",
    "        ret.extend([sub_re.sub(n, doc.text) for n in to_use])\n",
    "        ret_m.extend([(x, n) for n in to_use])\n",
    "\n",
    "    return process_ret(ret, ret_m=ret_m, n=n, meta=meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hawaiian-routine",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/Users/urjakhurana/.cache/huggingface/datasets/glue/sst2/1.0.0/7c99657241149a24692c402a5c3f34d4c9f1df5ac2e4c3759fadea38f6cb29c4)\n"
     ]
    }
   ],
   "source": [
    "from generalize_checklist.utils import get_dataset\n",
    "            \n",
    "dataset = get_dataset(\"glue\", \"albert-large-v2\", \"sst2\", split=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-dream",
   "metadata": {},
   "source": [
    "Since the test dataset from HuggingFace does not contain uppercasing, we extract the original sentences with correct uppercasing from the original GLUE SST-2 dataset (https://gluebenchmark.com/tasks) to detect and perturb names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "quantitative-prevention",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1815it [00:01, 1295.45it/s]\n"
     ]
    }
   ],
   "source": [
    "with open(\"sst2_test_labels.json\", \"r\") as f: \n",
    "    test_labels = json.load(f)\n",
    "\n",
    "# Filter out sentences for which we cannot retrieve original test labels and yield positive and negative sentences in test set.\n",
    "all_sentences = [d[\"sentence\"] for d in dataset if d[\"sentence\"] in test_labels]\n",
    "labels = [test_labels[sent] for sent in all_sentences]\n",
    "positive_sentences = set([sent for idx, sent in enumerate(all_sentences) if labels[idx] == 1])\n",
    "negative_sentences = set([sent for idx, sent in enumerate(all_sentences) if labels[idx] == 0])\n",
    "\n",
    "dictionary_path = \"../../../../Downloads/SST-2/original/dictionary.txt\"\n",
    "\n",
    "with open(dictionary_path, \"r\") as f: \n",
    "    original_sentences = f.read().splitlines()\n",
    "    \n",
    "original_sentences = [h.split(\"|\")[0] for h in original_sentences][1:]\n",
    "lower_originals = [s.lower() for s in original_sentences]\n",
    "\n",
    "# Create mapping between lower and uppercased sentences. \n",
    "matched = {}\n",
    "matched_positive = {}\n",
    "matched_negative = {}\n",
    "sentence_to_label = {}\n",
    "for i, new_sentence in tqdm(enumerate(all_sentences)): \n",
    "    if new_sentence in lower_originals: \n",
    "        idx = lower_originals.index(new_sentence)\n",
    "        matched[new_sentence] = original_sentences[idx]\n",
    "        if new_sentence in positive_sentences: \n",
    "            matched_positive[new_sentence] = original_sentences[idx]\n",
    "        elif new_sentence in negative_sentences: \n",
    "            matched_negative[new_sentence] = original_sentences[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "essential-lobby",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(all_sentences) == len(positive_sentences) + len(negative_sentences)\n",
    "assert len(matched.keys()) == len(matched_positive.keys()) + len(matched_negative.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "moderate-adult",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1795it [00:03, 452.61it/s]\n",
      "893it [00:01, 551.54it/s]\n",
      "902it [00:01, 558.97it/s]\n"
     ]
    }
   ],
   "source": [
    "sents = list(matched.values())\n",
    "processed_qs = list(tqdm(processor.pipe(sents, batch_size=32)))\n",
    "spacy_map = {q: processed_q for (q, processed_q) in zip(sents, processed_qs)}\n",
    "parsed_qs = [spacy_map[q] for q in sents]\n",
    "\n",
    "sents_pos = list(matched_positive.values())\n",
    "processed_pos_qs = list(tqdm(processor.pipe(sents_pos, batch_size=32)))\n",
    "spacy_map_pos = {q: processed_q for (q, processed_q) in zip(sents_pos, processed_pos_qs)}\n",
    "parsed_qs_pos = [spacy_map_pos[q] for q in sents_pos]\n",
    "\n",
    "sents_neg = list(matched_negative.values())\n",
    "processed_neg_qs = list(tqdm(processor.pipe(sents_neg, batch_size=32)))\n",
    "spacy_map_neg = {q: processed_q for (q, processed_q) in zip(sents_neg, processed_neg_qs)}\n",
    "parsed_qs_neg = [spacy_map_neg[q] for q in sents_neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "productive-footwear",
   "metadata": {},
   "outputs": [],
   "source": [
    "suite = TestSuite()\n",
    "editor = Editor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "entertaining-exercise",
   "metadata": {},
   "source": [
    "## Capability: Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-choice",
   "metadata": {},
   "source": [
    "### Synonyms and Antonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "auburn-communist",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "\n",
    "def get_antonyms_synonyms(word, antonym=False): \n",
    "    words = set([])\n",
    "    for syn in wordnet.synsets(word): \n",
    "        for l in syn.lemmas():\n",
    "            if antonym and l.antonyms(): \n",
    "                words.add(l.antonyms()[0].name().lower())\n",
    "            elif not antonym: \n",
    "                words.add(l.name().lower())\n",
    "    return list(words)\n",
    "\n",
    "        \n",
    "\n",
    "positive_words = [\"nice\", \"beautiful\", \"good\", \"entertaining\", \"interesting\"]\n",
    "negative_words = [\"bad\", \"horrible\", \"boring\", \"annoying\"]\n",
    "\n",
    "positive_synonyms = [word for pos_word in positive_words for word in get_antonyms_synonyms(pos_word)]\n",
    "positive_antonyms = [word for pos_word in positive_words for word in get_antonyms_synonyms(pos_word, antonym=True)]\n",
    "negative_synonyms = [word for neg_word in negative_words for word in get_antonyms_synonyms(neg_word)]\n",
    "negative_antonyms = [word for neg_word in negative_words for word in get_antonyms_synonyms(neg_word, antonym=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "frequent-columbus",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prissy, overnice, squeamish, gracious, decent, courteous, skillful, nice, dainty, beautiful, well, honest, goodness, in_force, skillful, salutary, upright, undecomposed, unspoiled, expert, trade_good, dear, respectable, practiced, near, serious, ripe, soundly, sound, proficient, safe, effective, thoroughly, in_effect, skilful, honorable, full, unspoilt, commodity, good, beneficial, right, just, secure, adept, dependable, estimable, entertaining, think_of, toy_with, nurse, think_about, hold, harbour, harbor, entertain, flirt_with, worry, matter_to, concern, interesting, interest, occupy\n",
      "\n",
      "\n",
      "nasty, ugly, bad, badness, ill, evilness, evil, uninteresting, bore\n",
      "\n",
      "\n",
      "big, risky, uncollectible, badly, sorry, bad, badness, unsound, forged, defective, tough, spoilt, speculative, spoiled, high-risk, regretful, unfit, frightful, horrible, horrifying, ugly, atrocious, drill, ho-hum, tire, slow, tedious, oil_production, drilling, dull, tiresome, deadening, boring, irksome, wearisome, bore, nark, irritation, galling, get_at, bothersome, teasing, vexatious, plaguy, annoyance, pesky, bother, vexation, pestiferous, annoy, annoying, rile, get_to, rag, irritate, irritating, nettlesome, vex, chafe, devil, pestering, plaguey, vexing, nettle, gravel\n",
      "\n",
      "\n",
      "good, goodness, unregretful, interest\n"
     ]
    }
   ],
   "source": [
    "print(\", \".join(positive_synonyms))\n",
    "print(\"\\n\")\n",
    "print(\", \".join(positive_antonyms))\n",
    "print(\"\\n\")\n",
    "print(\", \".join(negative_synonyms))\n",
    "print(\"\\n\")\n",
    "print(\", \".join(negative_antonyms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bored-colors",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words += [\"decent\", \"honest\"]\n",
    "negative_words += [\"nasty\", \"ugly\", \"evil\", \"uninteresting\", \"tough\", \"horrifying\", \"irritating\", \"bothering\", \"tiresome\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "rolled-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "editor.add_lexicon(\"positive_words\", positive_words)\n",
    "editor.add_lexicon(\"negative_words\", negative_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "active-poker",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = editor.template(\"This movie is {positive_words}.\", labels=1, save=True, seed=0)\n",
    "t += editor.template(\"This movie was so {positive_words} to watch.\", labels=1, save=True, seed=0)\n",
    "t += editor.template(\"This movie is so {negative_words}.\", labels=0, save=True, seed=0)\n",
    "t += editor.template(\"This movie was so {negative_words} to watch.\", labels=0, save=True, seed=0)\n",
    "t += editor.template(\"The acting in this movie was {positive_words}.\", labels=1, save=True, seed=0)\n",
    "t += editor.template(\"The acting in this movie was {negative_words}.\", labels=0, save=True, seed=0)\n",
    "\n",
    "ignore = ['This movie is beautiful.', 'This movie is good.']\n",
    "\n",
    "new_data = []\n",
    "new_labels = []\n",
    "for sample, label in zip(t.data, t.labels): \n",
    "    if sample not in ignore: \n",
    "        new_data.append(sample)\n",
    "        new_labels.append(label)\n",
    "        \n",
    "t.data = new_data\n",
    "t.labels = new_labels\n",
    "\n",
    "test = MFT(**t)\n",
    "suite.add(test, \"Movie sentiments\", \"Synonym/Antonym\", \"Use positive and negative words with their synonyms.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "daily-discretion",
   "metadata": {},
   "outputs": [],
   "source": [
    "rt_noun = [\"movie\", \"director\", \"actor\", \"show\", \"scene\"]\n",
    "editor.add_lexicon(\"rt_noun\", rt_noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "graduate-queens",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "beautiful, great, good, wonderful, terrible, fantastic, bad, terrific, brilliant, amazing\n"
     ]
    }
   ],
   "source": [
    "print(', '.join(editor.suggest('It was {a:mask} {rt_noun}.')[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "animal-divorce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_adj = [\"beautiful\", \"great\", \"good\", \"wonderful\", \"fantastic\", \"brilliant\", \"amazing\"]\n",
    "neg_adj = [\"terrible\", \"bad\"]\n",
    "neutral_adj = [\"American\", \"British\", \"New\", \"Old\"]\n",
    "editor.add_lexicon('pos_adj', pos_adj, overwrite=True)\n",
    "editor.add_lexicon('neg_adj', neg_adj, overwrite=True )\n",
    "editor.add_lexicon('neutral_adj', neutral_adj, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "logical-grove",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_verb_present = ['like', 'enjoy', 'appreciate', 'love',  'recommend', 'admire', 'value', 'welcome']\n",
    "neg_verb_present = ['hate', 'dislike', 'regret',  'abhor', 'dread', 'despise' ]\n",
    "neutral_verb_present = ['see', 'find']\n",
    "pos_verb_past = ['liked', 'enjoyed', 'appreciated', 'loved', 'admired', 'valued', 'welcomed']\n",
    "neg_verb_past = ['hated', 'disliked', 'regretted',  'abhorred', 'dreaded', 'despised']\n",
    "neutral_verb_past = ['saw', 'found']\n",
    "editor.add_lexicon('pos_verb_present', pos_verb_present, overwrite=True)\n",
    "editor.add_lexicon('neg_verb_present', neg_verb_present, overwrite=True)\n",
    "editor.add_lexicon('neutral_verb_present', neutral_verb_present, overwrite=True)\n",
    "editor.add_lexicon('pos_verb_past', pos_verb_past, overwrite=True)\n",
    "editor.add_lexicon('neg_verb_past', neg_verb_past, overwrite=True)\n",
    "editor.add_lexicon('neutral_verb_past', neutral_verb_past, overwrite=True)\n",
    "editor.add_lexicon('pos_verb', pos_verb_present+ pos_verb_past, overwrite=True)\n",
    "editor.add_lexicon('neg_verb', neg_verb_present + neg_verb_past, overwrite=True)\n",
    "editor.add_lexicon('neutral_verb', neutral_verb_present + neutral_verb_past, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "related-engineer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual positive words\n",
    "t = MFT(pos_adj + pos_verb_present + pos_verb_past, labels=1)\n",
    "suite.add(t, 'Single positive words', 'Vocabulary', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "passing-ethics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual negative words\n",
    "t = MFT(neg_adj + neg_verb_present + neg_verb_past, labels=0)\n",
    "suite.add(t, 'Single negative words', 'Vocabulary', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "authorized-practice",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = editor.template('{it} {rt_noun} {be} {pos_adj}.', it=['The', 'This', 'That'], be=['is', 'was'], labels=1, save=True, seed=0)\n",
    "t += editor.template('{it} {be} {a:pos_adj} {rt_noun}.', it=['It', 'This', 'That'], be=['is', 'was'], labels=1, save=True, seed=0)\n",
    "t += editor.template('{i} {pos_verb} {the} {rt_noun}.', i=['I', 'We'], the=['this', 'that', 'the'], labels=1, save=True, seed=0)\n",
    "t += editor.template('{it} {rt_noun} {be} {neg_adj}.', it=['That', 'This', 'The'], be=['is', 'was'], labels=0, save=True, seed=0)\n",
    "t += editor.template('{it} {be} {a:neg_adj} {rt_noun}.', it=['It', 'This', 'That'], be=['is', 'was'], labels=0, save=True, seed=0)\n",
    "t += editor.template('{i} {neg_verb} {the} {rt_noun}.', i=['I', 'We'], the=['this', 'that', 'the'], labels=0, save=True, seed=0)\n",
    "\n",
    "test = MFT(**t)\n",
    "suite.add(test, 'Sentiment-laden words in context', 'Vocabulary', 'Use positive and negative verbs and adjectives')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-continent",
   "metadata": {},
   "source": [
    "### Add Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "democratic-ministry",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive = editor.template('I {pos_verb_present} it.').data\n",
    "positive += editor.template('It is {pos_adj}.').data\n",
    "positive += ['I would watch this again.']\n",
    "negative = editor.template('I {neg_verb_present} it.').data\n",
    "negative += editor.template('It is {neg_adj}.').data\n",
    "negative += ['Never watching this again.']\n",
    "\n",
    "def add_phrase_function(phrases):\n",
    "    def pert(d):\n",
    "        while d[-1].pos_ == 'PUNCT':\n",
    "            d = d[:-1]\n",
    "        d = d.text\n",
    "        ret = [d + '. ' + x for x in phrases]\n",
    "        idx = np.random.choice(len(ret), min(10, len(ret)), replace=False)\n",
    "        ret = [ret[i] for i in idx]\n",
    "        return ret\n",
    "    return pert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "owned-prisoner",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_change(orig_conf, conf):\n",
    "    softmax = type(orig_conf) in [np.array, np.ndarray]\n",
    "    return orig_conf[0] - conf[0] + conf[1] - orig_conf[1]\n",
    "\n",
    "def diff_up(orig_pred, pred, orig_conf, conf, labels=None, meta=None):\n",
    "    tolerance = 0.1\n",
    "    change = positive_change(orig_conf, conf)\n",
    "    if change + tolerance >= 0:\n",
    "        return True\n",
    "    else:\n",
    "        return change + tolerance\n",
    "    \n",
    "def diff_down(orig_pred, pred, orig_conf, conf, labels=None, meta=None):\n",
    "    tolerance = 0.1\n",
    "    change = positive_change(orig_conf, conf)\n",
    "    if change - tolerance <= 0:\n",
    "        return True\n",
    "    else:\n",
    "        return -(change - tolerance)\n",
    "    \n",
    "goes_up = Expect.pairwise(diff_up)\n",
    "goes_down = Expect.pairwise(diff_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "annual-mississippi",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Perturb.perturb(parsed_qs, add_phrase_function(positive), nsamples=500)\n",
    "test = DIR(t.data, goes_up)\n",
    "description = 'Add very positive phrases (e.g. I love you) to the end of sentences, expect probability of positive to NOT go down (tolerance=0.1)'\n",
    "suite.add(test, 'add positive phrases', 'Vocabulary', description, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "instant-isaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Perturb.perturb(parsed_qs, add_phrase_function(negative), nsamples=500)\n",
    "test = DIR(t.data, goes_down)\n",
    "description = 'Add very negative phrases (e.g. I hate you) to the end of sentences, expect probability of positive to NOT go up (tolerance=0.1)'\n",
    "suite.add(test, 'add negative phrases', 'Vocabulary', description, overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "patent-straight",
   "metadata": {},
   "source": [
    "## Capability: Negation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "orange-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = editor.template('{it} {rt_noun} {nt} {pos_adj}.', it=['This', 'That', 'The'], nt=['is not', 'isn\\'t'], save=True, seed=0)\n",
    "t += editor.template('{it} {benot} {a:pos_adj} {rt_noun}.', it=['It', 'This', 'That'], benot=['is not',  'isn\\'t', 'was not', 'wasn\\'t'], save=True, seed=0)\n",
    "neg = ['I can\\'t say I', 'I don\\'t', 'I would never say I', 'I don\\'t think I', 'I didn\\'t' ]\n",
    "t += editor.template('{neg} {pos_verb_present} {the} {rt_noun}.', neg=neg, the=['this', 'that', 'the'], save=True, seed=0)\n",
    "t += editor.template('No one {pos_verb_present}s {the} {rt_noun}.', neg=neg, the=['this', 'that', 'the'], save=True, seed=0)\n",
    "test = MFT(t.data, labels=0, templates=t.templates)\n",
    "suite.add(test, 'Simple negations: negative', 'Negation', 'Very simple negations of positive statements')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "spatial-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_neg = neg[:-1]\n",
    "neutral =['my history with movies', 'all that I\\'ve seen over the years', 'it\\'s a Friday', \"that I bought it last week\", \"that we watched a lot\"]\n",
    "t = editor.template('{neg}, given {neutral}, that {it} {rt_noun} {be} {pos_adj}.', neutral=neutral, neg=['I don\\'t think', 'I can\\'t say', 'I wouldn\\'t say'], it=['this', 'that', 'the'], be=['is', 'was'], save=True, seed=0)\n",
    "t += editor.template('{neg}, given {neutral}, that {it} {be} {a:pos_adj} {rt_noun}.',neutral=neutral,  neg=['I don\\'t think', 'I can\\'t say', 'I wouldn\\'t say'], it=['this', 'that', 'the'], be=['is', 'was'], save=True, seed=0)\n",
    "t += editor.template('{neg}, given {neutral}, that {i} {pos_verb_present} {the} {rt_noun}.',neutral=neutral,  neg=['I don\\'t think', 'I can\\'t say', 'I wouldn\\'t say'], i=['I', 'we'], the=['this', 'that', 'the'], save=True, seed=0)\n",
    "t.data = list(np.random.choice(t.data, 500, replace=False))\n",
    "test = MFT(t.data, labels=0, templates=t.templates)\n",
    "suite.add(test, 'Hard: Negation of positive with neutral stuff in the middle (should be negative)', 'Negation', '', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "flying-paris",
   "metadata": {},
   "source": [
    "## Genre-Specific Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "flush-luther",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The horror movie is scary\n",
      "The horror movie was scary\n",
      "The horror movie is terrifying\n"
     ]
    }
   ],
   "source": [
    "start = [\"The\", \"This\"]\n",
    "be = [\"is\", \"was\"]\n",
    "positive_horror = [\"scary\", \"terrifying\", \"frightening\"]\n",
    "positive_romantic = [\"wholesome\", \"feel-good\", \"charming\"]\n",
    "positive_comedy = [\"funny\", \"light-hearted\", \"rib-tickling\"]\n",
    "positive_drama = [\"serious\", \"moving\"]\n",
    "\n",
    "negative_horror = [\"calming\"]\n",
    "negative_comedy = [\"serious\", \"unamusing\"]\n",
    "negative_children = [\"scary\"]\n",
    "\n",
    "start_be=start_be = [\"This is\", \"It's\", \"That is\"]\n",
    "positive_feeling = [\"liked\", \"enjoyed\", \"loved\"]\n",
    "genres = [\"horror\", \"romantic\", \"comedy\", \"drama\", \"children\"]\n",
    "audience=[\"I\", \"we\", \"they\", \"everyone\"]\n",
    "\n",
    "t = editor.template(\"{start} horror movie {be} {positive_horror}\", start=start, be=be, positive_horror=positive_horror, save=True, seed=0, labels=1)\n",
    "t += editor.template(\"{start} romantic movie {be} {positive_romantic}\", start=start, be=be, positive_romantic=positive_romantic, save=True, seed=0, labels=1)\n",
    "t += editor.template(\"{start} comedy movie {be} {positive_comedy}\", start=start, be=be, positive_comedy=positive_comedy, save=True, seed=0, labels=1)\n",
    "t += editor.template(\"{start} drama movie {be} {positive_drama}\", start=start, be=be, positive_drama=positive_drama, save=True, seed=0, labels=1)\n",
    "\n",
    "t += editor.template(\"{start} horror movie {be} {negative_horror}\", start=start, be=be, negative_horror=negative_horror, save=True, seed=0, labels=0)\n",
    "t += editor.template(\"{start} comedy movie {be} {negative_comedy}\", start=start, be=be, negative_comedy=negative_comedy, save=True, seed=0, labels=0)\n",
    "t += editor.template(\"{start} children movie {be} {negative_children}\", start=start, be=be, negative_children=negative_children, save=True, seed=0, labels=0)\n",
    "\n",
    "t += editor.template(\"{start} comedy movie {be} scary rather than {positive_comedy}\", start=start, be=be, positive_comedy=positive_comedy, save=True, seed=0, labels=0)\n",
    "t += editor.template(\"{start} horror movie {be} laughable rather than {positive_horror}\", start=start, be=be, positive_horror=positive_horror, save=True, seed=0, labels=0)\n",
    "t += editor.template(\"{start} drama movie {be} funny rather than {positive_drama}\", start=start, be=be, positive_drama=positive_drama, save=True, seed=0, labels=0)\n",
    "t += editor.template(\"{start} romantic movie {be} cold rather than {positive_romantic}\", start=start, be=be, positive_romantic=positive_romantic, save=True, seed=0, labels=0)\n",
    "\n",
    "t += editor.template(\"{start} comedy movie {be} {negative_comedy}, not {positive_comedy}\", start=start, be=be, negative_comedy=negative_comedy, positive_comedy=positive_comedy, save=True, seed=0, labels=0)\n",
    "t += editor.template(\"{start} horror movie {be} laughable, not {positive_horror}\", start=start, be=be, positive_horror=positive_horror, save=True, seed=0, labels=0)\n",
    "t += editor.template(\"{start} drama movie {be} funny, not {positive_drama}\", start=start, be=be, positive_drama=positive_drama, save=True, seed=0, labels=0)\n",
    "t += editor.template(\"{start} romantic movie {be} cold, not {positive_romantic}\", start=start, be=be, positive_romantic=positive_romantic, save=True, seed=0, labels=0)\n",
    "\n",
    "t += editor.template(\"{start_be} a {positive_horror} movie but {audience} {positive_feeling} it\", start_be=start_be, positive_feeling=positive_feeling, positive_horror=positive_horror, audience=audience, save=True, seed=0, labels=1)\n",
    "t += editor.template(\"{start_be} a {positive_romantic} movie but {audience} {positive_feeling} it\", start_be=start_be, positive_feeling=positive_feeling, positive_romantic=positive_romantic, audience=audience, save=True, seed=0, labels=1)\n",
    "t += editor.template(\"{start_be} a {positive_comedy} movie but {audience} {positive_feeling} it\", start_be=start_be, positive_feeling=positive_feeling, positive_comedy=positive_comedy, audience=audience, save=True, seed=0, labels=1)\n",
    "t += editor.template(\"{start_be} a {positive_drama} movie but {audience} {positive_feeling} it\", start_be=start_be, positive_feeling=positive_feeling, positive_drama=positive_drama, audience=audience, save=True, seed=0, labels=1)\n",
    "\n",
    "t += editor.template(\"{start_be} a {genres} movie but {audience} actually {positive_feeling} it\", start_be=start_be, genres=genres, audience=audience, positive_feeling=positive_feeling, save=True, seed=0, labels=1)\n",
    "\n",
    "new_data = []\n",
    "new_labels = []\n",
    "\n",
    "for sample, label in zip(t.data, t.labels): \n",
    "    if sample not in new_data: \n",
    "        new_data.append(sample)\n",
    "        new_labels.append(label)\n",
    "\n",
    "t.data = new_data\n",
    "t.labels = new_labels\n",
    "\n",
    "test = MFT(**t)\n",
    "suite.add(test, \"Movie genre specific sentiments\", 'Sentiment', \"Sentiment sentences that are specific to movie genres.\", overwrite=True)\n",
    "print(t.data[0])\n",
    "print(t.data[1])\n",
    "print(t.data[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "figured-genius",
   "metadata": {},
   "source": [
    "## Capability: NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "conservative-requirement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Director Kapur is a filmmaker with a real flair for epic landscapes and adventure , and this is a better film than his earlier English-language movie , the overpraised Elizabeth .\n",
      "Director Kapur is a filmmaker with a real flair for epic landscapes and adventure , and this is a better film than his earlier English-language movie , the overpraised Alyssa .\n",
      "Director Kapur is a filmmaker with a real flair for epic landscapes and adventure , and this is a better film than his earlier English-language movie , the overpraised Maria .\n"
     ]
    }
   ],
   "source": [
    "t = Perturb.perturb(parsed_qs, Perturb.change_names, nsamples=500, seed=0)\n",
    "test = INV(t.data)\n",
    "suite.add(test, 'Change names', 'NER', 'Replace names with other common names')\n",
    "\n",
    "print(t.data[0][0])\n",
    "print(t.data[0][1])\n",
    "print(t.data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "exposed-details",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "De Niro and McDormand give solid performances , but their screen time is sabotaged by the story 's inability to create interest .\n",
      "De Niro and Reginald Hudlin give solid performances , but their screen time is sabotaged by the story 's inability to create interest .\n",
      "Einstein and McDormand give solid performances , but their screen time is sabotaged by the story 's inability to create interest .\n"
     ]
    }
   ],
   "source": [
    "t = Perturb.perturb(parsed_qs_pos, change_names_sst2, nsamples=200, seed=0, negative_names=True)\n",
    "test = INV(t.data)\n",
    "suite.add(test, \"Polarizing Negative Names - Positive Instances\", \"NER\", \"Replaces names with polarizing negative celebrity names in positive instances of the training set.\", overwrite=True)\n",
    "\n",
    "print(t.data[0][0])\n",
    "print(t.data[0][1])\n",
    "print(t.data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "metropolitan-coverage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feel bad for King , who 's honestly trying , and Schwartzman , who 's shot himself in the foot .\n",
      "Feel bad for King , who 's honestly trying , and Smokey Robinson , who 's shot himself in the foot .\n",
      "Feel bad for King , who 's honestly trying , and Craig Bartlett , who 's shot himself in the foot .\n"
     ]
    }
   ],
   "source": [
    "t = Perturb.perturb(parsed_qs_neg, change_names_sst2, nsamples=200, seed=0, negative_names=False)\n",
    "test = INV(t.data)\n",
    "suite.add(test, \"Polarizing Positive Names - Negative Instances\", \"NER\", \"Replaces names with polarizing positive celebrity names in negative instances of the training set.\", overwrite=True)\n",
    "\n",
    "print(t.data[0][0])\n",
    "print(t.data[0][1])\n",
    "print(t.data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "naughty-swiss",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feel bad for King , who 's honestly trying , and Schwartzman , who 's shot himself in the foot .\n",
      "Feel bad for King , who 's honestly trying , and Crispin Glover , who 's shot himself in the foot .\n",
      "Feel bad for King , who 's honestly trying , and Yvan Attal , who 's shot himself in the foot .\n"
     ]
    }
   ],
   "source": [
    "t = Perturb.perturb(parsed_qs_neg, change_names_sst2, nsamples=200, seed=0, negative_names=True)\n",
    "test = INV(t.data)\n",
    "suite.add(test, \"Polarizing Negative Names - Negative Instances\", \"NER\", \"Replaces names with polarizing negative celebrity names in negative instances of the training set.\", overwrite=True)\n",
    "\n",
    "print(t.data[0][0])\n",
    "print(t.data[0][1])\n",
    "print(t.data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "elegant-ceremony",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Often gruelling and heartbreaking to witness , but Seldahl and Wollter 's sterling performances raise this far above the level of the usual maudlin disease movie .\n",
      "Often gruelling and heartbreaking to witness , but Seldahl and Smokey Robinson 's sterling performances raise this far above the level of the usual maudlin disease movie .\n",
      "Often gruelling and heartbreaking to witness , but Seldahl and Craig Bartlett 's sterling performances raise this far above the level of the usual maudlin disease movie .\n"
     ]
    }
   ],
   "source": [
    "t = Perturb.perturb(parsed_qs_pos, change_names_sst2, nsamples=200, seed=0, negative_names=False)\n",
    "test = INV(t.data)\n",
    "suite.add(test, \"Polarizing Positive Names - Positive Instances\", \"NER\", \"Replaces names with polarizing positive celebrity names in positive instances of the training set.\", overwrite=True)\n",
    "\n",
    "print(t.data[0][0])\n",
    "print(t.data[0][1])\n",
    "print(t.data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "verified-armor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It 's one of the most honest films ever made about Hollywood .\n",
      "It 's one of the most honest films ever made about Hogawood .\n",
      "It 's one of the most honest films ever made about Peruliwood .\n"
     ]
    }
   ],
   "source": [
    "t = Perturb.perturb(parsed_qs, change_hollywood, nsamples=200, seed=0)\n",
    "test = INV(t.data)\n",
    "suite.add(test, 'Change Movie Industries', 'NER', 'Replace the movie industry of Hollywood with other industries in the world', overwrite=True)\n",
    "\n",
    "print(t.data[0][0])\n",
    "print(t.data[0][1])\n",
    "print(t.data[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "weird-collector",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hollywood movies are nice\n",
      "Hollywood movies are beautiful\n",
      "Hollywood movies are good\n"
     ]
    }
   ],
   "source": [
    "movie_industries = [\"Hollywood\", \"Bollywood\", \"Nollywood\", \"Cantonwood\", \"Chinawood\", \"Taiwood\", \"Hallyuwood\", \"Hogawood\", \"Tollywood\", \"Kollywood\", \"Tamalewood\", \"Aussiewood\"]\n",
    "\n",
    "t = editor.template(\"{movie_industries} movies are {positive_words}\", movie_industries=movie_industries, positive_words=positive_words, save=True, seed=0, labels=1)\n",
    "t += editor.template(\"{movie_industries} movies are {negative_words}\", movie_industries=movie_industries, negative_words=negative_words, save=True, seed=0, labels=0)\n",
    "t += editor.template(\"{start} {movie_industries} movie {be} {positive_words}\", start=start, movie_industries=movie_industries, be=be, positive_words=positive_words, save=True, seed=0, labels=1)\n",
    "t += editor.template(\"{start} {movie_industries} movie {be} {negative_words}\", start=start, movie_industries=movie_industries, be=be, negative_words=negative_words, save=True, seed=0, labels=0)\n",
    "\n",
    "new_data = []\n",
    "new_labels = []\n",
    "\n",
    "for sample, label in zip(t.data, t.labels): \n",
    "    if sample not in new_data: \n",
    "        new_data.append(sample)\n",
    "        new_labels.append(label)\n",
    "\n",
    "t.data = new_data\n",
    "t.labels = new_labels\n",
    "\n",
    "test = MFT(**t)\n",
    "suite.add(test, \"Movie Industries specific sentiments\", 'Sentiment', \"Sentiment sentences about movie industries.\", overwrite=True)\n",
    "print(t.data[0])\n",
    "print(t.data[1])\n",
    "print(t.data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "northern-notion",
   "metadata": {},
   "outputs": [],
   "source": [
    "neutral_words = set(\n",
    "    ['.', 'the', 'The', ',', 'a', 'A', 'and', 'of', 'to', 'it', 'that', 'in',\n",
    "     'this', 'for',  'you', 'there', 'or', 'an', 'by', 'about', 'movie', 'show' 'my',\n",
    "     'in', 'of', 'have', 'with', 'was', 'at', 'it', 'get', 'from', 'this',\n",
    "    ])\n",
    "forbidden = set(['No', 'no', 'Not', 'not', 'Nothing', 'nothing', 'without', 'but'])\n",
    "def change_neutral(d):\n",
    "    examples = []\n",
    "    subs = []\n",
    "    words_in = [x for x in d.capitalize().split() if x in neutral_words]\n",
    "    if not words_in:\n",
    "        return None\n",
    "    for w in words_in:\n",
    "        suggestions = [x for x in editor.suggest_replace(d, w, beam_size=5, words_and_sentences=True) if x[0] not in forbidden]\n",
    "        examples.extend([x[1] for x in suggestions])\n",
    "        subs.extend(['%s -> %s' % (w, x[0]) for x in suggestions])\n",
    "    if examples:\n",
    "        idxs = np.random.choice(len(examples), min(len(examples), 10), replace=False)\n",
    "        return list(set([examples[i] for i in idxs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "lesbian-appreciation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It 's a decent glimpse into a time period , and an outcast , that is no longer accessible , but it does n't necessarily shed more light on its subject than the popular predecessor .\n",
      "It 's a decent glimpse into a time period , considered an outcast , that is no longer accessible , but it does n't necessarily shed more light on its subject than the popular predecessor .\n",
      "It 's a decent glimpse into a time period , and social outcast , that is no longer accessible , but it does n't necessarily shed more light on its subject than the popular predecessor .\n"
     ]
    }
   ],
   "source": [
    "t = Perturb.perturb(sents, change_neutral, nsamples=500)\n",
    "test = INV(t.data)\n",
    "description = 'Change a set of neutral words with other context-appropriate neutral words (using BERT).'\n",
    "suite.add(test, 'change neutral words with BERT', 'Vocabulary', description, overwrite=True)\n",
    "\n",
    "print(t.data[0][0])\n",
    "print(t.data[0][1])\n",
    "print(t.data[0][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-viewer",
   "metadata": {},
   "source": [
    "## Capability: Temporality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "intermediate-anthropology",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2152"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change = ['but', 'even though', 'although', '']\n",
    "t = editor.template(['I used to think this movie was {neg_adj}, {change} now I think it is {pos_adj}.',\n",
    "                                 'I think this movie is {pos_adj}, {change} I used to think it was {neg_adj}.',\n",
    "                                 'In the past I thought this movie was {neg_adj}, {change} now I think it is {pos_adj}.',\n",
    "                                 'I think this movie is {pos_adj}, {change} in the past I thought it was {neg_adj}.',\n",
    "                                ] ,\n",
    "                                 change=change, unroll=True, save=True, labels=1, seed=0)\n",
    "t += editor.template(['I used to {neg_verb_present} this movie, {change} now I {pos_verb_present} it.',\n",
    "                                 'I {pos_verb_present} this movie, {change} I used to {neg_verb_present} it.',\n",
    "                                 'In the past I would {neg_verb_present} this movie, {change} now I {pos_verb} it.',\n",
    "                                 'I {pos_verb_present} this movie, {change} in the past I would {neg_verb_present} it.',\n",
    "                                ] ,\n",
    "                                change=change, unroll=True, save=True, labels=1, seed=0)\n",
    "\n",
    "t += editor.template(['I used to think this movie was {pos_adj}, {change} now I think it is {neg_adj}.',\n",
    "                                 'I think this movie is {neg_adj}, {change} I used to think it was {pos_adj}.',\n",
    "                                 'In the past I thought this movie was {pos_adj}, {change} now I think it is {neg_adj}.',\n",
    "                                 'I think this movie is {neg_adj}, {change} in the past I thought it was {pos_adj}.',\n",
    "                                ] ,\n",
    "                                 change=change, unroll=True, save=True, labels=0, seed=0)\n",
    "t += editor.template(['I used to {pos_verb_present} this movie, {change} now I {neg_verb_present} it.',\n",
    "                                 'I {neg_verb_present} this movie, {change} I used to {pos_verb_present} it.',\n",
    "                                 'In the past I would {pos_verb_present} this movie, {change} now I {neg_verb_present} it.',\n",
    "                                 'I {neg_verb_present} this movie, {change} in the past I would {pos_verb_present} it.',\n",
    "                                ] ,\n",
    "                                change=change, unroll=True, save=True, labels=0, seed=0)\n",
    "\n",
    "new_data = []\n",
    "new_labels = []\n",
    "\n",
    "for sample, label in zip(t.data, t.labels): \n",
    "    if sample not in new_data: \n",
    "        new_data.append(sample)\n",
    "        new_labels.append(label)\n",
    "\n",
    "t.data = new_data\n",
    "t.labels = new_labels\n",
    "test = MFT(**t)\n",
    "description = '''Have two conflicing statements, one about the past and one about the present.\n",
    "Expect the present to carry the sentiment. Examples:\n",
    "I used to love this movie, now I hate it -> should be negative\n",
    "I love this movie, although I used to hate it -> should be positive\n",
    "'''\n",
    "suite.add(test, 'used to, but now', 'Temporal', description, overwrite=True)\n",
    "len(t.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "valid-display",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<checklist.test_types.MFT object at 0x7fec2de71d90>\n",
      "<checklist.test_types.MFT object at 0x7fec2e1f3f50>\n",
      "<checklist.test_types.MFT object at 0x7fec2e1c79d0>\n",
      "<checklist.test_types.MFT object at 0x7fec2e1d6910>\n",
      "<checklist.test_types.DIR object at 0x7fec2e1e3950>\n",
      "<checklist.test_types.DIR object at 0x7fec2e853bd0>\n",
      "<checklist.test_types.MFT object at 0x7fec2e1ec490>\n",
      "<checklist.test_types.MFT object at 0x7fec2e1f3090>\n",
      "<checklist.test_types.MFT object at 0x7fec2e408390>\n",
      "<checklist.test_types.INV object at 0x7fec2e1fb2d0>\n",
      "<checklist.test_types.INV object at 0x7fec2e1dd950>\n",
      "<checklist.test_types.INV object at 0x7fec5da20cd0>\n",
      "<checklist.test_types.INV object at 0x7fec2e40b150>\n",
      "<checklist.test_types.INV object at 0x7fec2f8591d0>\n",
      "<checklist.test_types.INV object at 0x7fec2e679950>\n",
      "<checklist.test_types.MFT object at 0x7fec2e6819d0>\n",
      "<checklist.test_types.INV object at 0x7fec2e850bd0>\n",
      "<checklist.test_types.MFT object at 0x7fec2e74b410>\n"
     ]
    }
   ],
   "source": [
    "for test in suite.tests: \n",
    "    print(suite.tests[test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "fourth-newspaper",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suite.summary()\n",
    "suite.save(\"testset_19_07_21.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "artistic-valuation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
